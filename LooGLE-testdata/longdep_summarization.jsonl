{"input": "Distinction and quadratic base change for regular supercuspidal representations\n\n\nChuijia Wang\n\n\n1 Introduction\nLet  be a connected reductive algebraic group over a non-archimedean local field  with residual characteristic . In the study of representation theory of , one important problem is to capture the distinguished representations with respect to a pair , where  is a closed subgroup of  and  is a one dimensional character of . More precisely, an irreducible smooth representation  of  is said to be -distinguished ifThe distinction property of an irreducible representation could be described in two common ways. One is in terms of the symmetry of the representation itself, such as the self dual or conjugate self dual property. The other one is in terms of the functorial property of the Langlands parameter associated to the representation.\nSakellaridis and Venkatesh [SV17] have set up a general framework to understand the relationship between distinguished representations and Langlands functoriality when the corresponding homogeneous space  is a spherical variety. Moreover, Dipendra Prasad [Pra15] has a more precise conjecture describing the relationship between the distinction property of an irreducible representation with respect to a specific quadratic character and the base change property of its Langlands parameter when  is a Galois symmetric space.\nThe main focus of this article is to understand Prasad\u2019s conjecture on the Galois distinction problem. More precisely, let  be a quadratic extension and  be the non-trivial element in . We are interested in the distinction problem for the pair , where  is regarded as a closed subgroup of  and  is the specific quadratic character of  associated to the quadratic extension  defined in [Pra15]. Let  denote the set of equivalence classes of irreducible representations of  and  denote the set of  conjugacy classes of Langlands parameters of . The local Langlands correspondence states that there exists a finite-to-one surjective map from  to , which is denoted by . Prasad [Pra15] predicts that the Langlands parameters of -distinguished representations are exactly those which are base change from Langlands parameters of , where  is a quasi-split -form of  such that . One can refer to Section\u00a05 for a more detailed description of these notions. In other words, we have the following:Moreover, he also conjectures that the following identity holds for an irreducible discrete series representation  of  in a generic -packet:where the sum of RHS runs over all the Langlands parameters  such that ,  denotes the irreducible representation of the component group  associated to , and  is the multiplicity of the trivial representation in the restriction of . Notice that 1.1 follows from 1.2, when both sides of 1.2 are non-zero.\nThis conjecture unifies a number of conjectures which aim to capture the distinction property of representations for Galois symmetric pairs and considerable progress has been made in attacking Prasad\u2019s conjecture for specific Galois pairs. For the pair , this conjecture generalizes a conjecture of Jacquet, Rallis and Flicker [Fli91], which states that the -distinguished representations of  are precisely those arising as base change from , and the conjecture is proved by Kable [Kab04] for discrete series representations. For the pair , this conjecture generalizes a conjecture of Jacquet [Jac05][Jac10] and is proved by Feigon, Lapid and Offen [FLO12]. Anandavardhanan and Prasad prove the conjecture for  in [AP03][AP16], where they give the first example of a non-supercuspidal Gelfand pair. More precisely, they find that the dimension of the space of invariant linear forms is strictly larger than one for some supercuspidal reprensentations. Hengfei Lu [Lu19][Lu20] proves this conjecture for certain classical groups of small rank and their similitude groups using the machinery of local theta correspondence. All of these work depends on concrete analysis of the terms appearing on both sides of Prasad\u2019s identity, and developing a general method which could work for all Galois symmetric pairs would be interesting. Recently, Raphael Plessis [Rap18] develops a relative trace formula approach to attack Prasad\u2019s conjecture for general groups. His method turns out to be powerful, and has already been used to prove Prasad\u2019s conjecture for Steinberg representations, which recovers early results proved by Broussous and Court\u00e9s [BC14] [Cou15] using the geometry of Bruhat-Tits building, and by Matringe [Mat17] through careful analysis of double cosets appearing in Mackey theory.\nIn this article, we try to give some evidence on the possibility of proving this conjecture for regular supercuspidal representations without constraints on the Galois symmetric pair using a different purely local method. Supercuspidal representations are fundamental objects in the study of representation theory of -adic groups. They serve as building blocks of all irreducible smooth representations in the sense that every irreducible representation can be realized as a subrepresentation of a parabolic induction from a supercuspidal representation of a Levi subgroup. One of the reasons why we work on regular supercuspidal representations is that they are parametrized by simple data and their Langlands parameters have good functorial properties. These representations are special cases of tamely ramified supercuspidal representations satisfying certain regular conditions. Explicit constructions of tame supercuspidal representations date back to the work of Howe [How77]. Following his pioneering work, tremendous progress has been made in the explicit construction of tame supercuspidal representations for general reductive groups. Jiu-Kang Yu [Yu01] first develops a general construction of tamely ramified supercuspidal representations using generic cuspidal -data , which generalizes the earlier work of Adler [Adl98]. Ju-Lee Kim [Kim07] later shows that the representations constructed by Yu exhaust all the irreducible supercuspidal representations when the charateristic of the residue is large enough. Recently, the exhaustion theorem is improved by Jessica Fintzen [Fin18] under a weaker constraint on . Based on Yu\u2019s work, Tasho Kaletha [Kal19] classifies regular supercuspidal representations using simpler data  and established the local Langlands correspondence for regular supercuspidal representations. As pointed out by Kaletha, one crucial property of a regular supercuspidal representation is that its Langlands parameter factors through the -group of the elliptic torus  which defines the representation:This property enables us to describe the base change of  in terms of the base change of  because of the following commutative diagram of functorial maps:\nTo state and prove Prasad\u2019s conjecture for regular supercuspidal representations, we need the Langlands-Vogan bijection for regular supercuspidal representations of . For these representations, the full Langlands-Vogan bijection, that is, the map  and the bijection between the set of characters of the component group and the set of rational equivalence classes of rational embeddings of tori, are constructed in a series of papers [Kal19] [FKS21]. In fact, they also deal with more general supercuspidal representations, which are known as non-singular representations. Their work enables us to use the parametrization results of regular supercuspidal representations unconditionally in the study of distinction problem.\nThe main ingredients to prove the conjecture are Hakim-Murnaghan\u2019s description of the Hom space by Mackey theory [HM08] and Kaletha\u2019s parametrization of regular supercuspidal representations using tame regular elliptic pairs [Kal19]. We will use these ingredients in three steps. The first step is to describe the base change map in terms of regular supercuspidal -packet data defined by Kaletha, and check the compatibility between our formulation and the original base change map defined by restriction of the Langlands parameter to the Weil group of the quadratic extension field. Then the right hand side of the conjectural formula 1.2 can be expressed as an identity involving a set of elliptic maximal tori over  and a set of characters of the elliptic tori satisfying certain conditions. The second step is to provide a reinterpretation of Hakim-Murnaghan\u2019s formula on the dimension of the Hom space using the same data that appears on the parameter side of the formula. The final step is to give a comparison between both sides, and reduce the proof to an identity comparing various characters of the elliptic maximal torus , which naturally appear in the distinction problem, the base change problem, and the construction of local Langlands correspondence. A priori, it seems that there is no obvious relation between these characters, whose constructions are of different nature. However, we can prove this conjectural identity for several examples, which gives a new purely local proof of Prasad\u2019s conjecture for regular supercuspidal representations of these groups. We also prove Prasad\u2019s conjecture for regular supercuspidal representations of  when  is unramified, and  is a general quasi-split reductive group.\nPrasad\u2019s conjecture 5.17 holds for regular supercuspidal representations when  is unramified.\nPrasad\u2019s conjecture 5.17 holds for regular supercuspidal representations of ,, ( odd) and  ( odd) for arbitrary quadratic extension .\nThis article is organized as follows. In Section\u00a03 and Section\u00a04, we briefly summarize Kaletha\u2019s work on the construction of -parameters and -packets for regular supercuspidal representations, and study the base change map of Langlands parameters (Lemma\u00a04.1 Proposition\u00a04.2) in terms of Kaletha\u2019s supercuspidal -packet data. After that, we give a brief introduction to Prasad\u2019s conjecture in Section\u00a05, where we also obtain a new factorization formula (Theorem\u00a05.15) for the restriction of Prasad\u2019s quadratic character to an elliptic maximal torus. Then we review Hakim and Murnaghan\u2019s work on the computation of the dimension of the space of invariant linear forms and give a new interpretation of their formula (Equation\u00a06.5) in Section\u00a06. After all these preparation, the reduction to the case of tori (Proposition\u00a07.8 Proposition\u00a07.4) and the comparison of the two sides (Proposition\u00a07.2 Lemma\u00a07.10) are established in Section\u00a07 except for 7.9. In Section\u00a08, we present a detailed study of these quadratic characters and prove Proposition\u00a08.1 and Proposition\u00a08.2, which finishes the proof of Theorem\u00a08.15 and Theorem\u00a08.16.\nAcknowledgement.\nThis article consists of my Ph.D thesis at National University of Singapore. I want to express my sincere thanks to my supervisor Wee Teck Gan for his patient guidance, constant encouragement and valuable discussions over the years. His insight and suggestions play an important role in the whole project. I would like to thank Dipendra Prasad for proposing his conjecture, as well as continuous communications and encouragement during the period of preparing this article. I am also grateful to Tasho Kaletha, Jeffrey Hakim, Fiona Murnaghan, Jiu-Kang Yu, Laure Blasco, Jessica Fintzen, Wen-Wei Li, Chong Zhang and David Schwein for kindly answering my questions. Thanks are also due to Tasho Kaletha, Jeffrey Hakim, Hung Yean Loke, Hengfei Lu, Jiandi Zou for providing useful comments and feedbacks on an early draft. This work was partially supported by a Singapore government MOE Tier 1 grant R-146-000-320-114 and Israel Science Foundation grant 737/20.\n2 Notations and conventions\n2.1 Notation.\nLet  be a non-achimedean local field with residual characteristic . Fix a valuation  on , let ,  and  denote the ring of integers, a uniformizer and the residual field of . Let  denote the cardinality of . Let  be an algebraic closure of  and  be the separable closure of  in .\nFor any finite Galois extension , let  be the finite Galois group. Let \nbe the absolute Galois group with the profinite topology. Let  be the relative Weil group of , that is, an extensionwhich corresponds to the fundamental class in . Let  be the Weil group with locally profinite topology. Let  be the inertia group, and  be the wild inertia group. The natural map from  to  fits into the commutative diagram:Let  denote the Weil-Deligne group. Let  be the maximal unramified extension of  and  be the lift of the Frobenius automorphism of , which is a topological generator of . For any reasonable object (abelian group, non-abelian group, algebraic variety) equipped with a  or  action which is compatible with the structure of , let  denote the -th Galois cohomology of  and  denote the -th Weil cohomology of . If  is the complex points of an algebraic group over , we use  and  to stand for continuous cohomology, by which we mean the cochains are continuous with respect to the natural complex analytic topology of .\nWhenever there is a group homomorphism , we use the notation  instead of  for simplicity, which is a group only when  is normal in . For any one dimensional character  such that , we sometimes use the notation  for simplicity, when there is no confusion.\nFor a reductive group  defined over , let  denote the derived subgroup of , which is semisimple, and  and  denote the simply connected cover and adjoint quotient of . For any maximal torus  defined over  with splitting field , let  denote the set of absolute roots associated to the adjoint action of . When there is no confusion about the maximal torus, we simply write  for convenience. For any root , let  and  be the subfield of  corresponding to the subgroup  and  of .  is an extension of  of degree at most two. If , then  is called asymmetric, otherwise it is called symmetric. Let  and  denote the set of asymmetric and symmetric roots in . Let  be the absolute root datum of . Let  be the Langlands dual group of , which is a complex algebraic group determined by the root datum . For ,  denotes the corresponding element in . Also, for ,  denotes the corresponding element in . We also use the usual notation  for the algebraic fundamental group of  and  for the component group of , both of which are finite when  is semisimple.\nFrom now on till the end, we will always assume that  splits over a tamely ramified extension , and  is a maximal torus of  defined over  which splits over . Let  denote the enlarged Bruhat-Tits building of  over . Set  with a natural partial order: for any ,  if ; ,  if ; and ,  for any . For any  and , let  denote the Moy-Prasad subgroup generated by  and  for any  defined in [MP94], and  be , with corresponding filtration lattices of Lie algebra  and . Let  denote , and  denote . For , we also use the notation  for the Moy-Prasad quotient . For a sequence of twisted Levi subgroups , a sequence  in  and , we use the following notation for simplicity:\nFor an irreducible admissible representation  of , let  be the depth of , which is defined by\nWe will also adopt the notations from [Kal19]. For any  and , let  denote the jumps of , that is,Let  and  denote the following subsets of roots\nFor any quadratic extension , we use the notation  for the set of norm  elements inside . When there is no confusion about the subfield , we simply write .\nWhen  is quasi-split over  with a fixed Borel subgroup  such that  is a maximal torus of  and  is the unipotent radical of , we use the notation  for the pinning of  determined by the pair . By a Whittaker datum , we mean a  conjugacy class of pairs , where  is a generic character of . Let  be a non-trivial additive character. Notice that each choice of  gives a homomorphism , and composing with the addition map  yields a homomorphism . Every generic character  arises as a composition of  and  for some choice of pinning , and we also call  the Whittaker datum determined by the pinning . A representation  of  is said to be generic if it is  distinguished for some Whittaker datum .\n2.2 Assumption.\nSince our work is based on the fundamental work of Kaletha [Kal19], we also need to propose certain assumptions on the ground field as in [Kal19]. We list these assumptions for convenience of the readers. We assume the residual characteristic ,  is not a bad prime for ,  and .\n3 Local Langlands correspondence for regular supercuspidal representations\n3.1 Langlands-Vogan bijection.\nWe first recall the conjectural local Langlands correspondence and Vogan\u2019s refinement. Let  be a quasi-split reductive group defined over , and  be the Weil form of the -group of .\nA Langlands parameter  of  is a homomorphism  such that: is a morphism of algebraic groups over . is continuous on  and  is semisimple in . is the natural projection.The homomorphism  satisfying the above conditions is usually called an admissible homomorphism.\nBy the third condition, for any , we can write , such that  lies in . Notice that  is a homomorphism if and only ifwhich means that one can regard  as an element in .\nLet  denote the set of equivalence classes of irreducible admissible representations of  and  denote the set of  conjugacy classes of Langlands parameters of . The local Langlands correspondence for quasi-split groups predicts that there exists a surjective, finite to one map:such that there exists a bijection between  and  for any , where  is the fiber of  and  is . The set  is called the -packet associated to . This bijection is not canonical and depends on certain normalization of Whittaker datum, under which the trivial representation of the component group corresponds to a generic representation. It is expected that LLC has nice properties, such as preserving local constants on both sides, being compatible with character twists on both sides, etc. We will list some of these properties in Section\u00a03.5.\nLater, Vogan [Vog93] notices that one should consider the representation theory of pure inner twist of  simultaneously in the local Langlands correspondence and he predicts that there should exist a bijection between  and  for any , such that the following diagram commutes:where the bottom arrow is given by the Kottwitz isomorphism. Fixing a Whittaker datum of the quasi-split form , one can associate a pair  to any irreducible representation  of , where  is the usual Langlands parameter and  is an irreducible representation of . The pair  is usually called the Langlands-Vogan parameter (enhanced Langlands parameter) of .\nIt is expected that one can read the information of an irreducible representation from its Langlands parameter. We have the following definitions of various Langlands parameters.\nLet  be a Langlands parameter of . It is calledelliptic (discrete), if  is not contained in any proper Levi subgroup  of . (or equivalently  is finite modulo .)bounded, if the closure of  in  is compact.unramified, if  is trivial.spherically unramified, if  is trivial.tamely ramified, if  is trivial.torally wild, if  is contained in a torus of .\nThese Langlands parameters are supposed to parameterize essentially discrete series, tempered, unipotent (unipotent reduction in the sense of Lusztig), unramified (spherical), depth zero and torally wild (essentially tame in the sense of Bushnell and Henniart for ) representations of .\nThe conjectural refined local Langlands correspondence has been verified for a large number of cases: for all representations of groups of certain type [HT01][Hen00][Sch13][Art13][Mok15][GT11] etc and for particular representations of general reductive groups [DR09][RY14][Kal15][Kal19][Sol 18] etc. One can refer to [Kal16a] for a more detailed description of the status of the conjecture.\nAs conjectured by Gross and Reeder [GR10, Conjecture 7.1 (4)], for a discrete Langlands parameter, the condition  should be equivalent to the condition that all the representations in  are supercuspidal representations. For these representations, the Langlands parameters are simply homomorphisms from  to .\nA regular supercuspidal parameter is a discrete Langlands parameter  such that: is contained in a torus of . is a torus.Let , , if  projects to a nontrival element in , then .\nLet  be a quadratic extension, and  be a regular supercuspidal Langlands parameter of . If  is a Langlands parameter of  such that  is  conjugate to , then  is also a regular supercuspidal parameter of . This is simply due to the fact that  implies  is a tamely ramified extension, so that one has  and .\n3.2 -embedding and -data.\nA crucial property of regular supercuspidal parameters is that they factor though the -group of certain elliptic maximal torus of , which could be regarded as a special example of functoriality discussed in Section\u00a03.5. Let  be an arbitrary maximal tori of a quasi-split reductive group  defined over a local field  of characteristic zero. Langlands and Shelstad [LS87] first realized that one could always extend a -stable  conjugacy class of embedding of dual groups  to an embedding of -groups (Weil form)  with the help of some auxiliary data. We give a brief review about their constructions of -embeddings using -data. A more detailed description could be found in [LS87] and [Tam16].\nLet  be a quasi-split reductive group over , and  be a maximal torus defined over , and we assume  is contained in a Borel subgroup  since  is split. We may choose a -invariant pinning  of  such that  and  maps the simple roots determined by  to those determined by . Notice that the map  is not necessarily -equivariant, we use subscripts  and  to denote the action on  and  for any .\nAn admissible -embedding  is a group homomorphism satisfying:for some .\nFor  to be a homomorphism, one must have:for any . From the first equation, one can see that . From the second equation, one can find that  is a Langlands parameter of .\nBy choosing a base point of an embeddingone can obtain the following fact.\nThe set of  equivalent classes of L-embeddings\n is a torsor under . The explicit bijection with respect to a base point  is given by:Conversely, for any given  and , one can associate an equivalence class of embeddings:\nFor  with elliptic maximal torus  such that  is a degree  extension, one can choose the canonical pinning of  such that  is the diagonal torus. One can choose a  such that . There is a canonical base point  in  such that:withfor any , and  is given by a permutation matrix in  with entries being  and  determined the the above relation. If we fix a character  and  which corresponds to an equivalence class of -embedding in Equation\u00a03.2 with respect to the above base point , the composition gives the Langlands parameter of :\nThe remaining difficulty is to construct a base point of an -embedding in general, which is achieved by Langlands and Shelstad [LS87] using -data.\nA set of -data for  is a collection of elements  satisfying:for any \nA set of -data for  is a collection of elements  satisfying:for any  and\n is the quadratic character attached to  for any symmetric root .\nLet  denote the Weyl group , one can define a section ofin the following way.\nLet  be a simple root of  with root vector . Let  be the corresponding  triple. Let  denote the simple reflection associated to , we setand set  for  with . This section gives a map:where  is the section of  in  and the action of  is given by the difference of the  action on  and  action on , that is\nNotice that the map  is not necessarily a homomorphism of groups. Hence to get a base point, Langlands and Shelsted [LS87] construct a 2 cocyle\nOne needs to find a splitting  of , that is, the map  should satisfy:Such splittings are constructed by a family of -data. We recall the explicit construction of the cochain . (In fact, the explicit realization of  involves certain choices of coset representatives). Fixing a set of representatives  of the left coset , we can define a family of functions  by the following equations:for suitable .\nOne can also define  similarly by fixing the coset representatives  of . More explicitly, for , , and for , .\nWe can define a cochain  by:\nLanglands and Shelstad prove that such  is a splitting of . A priori, the explicit construction of  depends on a choice of certain coset representatives, which has a more elegant interpretation via the notion of gauge introduced in [LS87].\nA gauge is a function  such that  for any .\nA set of coset representatives  of  canonically determines a gauge by . For two different gauges  and , one can associate a cochain  as in [LS87, Lemma 2.4]. The map  and  are related by .\nGiven a cochain  associated to a set of -data  and a fixed gauge , we can extend the embedding  to  by defining:\nThe above map in Equation\u00a03.8 is a group homomorphism.\nThis is essentially contained in [LS87]. We write down the explicit computation for completeness. To check that the map defines a homomorphism, one needs to check the following identity:Notice that by Equation\u00a03.1, we haveWe can also compute  explicitly by:Hence we only need to provewhich is exactly given by Equation\u00a03.6.\n\u220e\nIn fact, the choice of -data is not unique. The difference of -data provides a character of  in the following way.\nA set of -data for  is a collection of elements  satisfying:for any  and\n for any symmetric root  .\nLet  and  be two sets of -data, it is clear from definition that  is a set of -data. Following [LS87] and [Kal19], one can construct a character\nwhere  denotes the isomorphism . By the notation in Equation\u00a03.3, the -embeddings associated to  and  are related by:Among the set of -data, the following ones are crucially used in computing the characters of supercuspidal representations.\nA set of -data:  is called minimally ramified if, if  is asymmetric, is unramified, if  is symmetric unramified, is tamely ramified, if  is symmetric ramified.\nKaletha also introduced the following notion of mod--data, which can be better used in conjunction with tamely ramified -data.\nA set of mod--data for  is a collection of elements  satisfying:for any \nFor regular supercuspidal representations associated to a tame elliptic pair, Kaletha [Kal19] describes a canonical choice of minimally ramified -data associated to the mod--data determined by the character .\n, if  is asymmetric. is the quadratic character associated to the unique unramified quadratic extension of  by local class field theory, if  is symmetric unramified. is the tamely ramified character determined by the following equation, if  is symmetric ramified.\nFor any  and a Howe factorization  in Definition\u00a06.3,where  is the -constant defined by Langlands. More precisely, it has the following expression in terms of Deligne\u2019s local root numbers:where  denotes the additive character  and  similarly.\nNotice that the construction of Equation\u00a03.8 depends heavily on the choice of the -data, which is not unique. For the case of , Tam [Tam16] also constructed certain -data in order to understand the rectifiers defined by Bushnell and Henniart [BH10]. The comparison of Tam\u2019s -data and Kaletha\u2019s canonical minimally ramified -data is carefully studied for regular supercuspidal representations of  in [OK21], which also leads to a comparison of the local Langlands correspondences for these representations established by [HT01][Hen00] and [Kal19]. Throughout this article, we work with Kaletha\u2019s canonical minimally ramified -data.\nRecently, Kaletha [Kal19a] gives a new interpretation of the work of Langlands and Shelstad by introducing certain double cover of the elliptic torus, where the base point of the -embedding associated to the double cover corresponds to a genuine character of the double cover.\n3.3 Kaletha\u2019s parametrization of regular supercuspidal representations.\nBased on the earlier work of Langlands and Shelstad [LS87], Kaletha [Kal19] uses another type of data to describe these regular supercuspidal Langlands parameters, which he calls regular supercuspidal -packet data. He identifies the set of equivalence classes of regular supercuspidal parameters with the set of equivalence classes of regular supercuspidal -packet data, which forms a category. We give a brief review of his construction.\nLet  be a maximal torus and  be a character. The pair  is called tame elliptic regular if is elliptic and splits over a tamely ramified extension .The action of  on the root systempreserves a positive set of roots.the character  has a trivial stabilizer for the action of , where  is a reductive group with maximal torus  and root system .\n[Kal19](Category of regular supercuspidal -packet data.)An object in the category consists of tuples\n, where is an elliptic torus defined over  such that  and  splits over a tamely ramified extension of . is an embedding of complex reductive groups whose  conjugacy class is -stable. is a minimally ramified -data for . is a character, such that  is a tame elliptic regular pair in the sense of Definition\u00a03.11.A morphism between  and  is a triple , where is an isomorphism of -tori inducing an isomorphism of complex torus ., such that . is a set of zeta data, that is, a family of characters , such that , and .\nBy Kaletha [Kal19, 5.1], a -stable  conjugacy class  of embeddings  defined over  determines a -stable  conjugacy class  of embeddings  defined over , and vice versa. Here, the structure of  to be a maximal torus of  is given by , which is determined by , and is not necessarily defined over . Elements in  are usually called admissible embeddings, and the subset of  fixed points in  corresponds to the subset of admissible embeddings defined over , which is non empty due to [Kot82, Corollary 2.2]. As remarked by Kaletha, if we choose a  invariant pinning  of , one can always choose  such that  is an isomorphism over , and pull back  via  to get a  invariant subset . Here the notion of tame regular elliptic pair makes sense if one uses the embedding  defined over  determined by . The notion of symmetric roots or asymmetric roots also makes sense with the help of .\nThere is a natural 1-1 correspondence between the -conjugacy classes of regular supercuspidal parameters and the isomorphism classes of regular supercuspidal -packet data.\nFor a given -packet datum  (equivalently a given regular supercuspidal Langlands parameter ), Kaletha also introduces another category to parameterize supercuspidal representations in the -packet , which he calls the category of regular supercuspidal data. The object in the category is formulated in terms of Kaletha\u2019s rigid inner twist of a quasi-split reductive group. Since Prasad\u2019s original conjecture is formulated in terms of pure inner twist, we only use the pure inner twist version of Kaletha\u2019s fomulation. For relationship between rigid inner form and pure inner form, one can refer to Kaletha\u2019s paper [Kal16].\n[Kal19](Category of regular supercuspidal data.)An object in the category consists of tuples\n, where is a regular supercuspidal -packet datum. is a pure inner twist of , that is  is an isomorphism over  and  is an admissible embedding defined over .A morphism between  and  is a tuple , where is an isomorphism of regular supercuspidal -packet datum. is an isomorphism of pure inner twist of , such that .\nNotice that, one has a natural forgetful functor from the category of regular supercuspidal data to the category of regular supercuspidal -packet data. In this way, the -packet  as a set is in bijection with a torsor under . In fact, one also wants to understand the construction of each member of a given regular supercuspidal -packet data. Kaletha [Kal19] constructs a generic cuspidal -datum from a tame elliptic regular pair, which produces a regular supercuspidal representation by Yu\u2019s construction [Yu01]. We will describe this explicit construction later in Section\u00a06.1.\nFrom a regular supercuspidal datum , one can construct a tame elliptic pair , where  is known as certain rectifying character arising in the earlier work of Debacker-Spice [DS18] and Kaletha [Kal15]. Then, one can run the process described in Section\u00a06.1 to get a regular supercuspidal representation  of  from this tame elliptic pair.\nMore precisely, the character  has the following explicit expression.\nwhere  and  denote the unique non-trivial quadratic character of the cyclic group  and , and  denotes the toral invariants defined in [Kal15].\nMore detailed descriptions of these characters will be given in Section\u00a08.2.1.\n3.4 Comparison of the -packet.\nNow we have two ways to parameterize the set  for a regular supercuspidal Langlands parameter . One is conjecturally given by , while the other one is given by a torsor under . Notice that the first parametrization depends on certain normalization of Whittaker datum, while the second parametrization depends on a base point of the set of equivalence classes of rational embeddings. According to the strong tempered -packet conjecture, there exists a unique  generic representation in a given tempered -packet for a fixed Whittaker datum . Hence, one may expect that a fixed Whittaker datum canonically and uniquely determines a base point inside the set of equivalence classes of -embeddings of abstract tori.\nNotice that for a toral regular supercuspidal representation  with regular supercuspidal -packet data , the following lemma due to Kaletha implies that there exists a canonical choice of rational embedding as a base point in a given -packet for any chosen Whittaker datum.\nFix a Whittaker datum  for  associated to a fixed pinning  defined over  and an additive character . Let  be a toral -packet datum of generic depth . There exists a unique (up to  conjugacy) admissible rational embedding , such that the representation corresponding to  is  generic.\nIn a recent preprint of [FKS21, Page 25], Lemma\u00a03.9 is generalized to arbitrary regular supercuspidal representations. After fixing the base point, then these two parameterizations coincide as a consequence of Kottwitz isomorphism for tori and the following lemma due to Kaletha.\nThe embedding  induces an isomorphism .\nUnder this isomorphism,  is isomorphic to  by the Kottwitz isormophism for tori. Fix a base point of -embedding , then  could be regarded as an element in  by , which we still denote by  for simplicity.\n3.5 Cohomological aspects of local Langlands correspondence.\nIn the study of functorial properties of Langlands parameters, it is often convenient for us to ignore the Frobenius semisimplicity condition and regard  as a subset ofNotice that there is a natural bijection:which provides a parametrization of the (enlarged) space of equivalence classes of Langlands parameters by  as a pointed set. In this way, many functorial maps between Langlands parameters could be described in terms of natural maps between non-abelian Galois cohomology.\n3.5.1 Functoriality.\nThe principle of Langlands functoriality provides evidence that there may exist a deep relation between representations of different reductive groups. In a simple word, the Langlands functoriality predicts the existence of certain transfer of representations whenever there exists a homomorphism between their -groups. More precisely, we assume that  is also a reductive group defined over , and there exists an algebraic homomorphism :For any Langlands parameter  of , we can get a Langlands parameter  of  by composing  with :\nwhich implies that  defines a map from the set of Langlands parameters of  to those of .\nNotice that  descents to a map from  to , hence defines a transfer from  to . In fact, if we ignore the Frobenious semisimplicity condition,  also defines a map:If there exists a -equivariant mapbetween complex dual groups, then one can easily extend this homomorphism to a homomorphism of -groups simply by:\nIn this case,  should coincide with  induced by the  equivariant map , which provides a Galois cohomological interpretation of the funtoriality. However, the map  is not -equivariant in general and the -homomorphism  is usually not an extension of a -equivariant . Nonetheless,  may still enjoy some nice cohomological properties as , which will be seen soon.\n3.5.2 Twisted by characters and taking central characters.\nNotice that the set of continuous characters of  inherits a natural structure of abelian group with group structure given by pointwise multiplication. In this case, we also have a parametrization of this set in terms of abelian Galois cohomology.\nThere is a natural map:which is a bijection when  is quasi-split.\nIn fact, there is a convenient description of the above map using hypercohomology of crossed modules. This has been described in detail in [Bor98], [Kal15] and [Lab08]. Let  be a crossed module. More precisely,  is a group homomorphism and  is endowed with an action of  such thatfor any . Notice that the second equation implies that  is abelian. Let  be a group acting on the crossed module such that the action is compatible with the crossed module structure, that isthen we have the following cohomology theory for crossed modules:where the hypercocycles  and hypercoboundaries  are defined by:Remark that we also adopt the notation in [Kal15] such that the degree in our definition is shifted by  from the usual degree in the cohomology theory of crossed modules. The reason is explained in [Kal15] for the compatibility between the cohomology of crossed module and hypercohomology of a complex concentrated in degree  and , when we take the crossed module to be a complex of tori.\nUsing the above notation, we have the following isomorphisms.\nThere are canonical isomorphisms:and\nThe map  and the map (on the parameter side) of taking the central character of an irreducible representation correspond to the following natural maps between Galois cohomology.\nThe map  is given by:The map of taking the central character is given by:\nFor , the map of taking the central character has a simple description. Notice that we have a short exact sequence of -modules:which means that we have a quasi isomorphism of crossed modules:and the following commutative diagram:Hence the map of taking the central charactercoincides with the map of taking determinant on the parameter side\nNotice that the set of continuous characters of  acts naturally on the set of equivalence classes of irreducible representations of  by character twists, that is, one has a natural actionwhich corresponds to the following action on the parameter side:such that  is given by .\nFixing an elliptic maximal torus , Kaletha\u2019s construction of regular supercuspidal representations in Section\u00a06.1 and his construction of local Langlands for regular supercuspidal representations could be regarded as a map\nFor any character  with  being regular elliptic, the following well known isomorphism between supercuspidal representations yields the compatibility of character twists and the construction of regular supercuspidal representationswhich corresponds to the commutativity of the diagram on the parameter side:\n4 Base change of regular supercuspidal -packet data\nBase change is one of the examples of Langlands functoriality. From the point of view of trace formula and harmonic analysis, the theory of base change could be understood as a special example of the theory of twisted endoscopy, which has been detailed studied in [KS99]. We will not go deep into the theory of twisted endoscopy, instead we only focus on the local counterpart of quadratic base change.\n4.1 Base change of Langlands parameters.\nLet  be a quadratic extension. For a Langlands parameter  of , a base change  of  is nothing but the composite of  with the functorial map:where the  action on  is given by:\nIn other words, BC induces natural maps:There is an alternative way to describe the base change map. Since  is defined over ,  is naturally a -group. Consider the following -group:with the group law induced from the one on . To be more precise, for any , one defines .\nThere is a natural  action on  given by right multiplication, which preserves the group law:Choosing any element , we could construct a -equivariant isomorphism:For any , we have:which implies that the isomorphism does not depend on the choice of , hence is canonical. Moreover, we have the following commutative diagram:where the -equivariant map  is defined by:By Shapiro\u2019s lemma for non-abelian Galois cohomology, we have:Hence  coincides with the restriction map, which means that  could be identified with the restriction .\nMany aspects in the theory of base change have Galois cohomological interpretations. It turns out that the following remark in Prasad\u2019s paper [Pra15], which describes the fiber of base change map, is quite useful in our work.\nPicking up a base point  associated to an irreducible representation  of , we can twist the action of the Weil group on  by , which means we can define a new  action on  by:such that  corresponds to the distinguished point in . One advantage of doing this is that we have an identification:If we assume there exists an extension , such that , then under this twisted action, the set of possible extensions of  to a parameter of  can be described by the inflation-restriction sequence:where  denotes the corresponding non-abelian Galois cohomology associated to the twisted  action.\nThe obstruction of extending the parameter of  to a parameter of  could also be read from this inflation restriction sequence. For example, the inflation restriction map implies the image of  lies in . Hence a necessary condition for  to be extendable to parameters of  is that it is -invariant.(The Galois action is given by conjugation of an element in ). In fact, this is not the only obstruction. For general Langlands parameters, the inflation restriction sequence terminates due to the lack of  for non abelian -groups. However, for regular supercuspidal representations,  is still meaningful due to the special isomorphism in Lemma\u00a03.10.\n4.2 Base change for regular supercuspidal -packet data.\nNow we use tuples  as Langlands parameters for regular supercuspidal representations of . We would like to describe the quadratic base change in terms of regular supercuspidal -packet data. For simplicity, we first focus on those regular supercuspidal -packet data whose base change to  remain regular supercuspidal.\nA quadratic base change of a supercuspidal -packet datum of  associated toto  is given by a supercuspidal -packet datum of , which is equivalent to:where  is a -data of , such that .\nThe above definition of base change map only depends on the equivalence class of the supercuspidal -packet datum. Let  denote the subcategory of the category of regular supercuspidal -packet data of  over  consisting of the objects whose base change (in the usual sense) to  remain regular supercuspidal, then  can be regarded as a functor from  to the category of regular supercuspidal -packet data of  over .\nIt is enough to treat the case when the -isomorphism of  is the identity map. General cases could be reduced to this case by composing the isomorphism over . Recall  and  are equivalent, if and only if:where  is a character  constructed from the zeta datum  (product of characters depending on whether the root is symmetric or asymmetric) determined by the ratio of  and .\nComposing both sides with , we need to prove the following identity in order to check the definition of base change is well-defined:We only need to check this identity for a fixed  orbit of , which will imply the whole identity by taking the product of components of these orbits.If the  orbit of  remains a single  orbit, then we have the following diagramorNotice that we have a correspondence of orbits when  is symmetric, andwhen  is asymmetric.Hence the identity which we want to prove in this case ( component of Equation\u00a04.3) is given byIn this case, we have . We also have the following commutative diagram:In this case, the symmetric property of  is the same over  and . Based on the commutativity of the above diagram and the fact , one has the following identity:Composing both sides with , we havewhere  and  are identity maps when  is asymmetric over  and , and are isomorphisms , , when  is symmetric over  and .If the  orbit of  breaks into two  orbits, that is  for , with projection , then we have the following cases:The symmetry of  is different over  and .The only possibility is that  is symmetric over , but asymmetric over . In this case, one can choose  to satisfy . In this case, we have  and the following diagramNotice that we have a correspondence of orbits Hence the identity which we want to prove in this case ( component of Equation\u00a04.3) is given byIn this case, we have the following commutative diagramthat is,Composing both sides with , we haveNotice that in this case we havewhich implies thatThe symmetry of  is the same over  and .In this case, we have  and the following diagram:orNotice that we have a correspondence of orbits when  is symmetric andwhen  is asymmetric.Hence the identity which we want to prove in this case ( component of Equation\u00a04.3) is given byIn this case, we have the following commutative diagramthat is, we haveComposing both sides with , we haveNotice that in this case, we havewhich implies that\u220e\nA base change of supercuspidal -packet datum sending  to  coincides with the usual base change of the Langlands parameter sending  to .\nBefore we give a proof of this proposition, we have the following remarks on the base change maps of regular supercuspidal parameters.\nOne bad news is that  may fail to be minimally ramified. However, one can still find a representative in the equivalence class with minimally ramified -data over  by adjusting the character as in Definition\u00a03.12. More precisely, one can find a 4-tuple  where  is the minimally ramified -data determined by  such that the tuple is equivalent to . The explicit relation between  and  is described later in Equation\u00a07.1.\nThe base change map in the usual sense  given by  is well-defined on the set of equivalence classes of all the Langlands parameters. However, for a discrete Langlands parameter  of a regular supercuspidal representation of ,  may not be a Langlands parameter of a regular supercuspidal representation of . Hence the base change of regular supercuspidal -packet datum is only meaningful when the datum after base change is still a regular supercuspidal parameter. Nonetheless, for a given regular supercuspidal parameter , if , then  is a regular supercuspidal parameter by Remark\u00a03.2.\nTo prove Proposition\u00a04.2, we need the following lemma.\nLet  be any gauge. The cocycle in  Equation\u00a03.7 satisfies \nThis is a direct consequence of [Kal19a, Proposition 5.15.3] by taking  to be  and  to be . This is also proved in [Sch21, Theorem 64].\n\u220e\nLet  denote the Langlands parameter of the regular supercuspidal representation associated to the tame elliptic pair . As described in Section\u00a03.2,  is of the form:Combining the above lemma with local Langlands correspondence for tori, we havewhich means the supercuspidal -packet datum associated to  is .\nIn other words, we have the following commutative diagram:\u220e\n5 Prasad\u2019s conjecture for Galois pairs\nWe give a brief review of Prasad\u2019s conjecture relating the distinction property of an irreducible admissible representation of  to the base change functorial property of its Langlands parameter and certain numerical invariants on both sides. Before going into details, we give a brief introduction to certain objects defined by Prasad. For more detailed description of these objects, one can refer to Prasad\u2019s original paper [Pra15]. Let  be a quasi-split reductive group defined over a non-archimedean local field  and  be a quadratic extension with a non-trivial Galois involution .\n5.1 The quasi-split -form  of .\nNotice that quasi-split -forms of  are classified by:Let  be the Chevalley involution, which is defined by Prasad [Pra19a] in the general case and Adams-Vogan [Ada14][AV16] independently in the archimedean case. It is a well-defined element in . If we consider the isomorphism:where  is the based root datum of , then the Chevalley involution  is nothing but the  map on , where  is the longest Weyl element.\nSince  is quasi-split, we can produce a splitting of the exact sequence over :by fixing a pinning  of  over , that is, we have a natural splitting:In this way, we get an automorphism  in  such that . Notice that the involution  does depend on the pinning we choose and a canonical choice of lift  with respect to the given pinning  has been explicitly described by Prasad [Pra19a, Definition 1, Example 1]. Fixing a Chevalley involution  whose image is  in , we get a quasi-split -form  of  defined by the element in , which sends  to .\nNotice that  is a quasi-split -form of , such that  as algebraic groups over . More precisely, we have the following description of -rational points of :where  is the canonical involution constructed in [Pra19a, Definition 1].\nLet  be a torus defined over , then there is an isomorphism between  and . In this case,  and we haveThe following cases of tori will be frequently used later:, then ., then ., for a quadratic extension  over , which is different from , then  for the quadratic extension  over , which is different from  and .\nThe complex dual group of  is equipped with a natural embedding  sending  to , which extends naturally to a homomorphism of -groups  sending  to . This functoriality realizes the base change of , which coincides with the one in Section\u00a04.1, except that we use isomorphisms  sending  to .\nWe have already seen that one of the necessary conditions for a Langlands parameter of  to be a functorial lift from a Langlands parameter of  is that the parameter is -invariant (the Galois action is the one associated to the pair ), which is well known in the following cases:\nIf  is the quasi-split unitary group, then  is the general linear group over . A Langlands parameter of  being -invariant with respect to  means . Since each -packet of  is a singleton, this simply means , that is,  is conjugate invariant.If  is the general linear group, then  is the quasi-split unitary group. Notice that the  action on  is the usual Galois action twisted by the Chavelley involution , where  denotes the matrix . In this case, a Langlands parameter of  being -invariant with respect to  means , that is, . This simply means , that is,  is conjugate self dual.In case 1, the conjugate invariant condition is also a sufficient condition for  being a base change lift from . However, in case 2, the conjugate self dual condition is not sufficient to determine whether  is a (stable) base change lift from . One needs further information, that is, the sign of the conjugate self dual representation to determine whether it is a (stable) base change or not.\n5.2 The quadratic character  associated to .\nLet  be the quadratic character of  associated to the quadratic extension  by the local class field theory. More precisely,  is given by the natural projection . Although there is a uniform description of this quadratic character in terms of local class field theory, it is still convenient for us to write down the following explicit description of this quadratic character depending on whether  is ramified or not. Notice that  could be described using the quadratic Hilbert symbol sending  to . More precisely,\nWhen  is unramified, we havewhere  is the normalized valuation on  such that .\nWhen  is ramified,  is chosen to be a uniformizer  of . Then we have\nPrasad\u2019s quadratic character  is given by the following Galois cohomological construction. Consider the short exact sequence of -groups:which leads to a long exact sequence:Notice that we also have a short exact sequencefor any maximal torus  of .\nBy the natural identificationtogether with Tate duality, we have a natural map:By Proposition\u00a03.11, we have a natural bijection:Moreover, we have the following commutative diagram:where the first vertical map is induced by the natural -equivariant morphism , and the second vertical map is given by the composition with the natural map .\nBy choosing a regular unipotent element  in , we have a map  by Jacobson-Morosov theorem. Notice that . Hence we have a map of -groups:which induces a map:The image of  under this map determines a quadratic character of  hence a quadratic character of  by the vertical map. This is exactly the quadratic character .\nNotice that the Cartier dual of the finite group scheme  over a -adic field is the constant group scheme . The corresponding Tate duality gives a perfect pairing:When , there is a natural isomorphism between  and  as trivial -modules, where the second isomorphism is given by exponential maps . Together with the isomorphism  induced by the Kummer sequenceit is convenient for us to use the following isomorphisms to parameterize the set of isomorphism classes of quadratic etale algebra over .\nFrom the bijection in Proposition\u00a03.11, it is easy to see that  is trivial if  is semisimple, simply connected, since  is adjoint so that  is trivial. Moreover, we have the following lemma describing the relationship between  and .\n\n\nLemma 5.4.\n\n\n\n\n\n\n\n\n\n\n\nIt follows from the constructions of  and , which are both constructed from a quadratic character of  and the following commutative diagram:\u220e\nAs explained by Prasad in his paper, this quadratic character is closely related to the half sum of positive root in the following manner. Let  be a quasi-split group over a local field  and  be a maximal torus of  over  contained in a Borel subgroup  over .\nLet  be the half sum of positive roots of , then . Then we have the following commutative diagramwhich gives an exact sequence of dual Galois modules\n\n\n\n\n\n\n\n\n\nHence the map , which defines Prasad\u2019s character viais the restriction of the map\nFor , the map  is given by:It is not hard to see that the principal  map induced by  is given by:such that the induced map on  is given by:For the quasi-split group  with  quadratic, the computation is similar except that the  action on  factors through , and is given byfor , which means that there is an identification .\nBy later computations in Lemma\u00a05.11 and Remark\u00a05.12, Prasad\u2019s character  is given by:where  denotes the isomorphism , and  denotes the trivial character if , and denotes the quadratic character associated to  if .\nIn fact, Prasad\u2019s character has been computed explicitly for many examples [Rap18][MO21]. The above examples are also computed explicitly in [MO21] in a slightly different way. We list some of them.\n: the quasi-split special orthogonal group,  is given by ,\nwhere  is the Spin norm given by the connecting homomorphism:associated to the short exact sequence of -groups:  is trivial, since  is simply connected.: the split special orthogonal group or the quasi-split but non split orthogonal group,  is trivial.\n5.3 The restriction of  to the elliptic maximal torus .\nNotice that the restriction of a character of  to  is a character of  for any maximal torus  of . Hence we have the following interpretation of restriction of characters of  to  in terms of Galois cohomology\nNotice that we have the following commutative diagram:which gives the following commutative diagram at the level of :Hence the image of  under the natural mapis the restriction of Prasad\u2019s character to .\nNotice that the local Langlands correspondence for tori could be regarded as an isomorphism of two functors from the category of tori over  to the category of abelian groups [Yu09] sending a torus  toHence it enjoys the following functorial property.\nLet  be a morphism of  tori, which induces a morphism of -modules . Then we have the following commutative diagram\nThe following functoriality is frequently used in the later computation.\nLet  be a finite Galois extension and  be a torus defined over . Let  be the natural embedding . Notice that one has a natural identificationsuch that  is given by the corestriction mapWe have the following commutative diagram:\nMoreover, if we apply Proposition\u00a05.7 to the case when  is a split maximal torus of  and  is a root of , we can get the following factorization of the restriction of Prasad\u2019s character to the split maximal torus.\nLet  be a split maximal torus of a split reductive group . We have the following identity:\nThis is a direct consequence of the functorial property of local Langlands for tori in Proposition\u00a05.7 and the explicit description of the map  in Equation\u00a05.1.\n\u220e\nIn fact, we can also obtain a similar factorization for the restriction of Prasad\u2019s quadratic character to an elliptic maximal torus  of . However, since there will be no Borel subgroup defined over  containing , we need to find certain replacement of the set of positive roots, which is given by a section of . In the case when  is a maximal torus contained in a Borel subgroup , both of which are defined over ,  could be regarded as a section of  determined by the . Let  be an arbitrary maximal torus of  defined over , one can choose a Borel subgroup  of  defined over  containing  such that  can be identified with  as a set, where the former set may have a non-trivial  action. Let  be the corresponding maximal torus in  such that . We have the following lemma due to Kottwitz [Kot83, Page 292].\nThe restriction of  to  is independent of the choice of , hence is defined over  and  is preserved by any automorphism of .\nHence the definition of Prasad\u2019s character also does not depend on the choice of section . Notice that  indeed inherits a  action given byfor any . We have the following identification:hence the following partition:where ,  and  stand for symmetric, asymmetric  orbits and asymmetric  orbits. This decomposition enables us to get a factorization of Prasad\u2019s character in terms of certain  orbits.\nBefore we give a general description of the restriction of Prasad\u2019s character to an elliptic maximal torus, we first prove the following lemma.\nLet  be any one dimensional torus defined over a non archimedean local field , consider the natural -equivariant inclusion  (embedding of  into ), which gives the natural map . Let  be a quadratic extension of , which is regarded as an element in . Then the image of  under the above map is the character of  given by the natural map .\nFirst we need to prove that the map  is indeed a character, that is,  could be embedded into . Notice that there are four kinds of one dimensional tori over a -adic field, when the residue characteristic is not :  and , where  are three quadratic extensions of . When  is , we have  by local class field theory. When  is , we have  by Hilbert , where  is given by . When  is  with  and , we have  and . Then we have the following identificationdue to the following isomorphism:The last isomorphism is due to the fact that the map  is trivial since .Since  acts on  trivially, we have the identificationThen the element  gives rise to a natural quadratic character of  which is trivial on the index two subgroup . Let  denote the image of  under the map . Then  is a cocycle which is trivial on . Under the local Langlands correspondence for tori,  corresponds to a character of  trivial on , which is the natural character .\u220e\nThe above quadratic character has a more convenient description in terms of quadratic characters of the splitting field of the one dimensional torus . Let  be a one dimensional torus over  with splitting field . There exists a natural embeddingwith a -equivariant morphism of dual torus given by the corestriction map in Equation\u00a05.3:Notice that we have a commutative diagramApplying the functor , we get a commutative diagram at the level of :By local Langlands correspondence for tori, the image of  is  for , where  is trivial if  is contained in , and the quadratic character associated to  if  and  are disjoint.\nIn fact, for any torus  of the form , where  is a one dimensional torus over , one can also construct the following map:The simplest example is when we take  to be . For disjoint  and , the image of  is the quadratic character . For , the image of  is trivial.\nNow we give a new interpretation of the restriction of Prasad\u2019s character to , where  is an elliptic maximal torus of . This interpretation is largely inspired by the work of Kaletha and Langlands Shelstad.\nThe following diagram of -modules is commutative:\nNotice that the  action on  is trivial. By Equation\u00a04.1, the natural map  sends  to the constant functions  on . For a  orbit  of a root , we have a natural identification . One can directly check the commutativity of the diagram by explicit computation:\u220e\nWe can apply the functor  to get a commutative diagram at the level of :Moreover, if  is symmetric, then we also have:\n is symmetric.Let  be the one dimensional anisotropic torus over  whose  points correspond to the norm-one elements of  with respect to . A  orbit of  induces a natural map . Then we consider the following diagram:One can define a character of  associated to  and the  orbit of  in the following way:sending  to , where  is the natural mapNotice that we have the following commutative diagram:where  denotes the isomorphism .\nHence we have is asymmetric.One can define a character of  associated to  and the  orbit of  in the following way:sending  to .Notice that by [Kal19a, Page 6], any root  gives a morphism , and summing over  orbit of  gives a morphism:defined over . (In fact these two morphisms are trivial on , hence define a morphism from  to  over , which is in fact trivial due to the ellipticity of .) This gives a morphism of dual toriNotice that the -mapfactors through the above map, which implies the character  factors throughHence the character is trivial.\nThe restriction of Prasad\u2019s character to an elliptic maximal torus  inherits the following factorization:\nNotice that the restriction of Prasad\u2019s character to  is given by the image of  under the following map:By Equation\u00a05.4, we haveNotice that each summand is defined over , hence we have the following factorization by Equation\u00a05.5 and Equation\u00a05.6:\u220e\nOne advantage of our formulation is that we can compute the restriction of Prasad\u2019s character to an elliptic torus  according to the property of absolute roots associated to .\nFor , computations in Example\u00a05.5 have already shown thatNow we give a reinterpretation of , where  is a maximal elliptic torus of  of the form  for a degree  extension . Since  is still an elliptic torus of , we know that . One can easily see that , which means that we haveIn this case we also have  for each root . Notice that each  orbit of roots has exactly  roots, hence the number of  orbits equals .\nHence we havewhich means thatBy Theorem\u00a05.15, we can deduce\n5.4 Prasad\u2019s conjecture for regular supercuspidal representations.\nAlthough Prasad makes his conjecture for an arbitrary irreducible admissible representation of  in a generic -packet, the conjecture has a simpler form for regular supercuspidal representations.\nFix a Whittaker datum  such that  satisfies , let  be a regular supercuspidal representation of  with Langlands-Vogan parameter , where  is the Langlands parameter of  and  is an irreducible representation of the component group . Let  be the quasi-split -form of  defined in Section\u00a05.1, and  be the quadratic character of  associated to  defined in Section\u00a05.2. Then we have the following identity:where the sum of RHS runs over all the Langlands parameters  such that , and  is the multiplicity of the trivial representation in the restriction of .\nNotice that we can simplify the parameter side of this identity based on the nice parametrization properties of regular supercuspidal representations, which will be described in detail in Section\u00a07.2.1.\nThe inflation restriction sequence Equation\u00a04.2 already implies that the set of possible extensions of  can be identified withNotice that under the twisted (by )  action, we have an identification . In fact, for a regular supercuspidal parameter , Lemma 5.3.4 in [Kal19] impliesHowever, there may exist different  structures on  (hence different  structure on ) such that  is , and we should count them all. If we fix an  structure on , then the set of possible extensions of  can be identified with the pointed setunder the above isomorphism. We will give a comparison between this and the one obtained from the naive base change in Remark\u00a07.5.\n6 Hakim-Murnaghan\u2019s formula for distinguished regular supercuspidal representations\n6.1 Yu\u2019s construction of tamely ramified supercuspidal representations.\nLet  be a reductive group over a nonarchimedean local field  of residual characteristic , such that it splits over a tamely ramified extension of . Yu develops a general method to construct tame supercuspidal representations of  using cuspidal data. We give a brief review of the construction here. For more details, one can refer to [Yu01],[HM08]. We fix an additive character  of conductor  for convenience.\nA generic cuspidal datum is a -tuple:where is a sequence of tamely ramified twisted Levi subgroups of , such that  is anisotropic. is a point in the enlarged Bruhat-Tits building of  and  denotes its image in the reduced building. is a sequence of real numbers, such that  if , and  if . is an irreducible representation of  such that  is -isotypic and  contains an inflation of a cuspidal representation of , and also - is irreducible.(The last condition is also equivalent to the condition that  is a depth-0 supercuspidal representation of .) is a sequence of quasi-characters  of  of depth , which are  generic in the sense of Yu. More precisely,  is trivial and there exists a  generic element  such that:for any , where  denotes the Moy-Prasad isomorphism:\nTo understand Yu\u2019s construction, we first need to understand the representation theory of abstract Heisenberg -groups and Yu\u2019s special isomorphism, which is crucial in the whole construction. Let  be a symplectic vector space over a finite field  such that , and  be the usual Heisenberg group associated to . More precisely,  is identified with  with multiplication given by\n[Yu01]\nA Heisenberg -group is an abstract group  which is isomorphic to a Heisenberg group  associated to a symplectic vector space  over .\nFor an abstract Heisenberg -group  with center , let  denote . The commutator map defines a symplectic form on :\nA special isomorphism on  is an isomorphism  such that the following diagram commutes:\nFix a non-trivial additive character , the Heisenberg Weil representation of  is the pull back of the usual Heisenberg Weil representation of  associated to .\nThe explicit construction of the tamely ramified supercuspidal representations [Yu01] could be described as follows.\nLet  be a maximal -split torus of ,  be an -torus containing  such that  is maximal -split, and  be the centralizer of  in . Since  is quasi-split over ,  is a maximal torus of  defined over  with maximal -split subtorus . Let  be the splitting field of  such that  is a tamely ramified extension. We have canonical inclusions of apartments:When  is quasi-split over , then  could be chosen to be the maximal torus , such that  determines the pinning of  over .\nFor an arbitrary maximal torus  defined over , which splits over a tamely ramified extension . We adopt the notation in [Yu01] and [HM08].\nLet  denote the intersectionin .\nSince  is tame, by Galois descent on Bruhat-Tits building, we have a natural identification:\nFix a cuspidal datum  such that  for a tamely ramified maximal torus , and set , Yu defines a family of subgroups of :These subgroups satisfy the following relations:Since  is of depth , hence is trivial on , so that  factors through a character of . We can get a character of  by inflation:Let  be the unique character of  such thatNotice that  has a natural structure of abstract Heisenberg group over the residue field, such that  has a natural structure of symplectic vector space over the residue field. There exists an irreducible representation  of , which corresponds to the Heisenberg representation via the special isomorphism such thatThe restriction of  to  is  isotypic.The restriction of  is  isotypic.It is also proved that  factors through the mapwhere  is the inflation of  to .\nLet  be the representation of  such that its inflation to  is . One can produce a sequence of representations  of  by inflation. More precisely, we have\n,  for , and .\nThen one can further produce a representation of  byBy [Yu01] and [Fin19], the representation - is irreducible, hence a supercuspidal representation of .\nAn important class of such representations are the so-called toral supercuspidal representations, that is, the representations with Yu data:where  is an elliptic maximal torus of  and  is a character of . As remarked by [Kal19], these representations are already general enough to include a class of supercuspidal representations called epipelegic representations, which is first constructed by Reeder and Yu [RY14] using stable vectors in geometric invariant theory. Later, Kaletha [Kal15] proved that their constructions could be recovered from Adler\u2019s construction [Adl98] when the residual characteristic  is good.\nBased on Yu\u2019s work, Kaletha provides a strategy to construct regular supercuspidal representations from a tame elliptic pair  satisfying certain regular conditions. We give a short review of his construction here. The key point to recover Yu\u2019s data from  is the following existence result of Howe factorization proved by Kaletha.\nLet  be the splitting field of , one can produce a sequence of Levi subsystem of  for a sequence of positive real numbers  and :\nSet , then one can define  to be the connected reductive subgroups of  with a maximal torus  and root system . We also set .\nA Howe factorization of  is a sequence of characters  for  such that. is trivial on . is of depth  is  generic. For ,  is the trivial character if , and has depth  if . For ,  is the trivial character if , and is a depth zero character if . In this case we usually denote it by  instead of .\nAny pair  consisting of a tame elliptic torus  and a character  has a Howe factorization .\nIf , then  is a maximally unramified elliptic maximal torus of  [Kal19, Definition 3.4.2], and  is a regular depth zero character such that  factors through . Let  denote the inflation of the irreducible Deligne-Lusztig cuspidal representation  of  to . Let  denote the canonical extension of  to  established by Kaletha with the help of  action on the corresponding Deligne-Lusztig variety. By [Kal19, Propositon 3.4.27],  could be chosen to be .\nHence, the above process associates a generic cuspidal datum  to . One can then get a regular tamely ramified supercuspidal representation of  from Yu\u2019s construction.\n6.2 Hakim-Murnaghan\u2019s formula.\nFor a tame supercuspidal representation  of  with a fixed Yu-datum, Hakim and Murnaghan [HM08] give a formula to describe the dimension of the space of  invariant linear forms on  for an involution  defined over . We can apply their machinery to the case when  is  and  is the -involution induced by  (also denoted by ).\nwhere  is certain multiplicity, and  is certain quadratic character of .\nMoreover, they also describe the relevant condition explicitly.(i.e. the condition of double coset or equivalently  such that .)\nFor toral supercuspidal representations, this formula could be even much simpler. More explicitly,  is a toral supercuspidal representation, where  and  is the representation of  attached to  through Yu\u2019s special isomorphism. For these representations, we have:\nRecently, Hakim [Hak18] transforms the relevant condition on  orbits of involutions to  orbits of involutions, that is, from double coset  to double coset  for regular supercuspidal representations, and gets a refined formula for these representations. Remark that the set of  orbits of involutions within a fixed  orbit of  can be identified with , where  is the stabilizer of  in , and it\u2019s clear that  contains  as a finite index subgroup. However, in our reinterpretation, we prefer to use the double coset  instead of  for certain reason, which also avoids the factor .\nThe following theorem (in a slightly different form) is proved by Hakim [Hak18] for regular supercuspidal representations:\nLet  be a regular supercuspidal representation of  attached to a tame regular elliptic pair , then we have:\nMore precisely, the quadratic character  has the following explicit description:In fact,  is indeed the quadratic character  in Equation\u00a06.3 given by , whereis a vector space over the residue field .\n6.3 Some facts about -adic tori.\nBefore we give a reinterpretation of the relevant condition on the set of  orbits in the  orbit of the Galois involution , we first review some basic facts about -adic tori.\n Conjugacy class.\nFor a connected quasi-split reductive group  defined over , let  be a fixed base maximal torus defined over .\nLet  and  be two maximal tori of  defined over . They are called rationally conjugate if they are conjugate by an element in . They are called stably conjugate if  and  are conjugate by an element in .\nWe have the following well-known parametrization of these conjugacy classes.\nThe set of rational conjugacy classes of maximal tori of  defined over  is in bijection with the pointed set .\nExplicitly, the bijection is given by:where  is a maximal torus of  such that .\nIn fact this identification can also be read from the long exact sequence associated to the short exact sequence of Galois pointed sets:where the set of rational conjugacy classes of maximal tori defined over  can be identified with the set . In fact, the variety  is known as the variety of maximal tori, whose rational points  parameterize the set of maximal tori of  defined over .\nThe set of stable conjugacy classes of maximal tori defined over  is in bijection with the pointed set  and there is a surjective mapwith each fiber consisting of the set of rational conjugacy classes of maximal tori inside a stable conjugacy class of maximal tori.\nNow we fix a cocycle  with . Let  be the -torus corresponding to  (regarded as an element in  by the natural map ). Notice we have an -isomorphism , where  lies in , such that  projects to . Hence we have an embedding of  into  for any choice of , such that  is a maximal torus of .\nBy the short exact sequence of -groups:we have a long exact sequencehence also a long exact sequence\nNotice we have natural isomorphisms:which means  as a set.\nMoreover, in [Re11, Section 6.2] Reeder also constructs an affine action of  onsuch that the long exact sequence gives a bijection between the set of rational conjugacy classes of maximal torus in  and the set of  orbits in .\n Rational Embeddings.\nFix a stable conjugacy class of maximal tori , there is another interpretation of the set:\nThis set parametrizes rational equivalence classes of -embeddings of a maximal torus  into , that is(two embeddings  and  are equivalent if there exists some  such that )\nIf we write  for some , we not only have  (this is the condition for  to be defined over ), but also have  for any  and any (this is the condition for  to be defined over , that is ), which means .\n\u220e\nIn the above lemma, we have already assumed that  is a maximal torus of , which means that we have already chosen a base point of an -embedding of the underlying abstract torus of  to . Moreover, if  is an abstract torus with a fixed  conjugacy class of an embedding  such that  is a maximal torus of , then the set of  is a torsor under  by sending  to  for  such that .\nNotice that the setparameterizes all the  equivalence classes of possible embeddings of maximal torus into . More precisely, this set is in bijection with the set of equivalence classes of the pairs  where  is an -torus with  and  is a  equivalence class of -embeddings.  is equivalent to  if and only if  and there exists  such that .\nIf  is an elliptic maximal torus of , then  is surjective.\nBased on this lemma, we can see that the pointed set  with  being an elliptic maximal torus of  can be identified with the set of rational conjugacy classes of -embeddings of  into all pure inner forms  of  for . For a regular supercuspidal parameter , we have already seen in Section\u00a03.4 that there is a bijection:What\u2019s more, we also have the following refined bijiection:\n6.4 Reinterpretation of the indexing set appearing in Hakim-Murnaghan\u2019s formula.\nLet  denote the  orbit of the Galois involution . For a regular supercuspidal representation  associated to  with  elliptic torus over  such that  and  is maximal torus of , the relevant condition for  being distinguished becomes that  is stable under  for some  by [Hak18]. Notice that this condition is equivalent to the condition , which means  is defined over . Let  denote this -torus, and we have  as locally compact topological groups.\nThere is a bijection between the relevant double cosetand the set , where  is defined to be:Let  be a fixed base point of an embedding of an abstract torus  to  over . Then  could be regarded as an element of  via the map . Furthermore, if  is fixed as the base point in , this set can also be identified with the set:\nNotice that  is -stable hence defined over  with . We partition the relevant double coset according to the isomorphism class of the -structure of . The bijection is given by sending  to  such that . It is clear from definition that  only depends on  and that . It is also direct to check this map is indeed a bijection. The second statement follows from Propostion (6.7), Lemma (6.9) and the following commutative diagram for elliptic torus, which is due to snake lemma:where  is the short notation for .\n\u220e\nWe can also consider the above BC map for pure inner forms  with  and these maps can be glued to a map:which coincides with the usual restriction map:Moreover we have:\nIn fact, if we choose  to be the base point in , there is a natural identification:\nIn terms of this interpretation, Hakim-Murnaghan\u2019s formula becomes:\n6.5 -extension and a reduction step.\nSince we are dealing with the distinction problem with respect to a specific quadratic character which may be nontrivial, we can\u2019t apply Hakim-Murnaghan\u2019s formula directly. An obstruction is that  could not always be extended to be a character of . To deal with this issue, we take consideration of the -extension of .\nLet  be a connected reductive group over . A -extension of  is a central extension  of :such that is a connected reductive group over  whose derived subgroup is simply connected. is an induced torus, that is,  is isomorphic to a finite product  for finite extensions .\nFor any reductive group  over a field of characteristic , a -extension always exists.\nTaking the long exact sequence of Galois cohomology associted to the short exact sequence of -groups, we have:By Shapiro\u2019s lemma, we have isomorphisms:which implies that .\nIn this way, we can treat an irreducible representation of  as an irreducible representation of , which  acts on trivially. In particular, Prasad\u2019s character  is indeed a quadratic character of .\n, as a quadratic character of , can be extended to a quadratic character of  for any -extension  of .\nWe first prove that  regarded as a character of  is the same as . Notice that we have a following commutative diagram:which leads to the following commutative diagram:The commutativity of the above diagram implies that  as a character of . By Lemma (5.4),  coincides with , which is trivial since  is simply connected. This simply means that  is a character of .Notice that we have a second exact sequence of -groups:where  denotes the derived subgroup of  and  denotes the cocenter of , which is a torus defined over .Taking the long exact sequence of Galois cohomology, we have:since  is simply connected. This provides an identification between  and . Since  is a subgroup of the locally compact abelian group ,  as a character of  could be always extended to be a character of , hence a quadratic character of .\n\u220e\nLet  be an extension of  to . Now we review the relationship between representation theory of  and . Notice that we have a natural map:by regarding an irreducible representation of  as an irreducible representation of , on which  acts trivially.\nLet  be a regular supercuspidal representation of  constructed from a tame regular elliptic pair , the image of  under this map is the regular supercuspidal representation of  attached to , where  is the preimage of  in  and  is the pull back of  along . We have the following commutative diagram:\nTaking long exact sequence of Galois cohomology, we have the following commutative diagram:\nSince  is an induced torus, we know that  and . By the snake lemma, we have an isomorphism:\nIf we fix a stable conjugacy class of an elliptic torus  in , then we have a bijection:Moreover, there is a bijection:since any -embedding  into , whose base change to  is , canonically determines an -embedding  whose base change to  is  and vice versa. Hence we have\n7 Proof of the theorem under 7.9\n7.1 Torus case.\nWe start with Prasad\u2019s conjecture for torus . This has already been treated in Prasad\u2019s paper [Pra15], and we give a brief review of the torus case here. Notice that  is trivial, hence for any  which may be nontrivial,  is identified with . From the construction of , we know that it is in fact constructed from a character of , hence is trivial in the torus case.\nLet  be a character of . The left hand side of Prasad\u2019s conjecture gives\nBy Example\u00a05.1,  is a -torus, whose -rational points are given byFrom the long exact sequence associated to the short exact sequence of -groups:we haveApplying the exact functor  of taking the Pontryagin dual, we can see that a character  of  is distinguished by  if and only if it is a base change of a character of  that is  where  is a character of  and  is the norm map associated to  given by  Hence we haveNotice that the set of possible extensions of the parameter of  (if not empty) can identified with the set . The right hand side of Prasad\u2019s conjecture reads:In fact, by local Langlands for tori and the exact sequencewe can already see that the number of base change lifts of  from  (if not ) equals the cardinality of\nNow we give a direct proof based on Galois cohomology. For the exact sequence of algebraic groups over :we have a dual exact sequence of -modulesBy combining a result of Kottwitz [Kot84, Corollary 2.3] and Shapiro\u2019s lemma, we have the following long exact sequence:which leads to an isomorphism:where the map  is induced by the corestriction map. Since  is dense in ,  for any Galois module . Hence we have the commutative diagram:Notice we have isomorphismsNotice that for a homomorphism of abelian groups , there is a natural identification . As a corollary, we have , which implies the equality\nNow we try to reduce the proof of Prasad\u2019s conjecture for regular supercuspidal representations to the case of torus.\n7.2 Regular supercuspidal case.\nWe first summarize Kaletha\u2019s construction of an -packet associated to a regular supercuspidal -packet datum in a few words.\nFix a regular supercuspidal -packet datum  of  such that  is the minimally ramified -datum determined by , the Vogan -packet associated to this Langlands parameter consists of representations:where  runs over the set of  conjugacy classes of embeddings of  into  over  for any , and the representation  is the one constructed from Yu\u2019s generic cuspidal datum associted to the tame elliptic pair in Section\u00a06.1.\nLet  be a regular supercuspidal representation associated to a regular supercuspidal datum , where  is an admissible embedding of  to  defined over . Now we give an explicit computation of LHS and RHS of Equation\u00a05.7. Notice the tame elliptic regular pair associated to this regular supercuspidal datum is . We also need the following generalization of Lemma\u00a03.9 to fix a base point in a given regular supercuspidal -packet.\nFor any Whittaker datum  for , there is a unique admissible embedding (up to  conjugacy)  such that the regular supercuspidal representation corresponding to  is -generic.\nIf the Whittaker datum  is chosen to satisfy Prasad\u2019s condition , then base point of embedding  is defined over .\nBy Lemma\u00a0A.11, the condition  is equivalent to the condition . Let  be the generic semisimple element associated to the character . Since we also assume the -parameter of  is a base change lift from one of , we have . By [Kal19, Lemma 6.2.2] [FKS21], the unique embedding (up to  conjugacy)  such that  is  generic is characterized by the condition that\nthe  conjugacy class of  meets the Kostant section of . More precisely, there exists  such that . To prove  is defined over , we need to verifyLet  denote , then we have . Notice that the facts  and  imply thatBy the uniqueness of the characterization, we have , that is,  is defined over .\n\u220e\nWe shall henceforth fix a Whittaker datum  satisfying Prasad\u2019s condition and use  in Proposition\u00a07.2 as a base point to fix the bijection:\n7.2.1 RHS of Equation\u00a05.7.\nNow we try to compute the RHS of Prasad\u2019s conjecture in Equation\u00a05.7 explicitly for regular supercuspidal representations in terms of their supercuspidal data. Notice that  plays the role of a character of component group  associated to .\nTo find an extension of a parameter  to a parameter  is equivalent to find a regular supercuspidal -packet datum  of , where  is an elliptic maximal torus of  defined over  and  is a character of  such thatThis is equivalent to the condition that there exists an abstract isomorphism of  tori:where the norm  is the composite of  and the norm map on  sending  to . We take this abstract isomorphism  as part of our initial data.\nSince  is tamely ramified, we know that . Then the second condition becomes\nA priori, it seems that the character  produced by -data depends on the character . However, the computations in Section\u00a08.4 imply that this character does not depend on , but only depends on .\nNotice that for a supercuspidal parameter , Lemma 5.3.1 in [Kal19] implies\nThe parameter side of Prasad\u2019s conjecture in Equation\u00a05.7 then becomes:where the notation  means that we fix an abstract isomorphism  of abstract tori over .\nThe  of Equation\u00a05.7 is given by:\nWe give an explicit computation of each term appearing inBy local Langlands correspondence for tori,\n We also have a commutative diagram:Hence for , the setcan be identified with a torsor for .Fix a Whittaker datum  satisfying Prasad\u2019s condition, which determines a base point  of the set of equivalence classes of rational embeddings of  to . By Proposition\u00a07.2,  is in fact defined over , and the representation  has the label  such that , which we still denote by  for simplicity. Consider the following correspondence established in Theorem\u00a07.1:The condition  (hence must be ) is equivalent to the condition\n. We also have a commutative diagramwhere the horizontal arrows are given by Kottwitz isomorphisms. Hence the condition  is equivalent to the condition By the above two interpretations of the formula, we prove that the  of Equation\u00a05.7 is given by\u220e\nComparing the number of base change lifting of supercuspidal -packet datum with the one given by inflation and restriction sequence Equation\u00a04.2, it seems that the extension of the character part of the datum is already parametrized by . In fact, the regularity condition of the character  seems to pose some constraints on the set of pair  whose base change over  is . One natural question is whether  could be a base change of  and  simultaneously such that the -structure of  and  are different. We can even see this in the following example of :Let T be an elliptic maximal torus of  over  and  be a regular character of . Then  can be identified with norm  elements inside a quadratic extension . A necessary condition for the existence of an elliptic maximal torus of  whose base change equals to  is that  is a biquadratic extension. Let  and  be the other  intermediate fields between  and . Let  denote the non-trivial involution. Then  can not be a base change of  and  with  simultaneously.If  comes from two elliptic torus  and  over  with , then there exist characters  such that  for any . A immediate consequence is that , which implies . This contradicts with the regular condition, since we have a natural identification: \n\u220eLater we will see that the same phenomenon happens on the representation side. More precisely, the regular condition may pose the condition that  can not be distinguished with respect to  and  with  simultaneously. Since these conditions are equivalent as a simple consequence of local Langlands correspondence for tori, we do not need to exclude these possibilities to prove Prasad\u2019s identity.\n7.2.2 LHS of Equation\u00a05.7.\nFor , we have a -extension of  depending on . Let  denote the -extension for . Summing these dimensions over -pure inner forms  of  which are trivial over , we have the following identity:\n\n\nProposition 7.8.\n\n\n\n\n\n\n\n\n\n\n\nWe have the following equalities of charactersfor any reductive group  whose derived subgroup is simply connected.\nIf we assume 7.9, then the proof is a direct consequence of the proof of torus case and the following comparison of Proposition(7.4) and Proposition(7.8):\nThe conditions in Proposition\u00a07.4 and Proposition(7.8) are the same.\nA stable conjugacy class of a maximal torus  of  uniquely determines a stable conjugacy class of maximal torus  of , and vice versa. By the long exact sequence associated to the short exact sequence of -groups:we haveTaking the Pontryagin dual of the above exact sequence, we can see  if and only if By the long exact sequence associated to the short exact sequence of -tori:we have \n\u220e\nPrasad\u2019s conjecture 5.17 is true for regular supercuspidal representations if and only if Conjecture 7.9 is true.\n8 Comparison of various characters\nTo prove 7.9, we need to detect the relation between the following four quadratic characters: , ,  and , where  appears in [HM08] for the computation the dimension of invariant forms,  is the restriction of Prasad\u2019s quadratic character to ,  is the the rectifying character, which is used to construct regular supercuspidal representations from  in [Kal19], and  is the character of  associated to the -data, which measures the difference of two different -data. The proof of Conjecture 7.9 is not completely done in this article, we manage to prove Conjecture 7.9 for some particular examples, and when  is unramified. A priori, it is hard to imagine there is any relation between these characters, since the constructions of these characters are of different nature. In fact, these characters are quite mysterious, and of independent interest themselves. Certain deep arithmetic hides behind these characters. We give a short summary of these characters.\nThe motivation of Prasad\u2019s character is to detect the sign of a conjugate self dual representation. More precisely, for the case of , the representations distinguished by the trivial character are conjugate orthogonal, and the ones distinguished by Prasad\u2019s character are conjugate symplectic. Hakim\u2019s character consists of two parts, both appearing in the computation of the dimension of the linear form. The first part of Hakim\u2019s character origins from different choices of Yu\u2019s special isomorphism in his construction of tame supercuspidal representations. The second part of Hakim\u2019s character appears in the depth zero part, which follows from Lusztig\u2019s work on the computation of the dimension of linear forms for finite groups of Lie type. Kaletha\u2019s character naturally appears in the construction of local Langlands for regular supercuspidal representations, which aims to produce the correct character identity based on the work of Adler, Debacker and Spice [AS09] [DS18]. The character  appears naturally measuring the difference of the base point of -embedding given by different tamely ramified -data determined by the characters of the torus. We will give a description, and sometimes a reinterpretation of these characters in detail.\nWe first recall the explicit expressions of these characters.\n Hakim-Murnaghan\u2019s character of .where \nis a vector space over the residue field .\n Kaletha\u2019s character of .\nwhere  is the toral invariant defined by Kaletha. More precisely, it is given by:where  denotes ,  denotes a nonzero element in ,  is a quadratic extension with , and  denotes the quadratic character  associated to  by local class field theory.\nIn the next few subsections, we are going to compute these characters explicitly taking into consideration of the distinction problem. For convenience, let  be a maximal torus of , and  be a maximal torus of  such that  is  conjugate to  instead of writing  and  for abstract tori  and embeddings .\nConjecture 7.9 is true when  is unramified.\nConjecture 7.9 is true for ,, ( odd) and  ( odd) for arbitrary quadratic extension .\n8.1 Prasad\u2019s character.\nBy Theorem\u00a05.15, we have the following factorization of Prasad\u2019s quadratic character:\n8.2 Kaletha\u2019s character.\nKaletha\u2019s character is given by:\nNow,  is a maximal torus of . Notice that we care about the situation when  is a base change of a maximal torus  of  over . Then we can identify the absolute character groups .\n8.2.1 Toral invariant.\nIn [Kal19], he gives a characterization of the toral invariant in terms of the Kottwitz sign of certain absolute rank  group. Now we describe his formulation.\nFor a symmetric root  over , let  denote the subgroup of  generated by the root subgroups for  and .\nWe know that  is defined over , and a semisimple group of absolute rank . If we assume  being simply connected, then the toral invariant could be understood as the Kottwitz sign of .\nwhere  is a division algebra over  and  denotes the Kottwitz sign [Kot83].\nThis is essentially proved by Kaletha. Notice that one has a decomposition of Lie algebrasuch that  is the Lie algebra of a one dimensional anisotropic torus  defined over , which splits over . Since  is simply connected, semisimple of rank  over , we know  must be an inner form of  over . From the definition of the toral invariant , we can see that . Hence the computation reduces to a computation of toral invariant of absolute rank one semisimple simply connected group. Notice that  is  by [Kal19, Lemma 4.5.3, Page 57]. By [Kal15, Proposition 4.3], we have the following formula for an inner twist  with its restriction to be an -isomorphism :We apply this formula to the case of absolute rank one group over , and get\n.In fact, we can write down a direct computation for  and  uniformly.Let  for . Let  be a quaternion algebra over , which possibly splits. Then  could be embedded into  such that  as a (right) -vector space could be written as  for  with multiplication satisfying . Then the quaternion algebra is determined by the Hilbert symbol .\nNotice that the left multiplication of  on  is  linear since  is a right  vector space. By choosing a basis  over  , one can embed  to  sending  to . Notice that  is the fixed point of  of the following involutionwhich defines the action of . Over , the adjoint action of  is given by . We can choose\n, then  and , which implies . Hence we have\u220e\nNotice that we only care about the case that  is a base change of a torus  over , and  is defined over  for the purpose of distinction. It is clear from the definition that  must be symmetric over  if it is symmetric over .If , that is,  and  are both quadratic extensions, then  is also a base change of a rank one group over . Since  splits over any quadratic extension, in particular, over , we know that .If , then the  orbit of  breaks into two  orbits:  and  for . Then we can put the toral invariant of  and that of  together, and get\n8.2.2 Explicit computation.\nWe try to compute the quadratic character  explicitly. Notice that Kaletha\u2019s character is given by a product of characters over  orbits of roots, we will deal with the component of a fixed  orbit at each time.\n is asymmetric over , then  is automatically asymmetric over , that is  and . We have two cases:The  orbit of  becomes two  orbits. In this case .Let  and  be the two  orbits, both of which contribute to the character. We can put  component and  component of Kaletha\u2019s character together. More precisely, for , that is, , we haveThe  orbit of  remains one  orbit. In this case .If  is unramified,  must be unramified.Since  is unramified, we have  for . Let  be the generator of the cyclic group , that is,Then we have:since , which means that every element in  is a square in . Hence the restriction of the character  to  is trivial.If  is ramified,  could be ramified or unramified. If it is unramified, the character is trivial by the same reason. If it is ramified, the quadratic character is given by , where  denotes the non-trivial quadratic character of . is symmetric unramified over , that is  is unramified quadratic.The  orbit of  becomes two  orbits, that is . Notice we have is asymmetric over , that is  and  is unramified quadratic.In this case, one has two  orbits. Notice that we can choose a lift  of  such that , and we only need to compute the contribution of  or  in the asymmetric case. Hence the quadratic character is given by .Since  is symmetric unramified over  in this case, we have  lies in . Similarly, let  be the generator of the cyclic group , that is,Then we havesince , which means that every element in  is a square in . Hence the restriction of the character  to  is trivial. is symmetric (necessarily unramified) over , that is  unramified quadratic extension with .In this case, one has two  orbits  and , both of which are symmetric over . We can put  component and  component of Kaletha\u2019s character together. For , that is, , we haveThe  orbit of  remains one  orbit, that is  is a quadratic extension. In this case, both  and  are unramified quadratic. Notice that we have , hence , which means  is a biquadratic extension of .In this case  is unramified and  are all ramified. Hence  is symmetric unramified over . The quadratic character is given by . is symmetric ramified over , that is  is ramified quadratic.The  orbit of  becomes two  orbits, that is . Notice we have is asymmetric over , that is  and  is ramified quadratic.In this case, one has two  orbits. Notice that  and we only need to compute the contribution of  or  in the asymmetric case. Hence the quadratic character is given by . is symmetric (necessarily ramified) over , that is  ramified quadratic extension with .In this case, one has two  orbits  and , both of which are symmetric over . We can put  component and  component of Kaletha\u2019s character together. The quadratic character is given by the toral invariant.The  orbit of  remains one  orbit, that is,  is a quadratic extension. In this case, both  quadratic and  is ramified quadratic. By the same reason  is biquadratic over  and  is unramified. is unramified. Then we have  is unramified and  is ramified, which means that  is symmetric ramified over . Hence the character is given by . is ramified,  could be unramified or ramified. is unramified, and  is biquadratic. Hence  is symmetric ramified over  and the character is given by . is ramified, and  is biquadratic. Then  is unramified, that is,  is symmetric unramified over . Hence for , the character is given by .\n8.3 Hakim\u2019s character.\nAccording to [Hak18, 3.2], Hakim\u2019s character is given by:where  is a quadratic character given by \nBefore we give a new interpretation of Hakim\u2019s character, we first list some properties of Hakim\u2019s character. These properties are mainly proved by Hakim [Hak17] [Hak18] and Zhang [Zha20a] [Zha20b].\n\nThe proof depends on the algebraic nature of this quadratic character, which means that it is the restriction of a algebraic quadratic character of , and the fact that one has a decomposition .\n factors through , where the latter is the Lusztig quadratic character defined by:where  is the sign defined by Lusztig, which is  for any reductive group  defined over .\nLet  be any  involution of  preserving . Lusztig\u2019s quadratic character has the following factorizationwhere  denotes .\nFor Galois pair,  is always trivial.\n8.3.1 A new interpretation of \nNotice that \nis a vector space over the residue field . We rewrite  as a direct sum over  orbits of roots appearing in .\n\n\n\n\n\n\n\n(8.1)\n\n\n\n\nNotice that we have isomorphisms of  vector spaces:The adjoint action of  becomes multiplication of  under this identification and the determinant is given by the norm . If we have , that is  is a jump, then  is given by , otherwise  is trivial.If  is asymmetric over , we could put the character associated to  and the character associated to  together. Notice that one has  by [DS18, Corollary 3.18], and the character is unchanged if one replaces  by . The number of  orbits of asymmetric roots is even with the same jump condition for  and . Hence the product of  over asymmetric roots is trivial.If  is symmetric over . Then the determinant of the action is given by .When  is unramified, this character is trivial sinceWhen  is ramified, this character is given by\n8.4 The character associated to -data.\n8.4.1 Relation between  and .\nNotice that , as an element of absolute root system , is the same as , but carries a twisted Galois action. More precisely, the Galois action on  could be descried as follows.\nFor any , whose projection to  is trivial,For any , whose projection is ,where  denotes the original action on , and  denotes the twisted action.\nLet  denote the subfield of  which corresponds to  under this  action, which we denote by .\n.\nWe only need to prove that . For any , we havewhich means that . The reverse direction is similar.\n\u220e\nIf  is a quadratic extension of  and  with , then  is the other intermediate field of the biquadratic extension  over .\nLet  and  be the two non-trivial elements. We havewhich impliesHence  is the third intermediate field of  corresponding to the order two element .\n\u220e\nIf  and  is both symmetric over  and . Then \nNotice that  is symmetric over , hence it is necessarily symmetric over . Hence we havewhich means that .\n\u220e\nIf  and  is symmetric over  but asymmetric over . Then .\nNotice that we have  and  over  is quadratic. Furthermore, we know  since  action on  is non-trivial. Hence , which means that  is asymmetric over .\n\u220e\n8.4.2 Explicit computation.\nThe  orbit of  remains a single  orbit.The symmetry of  is necessarily the same over  and .Symmetric case is symmetric ramified both over  and .In this case,  is also symmetric over  since  is symmetric over . Then  is a biquadratic extension of  with three intermediate fields . We have the following diagram:Under the isomorphism ,  is the trivial character on\n, the unique non-trivial character on , and is determined by its value at . Notice that  is the trivial character on , the unique non-trivial character on , and is also determined by its value at  by the surjectivity oftogether with the factThis means that  is also tamely ramified over . Hence  is trivial on , and is determined by the difference of these two -data. To compare these two -data at the symmetric ramified root  over , one only needs to evaluate the two character at  for certain mod--data over .Let  be the -data corresponding to a character , then  is also the -data corresponding to the character .This follows from the following direct computation.\u220eApply the above proposition, we know that  is given by  on . According to Bushnell and Henniart [BH05, 1.5.2], for inclusions  such that  is a biquadratic extension, we have a formula:Hence we have:which impliesBy [BH05, Lemma 1.5], for any unramified extension  of degree , . Hence , which means it is the unramified quadratic character of  associated to the unique unramified extension , which means that  is the unramified quadratic character .Hence, the  component of  is given by: is symmetric unramified over  and symmetric ramified over .\nWe have the following diagram:where  is the unramified extension of , and  is the tamely ramified -data determined by the mod  data. Notice that we haveSince  is ramified, hence we have  mod . By the fact that  is an unramified character and , we know that  is trivial. Hence we only need to compute  explicitly. is .Notice that we have  by the definition of -data, which impliesby considering the diagram:\u220eHence the  component of  is given by: is symmetric unramified both over  and .We have the following diagram:Notice that we haveby considering the diagramHence, the  component of  is given by:Asymmetric caseIf  is asymmetric both over  and . Then we have:Hence, the  component of  is given by:The  orbit of  breaks into two  orbitsThe symmetry of  is the same over  and .We have the following diagramsororNotice that the equalities  and  imply . Hence the  component of  is trivial in all these three cases.The symmetry of  is different over  and .We have the following diagrams:Notice that  since  is asymmetric over . The  component of  is given byFurthermore, we have  and  is unramified, hence the  component of  is trivial.Notice that  since  is asymmetric over . The  component of  is given bywhere  is a tamely ramified -data, which is the unique nontrivial quadratic character on  and determined by mod--data. Notice that , hence the  component of  is given by\n8.5 Tables.\nWe list tables describing the contributions of each type of roots to these four quadratic characters.\n8.6  unramified case.\nIn particular, we can use our methods to deal with all cases such that  is unramified. The unramified assumption enables us to prove many components of these characters are trivial due to some arithmetic reasons.\nPrasad\u2019s conjecture 5.17 holds for regular supercuspidal representations when  is unramified.\nPrasad\u2019s character.\nNotice that we have the following factorization of Prasad\u2019s character:for any .\nWhen  is contained in , then  is trivial.\nWhen  and  are disjoint, then . Hence the only non-trivial term is the following case:In this case,  is a biquadratic extension of . Since  is unramified, both  and  are also unramified, which means  is symmetric ramified over  and .\nHence, Prasad\u2019s character could be simplified by:\nKaletha\u2019s character.\nBy Table\u00a02, we have the following description of the character .\nIf  is unramified, we have\nHakim\u2019s character.\nNotice that  consists of two partswhere  has the following factorizationby Section\u00a08.3.1.\nNotice that  is trivial for any Galois involution by [Zha20a, Corollary 3.18], which means that\nHowever, we can not detect more information of this character from this expression. Luckily, when  is unramified,  is trivial by a result of Zhang [Zha20b, Proposition 4.1]. His proof relies on the existence of depth zero good element of trace zero, which is only available when  is unramified. In fact, his argument is global in nature which means that he constructs an  symplectic structure preserved by the adjoint action of , instead of analyzing a fixed root component of Hakim-Murnaghan\u2019s character. His method is somehow complementary to ours. Hence when  is unramified, we have:\nThe character associated to -data.\nBy Table\u00a04, we have the following description of the character of  associated to -data.\nIf  is unramified, the character is simply given by:\n\n\n\n\n\n\n\n\n\nSummarizing the above computation, we haveIn this case, both  and  are symmetric ramified over , and the above computation implies Conjecture 7.9 is true when  is unramified.\n\u220e\n8.7 Examples.\nIn this section, we apply our method to various examples and give a new proof of Prasad\u2019s conjecture for regular supercuspidal representations of these groups. Although most of these results are not new, our method is still somehow illuminating.\nPrasad\u2019s conjecture 5.17 holds for regular supercuspidal representations of ,, ( odd) and  ( odd).\n8.7.1 Example of .\nIn the case of , Prasad\u2019s character is trivial since  is simply connected and perfect. Hakim\u2019s character is also trivial since  is always a square. In fact, we can list all the possible cases of regular toral supercuspidal representations here. We also provide a comparison between our new interpretation of Hakim\u2019s character in Equation\u00a08.1 and the original one given by taking determinant of the adjoint action.\nLet ,  with . Let , so that we have the following biquadratic extension: can be embedded into  in the following two ways:..These two embeddings are -equivalent. More precisely,  maps  to . However, the intersection with  of these two elliptic maximal tori are different:Hence it indeed happens that there are different  structures of , which means that the sum over abstract torus with different -structure in our formula is not trivial a priori.Let  be the split maximal torus of  over  with  consisting of diagonal matrices. Let  be the anisotropic maximal torus of  over  with , together with an embedding (there are two rational conjugacy classes of  embeddings of  into ) given by:Let  (In fact we can even choose an element , here we use  for simplicity). Then we havethat is, .Let  be the apartment associated to  of the building , we have identificationsSince  is split,  acts trivially on  andNotice that  and  are related by . By the -equivariant property of the Bruhat-Tits building , we have:The condition  implies that  is the origin  of . Hence we have , which is a point in .Now we restrict ourselves to the toral case (every tame supercuspidal representation of  is of depth zero or toral), that is, the twisted Levi sequence is , we describe the group  and  explicitly. Such computations have essentially been done by Hakim and Lansky in [HL10].Let  be the depth of the generic element  over , which corresponds to  via . We fix a valuation  on  such that . Let , the valuation of  forces the conditionWe have:where .\nLet  denote the symplectic vector space over , where the Moy-Prasad isomorphism between  and  is realized by Caylay transform [HL10, A.6]. ramified, .  unramified,  is odd, . unramified,  is even. ,where  is endowed with a natural symplectic structure associated to an additive character such that .In fact, we can compute the action of  on  explicitly (although we actually restrict the action to  on ). If we choose the isomorphism , the action of  is given by:One can see that  (mod  is , since we have .Now we use  as an example to show how to compute Hakim\u2019s character using our reinterpretation in Equation\u00a08.1. In this case,  is symmetric both over  and . In particular, we have , ,  and . Furthermore, we havetogether with an isomorphismOne can check directly that the adjoint action of  is simply given by multiplication by  under the above isomorphism, and taking the determinant of the adjoint action mod  is simply given bywhich implies the triviality of .\nNotice that in the case of ,  is always symmetric over . By our interpretation 8.3 or [Kal19, Lemma 4.5.3], the toral invariant of  is always trivial. Hence Kaletha\u2019s character is trivial by the triviality of the toral invariant in the symmetric ramified case, together with the fact  in the symmetric unramified case. Hence the only remaining part is the computation of character of -data. Notice that the computation of  is exactly the same as the case of . By Equation\u00a08.10, Equation\u00a08.12, and Equation\u00a08.13, we have  or , both of which are trivial. Hence, Conjecture (7.9) is true for , which gives a proof of Prasad\u2019s conjecture for regular supercuspidal representations of .\n8.7.2 Example of .\nThe difference in treating the case of  and  shows different complexity of Prasad\u2019s conjecture. For the case of , the double coset part, which is related to the set of certain embeddings of tori, is more complicated, while the character part is relatively easy. However, for the case of , the non-trivial quadratic character associated to  appears, while the embedding part is easy since there are not so many equivalence classes of rational embeddings.\nLet  be an elliptic maximal torus of  over . Then  for a quadratic extension . A necessary condition for the existence of an elliptic maximal torus of  whose base change equals to  is that  is a biquadratic extension. Let  and  be the other  intermediate fields between  and . Let  denote the non-trivial involution. Then  For simplicity, let  be a torus over , whose base change to  is  with .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the case of , Prasad\u2019s quadratic character is given by:\nHence  is given by:\nWe will give an explicit computation of the case of . Before doing this, we first review some results on the descriptions of supercuspidal representations of , which arises as base change of irreducible representations of . These results are essentially due to [Bla10].\nAssume  is ramified, and  is unramified. Then  could be unramified or ramified. Let  be a character such that  is a regular supercuspidal representation of  associated to . Assume  is a base change from a Langlands parameter of . Then  is a base change of a torus  with , and  is a base change of , which means that .\n is odd if and only if we have the field diagram\nThis result has been mentioned in [Bla10]. We write down a proof for completeness.. This direction is relatively easy. Let  denote the depth of . Let  be the generic element associated to , that is,Since , we know that , in particular, . This is equivalent to the fact  mod . We can choose a uniformizer  of  such that  and . The condition  forces  to be odd.. The direction is suggested by Blasco. Since  is unramified, we can choose  to be a uniformizer  of . Since  is ramified, we can choose  to satisfy . Since  corresponds to a level  character,  is a unit. On the other hand, since  is odd, we have , which means that . However  does not lie in , hence does not belong to , which means  generates  over . This implies  is unramified, hence  is ramified.\u220e\nNow we give a comparison of these four characters in the case of .\nThe odd case. (This terminology is from [HM02]) Representation side:In this case, by the above lemma, we know that  is even, which means that there is a non-degenerate Heisenberg quotient and  belongs to :Notice that both of these two characters are trivial on  since  for . On , the product of these two characters is given by:Explicit computation shows that these two non-trivial quadratic characters coincide on , which means: Parameter side.Notice that we have , withMoreover, we have  and . The commutative diagram:becomesand  is given by  for any  or .In this case,  is the unramified quadratic character of  and , where  is the unramified quadratic character of . Hence we have  and we haveHence we have the equalityThe even case. There are two cases: Representation side.A priori, if , we haveIt is clear that  is trivial on  and given by  for . Notice that  satisfiessince , and is given by  for . Moreover, we have the following indentitywhich means that if , then we have .However, in this case,  is odd, which means that  and the Heisenberg quotient is degenerate. Hence Kaletha\u2019s character and Hakim\u2019s character are automatically both trivial in this case. Parameter side.Following Equation\u00a08.5, , where  is the quadratic character of  determined by mod  data, and  is the unramified quadratic character  of . Hence . Now we are going to proveNotice that we have  by the definition of -data, which impliesby consideringHence we also have the equality Representation side.A priori, if , then we haveNotice that  is trivial by Example\u00a08.17 in this case, which means Hakim\u2019s character is always trivial. Parameter side.By Equation\u00a08.2, we have . Hence we have\nPrasad\u2019s conjecture 5.17 holds for regular supercuspidal representations of .\nIt seems that our approach is quite different from the proof existing in the literature. These characters may not be seen explicitly in the trace formula approach or in the local Rankin-Selberg method even in the simple case of .\n8.7.3 Example of ,  is odd.\nLet  be the elliptic maximal torus  of , where  is a degree  extension of . Since we are considering the case when  is also elliptic,  and  are disjoint. Let  denote the composite of  and . Fix a set of representatives  of . One can diagonalize the element  over , such that , where  lies in . Then each root in  is of the form . When  is cyclic generated by , then  is simply . Since  is odd, we know that all the roots are asymmetric both over  and . In this case, we have , . In this case, we have . All the roots in  are symmetric over  but asymmetric over . In this case, we have  and .\nPrasad\u2019s character.\nPrasad\u2019s character is trivial, since  is odd. The fact that the restriction of Prasad\u2019s character to an elliptic maximal torus is trivial can also be seen from Example\u00a05.16. Since all the roots are asymmetric over , when  is odd.\nHakim\u2019s character.\nHakim\u2019s character is also trivial by Section\u00a08.3.1, since all the roots are asymmetric over , when  is odd.\nKaletha\u2019s character.\nA priori, it seems that Kaletha\u2019s character is not necessarily trivial from its definition. Notice that all the roots are also asymmetric over . Hence from its definition, the character  is given by\nLet  be a maximal elliptic torus of . The character  is trivial, if  is of odd ramification degree.\nNotice that  is character of  defined over , which is trivial due to the ellipticity of .\nHence we have:where  is the  orbit of , and can be identified with . Hence if  is odd, we have .\n\u220e\nNotice that all the elliptic tori of  is of the form , for a degree  extension . Hence by the above lemma, Kaletha\u2019s character  is trivial when  is odd, and so is .\nCharacter from zeta data.\nSince all the roots are asymmetric over , by Equation\u00a03.9, the character is\nNotice that  since  is asymmetric over . We only need to compute . We can choose  in its orbit such that  for some . We have the following cases.\n is unramified.  is given by . Notice that  since both  and  are unramified. Hence for , . is ramified.  is given by , where  is the tamely ramified character, which is the unique non-trivial character on  and determined by the value at some mod--data.\nNotice that for any , . is ramified. , which means the character is trivial. is unramified. , since  is odd.\nThe above computation shows that 7.9 is true for , when  is odd. This also gives a simple proof of Prasad\u2019s conjecture 5.17 for regular supercuspidal representations of  when  is odd.\n8.7.4 Example of   is odd. \nNotice that  is an elliptic maximal torus of , hence  is of the form  for a degree  extension . Hence we have  for a degree  extension  such that . Moreover, we have , , which means all the roots are asymmetric over  but symmetric over . We also know that . Moreover, we have , which means all the roots in  are asymmetric over .\nPrasad\u2019s character.\nNotice all the roots are asymmetric over , since . Hence we have . Prasad\u2019s character is trivial by Equation\u00a05.2. The fact that the restriction of Prasad\u2019s character to an elliptic maximal torus is trivial can also be seen from Theorem\u00a05.15, since .\nHakim\u2019s character.\nThe only possibility for Hakim\u2019s character to be non-trivial is that  is ramified quadratic by Section\u00a08.3.1. In this case Hakim\u2019s character is given bySince  is ramified, the reduction mod  of  is . Hence the reduction of  is , which means Hakim\u2019s character is trivial.\nKaletha\u2019s character.\nNotice that . By the argument in Lemma\u00a08.20, Kaletha\u2019s character  is trivial when  is odd, so is .\nCharacter from zeta data\nSince all the roots are asymmetric both over  and , by Equation\u00a03.9, the character is\nThe above computation shows that Conjecture 7.9 is true for , when  is odd. This also gives a simple proof of Prasad\u2019s conjecture 5.17 for regular supercuspidal representations of  when  is odd.\nAppendix A Whittaker model for distinguished regular supercuspidal representations\nIn this appendix, we collect some facts about the characterization of Whittaker models of regular supercuspidal representations in terms of geometry. This origins from the work of Debacker and Reeder [DR10] on description of Whittaker models for generic very cuspidal representations. Basically, one can describe all the characters  of  which occur in  in terms of certain intersection property between the Kostant sections of  and the  orbit of the generic element associated to . Some of these work is generalized to regular supercuspidal representations in [Kal19] and [FKS21]. We will also mention some results about the Whittaker model of a  distinguished representation of . These results interact naturally when we study the distinction problem of a regular supercuspidal representation of .\nA.1 Local character expansions.\nWe first review some basic facts about the character expansion and -adic analogue of Rossman\u2019s character formula, which is known as the Murnaghan-Kirillov formula [Mur96]. Later, this work has been extended to a more general setting by many people: Jeffrey Adler, Stephen Debacker, David Kazhdan, Loren Spice [AD04] [DK11] [AS09] etc. Fix a -invariant bilinear form  on , which identifies  with . For any regular semisimple element , let  denote the semisimple orbital integral:where  denotes the centralizer of  and  is a left invariant Haar measure on  defined by Rao [Rao72], depending on a choice of Haar measures on  and . Notice that  is a distribution if we vary , while it could also be regarded as a function on  if we fix  and vary . We use  and  to distinguish them.\nFix an additive central character , one can define the Fourier transform of arbitrary orbital integral by:where  is defined by:Notice that the Fourier transform of a nilpotent orbital integral  as a distribution could also be represented as locally constant function on an open dense subset , which we also denote by .\nLet  denote the character distribution associated to an irreducible admissible representation . More precisely, fix a Haar measure  on , for any ,where  is an operator defined byIt is known that  is represented by some locally constant function on an open dense subset of , which we still denote by . Moreover, we have the well-known local expansion formula of , which is essentially due to Harish-Chandra and Howe [DP99].\nThere exist constants  and a neighbourhood  of  in  such that, for any where  is a semisimple element of , , and  runs over all the nilpotent  orbits in .\nFor , this formula is the usual Harish-Chandra character expansion:as an equality of locally constant function in a small neighbourhood of .\nIn fact, semisimple orbital integrals and nilpotent orbital integrals both play an important role in the space of invariant distribution on . Moreover, they are related by the following germ expansion result of regular semisimple orbital integral by Shalika [Sha72].\nFor any , there exist locally constant functions  on  and a neighbourhood  of  in  such that for any ,\nFor a fixed  sufficient close to , this identity is an identity of distributions on :A priori, this identity has nothing to do with representations. In fact, we could expect more for the relationship between character expansions and Shalika germs expansions. For instance, if we admit the philosophy of orbit method in the spirit of Kirillov-Rossmann [Ros78] for real reductive groups, that is, for some particular discrete series representation , we can associate a semisimple elliptic element  (in fact a coadjoint orbit in ), one can relate  and .\nMurnaghan [Mur96] studies the relation of  and  and found thatfor arbitrary nilpotent orbit , which leads to a formula of Kirillov-Rossmann type.\nwhere  is a regular elliptic element associated to the supercuspidal representation .\nA.2 Kostant section.\nLet  be a regular nilpotent  orbit. Let  be a nilpotent element. By Jacobson Morozov theorem, there exists a  triple  such that:\nA Kostant section of  at  is an affine subspace  defined by:\nSince  and  are -rational, the Kostant section  is defined over .\nEvery regular  orbit  meets  in exactly one point.\nMoreover, if the  orbit  is also defined over , then the unique point in  is -rational. Hence the Kostant section  determines an -rational point in every regular  orbit.\nLet  be a regular  nilpotent orbit in ,  be a Kostant section for , and  be a regular semisimple element in . Then the coefficient  is non zero if and only if the  orbit of  meets \nIf  is a very supercuspidal representation associated to a tame elliptic pair , let  denote the good semisimple element with . We have the following theorem due to Debacker and Reeder.\nLet  be a regular supercuspidal representation of . Assume  is a hyperspecial point. For any generic character ,  if and only if  orbit of  meets .\nFrom another perspective, if we pick up a generic representation  of  which is  distinguished, one has the following expectations on the Whittaker model of  from Prasad.\nLet  be an irreducible generic representation of . If  is  distinguished, then  has a Whittaker model with respect to a character .\nThis conjecture has been proved by Anandavardhanan and Prasad for  [AP16] based on the study of the restriction of representations of  to  and the classification of representations of . Later, this type of question has been raised and treated in a paper of Dipendra Prasad [DS19] with an appendix by Sakellaridis for general symmetric spaces. Later, Gourevitch and Sayag [GS20] give another proof by carefully studying the geometry of coadjoint orbits sitting inside the image of moment map.\nWe have the following characterization of generic characters , such that .\nNotice that we have the following exact sequence of -groups:Since  is unipotent,  is trivial. The long exact sequence gives the isomorphismLet  denote the compositionNotice that any generic character  is of the form . More explicitly,  is defined by:where  is a fixed additive character of .\nLet  denote the -group , whose -rational points consist of trace zero elements in where  denotes the map  sending  to . Let  denote a chosen trace zero element such that , we have the following exact sequence\nNotice that we have an exact sequence of -groups:Since  is trivial, the long exact sequence implies the lemma.\n\u220e\n satisfies  if and only if .\nBy A.1, we know that  if and only if . By applying the exact functor  to A.2, we know  if and only if  is a lift of a character of , that is,  is of the form  for some character  of . This in turns implies that . The reverse direction easily follows from the surjectivity of the trace map  sending  to .\n\u220e\nBy [DR10, 4.5], one has the following assignment:where  is defined byfor any . This implies that the element  associated to  satisfies the condition\nIn fact, if  is a regular supercuspidal representation of , which is  distinguished, the results of Prasad [DS19] on the description of Whittaker model for  could be regarded as a reverse direction of Proposition\u00a07.2.\nFaculty of Mathematics, Technion, Haifa, Israel\nEmail address:wangchuijia@u.nus.edu", "output": "In this article, we study Prasad's conjecture for regular supercuspidal representations based on the machinery developed by Hakim and Murnaghan to study distinguished representations, and the fundamental work of Kaletha on parameterization of regular supercuspidal representations. For regular supercuspidal representations, we give some new interpretations of the numerical quantities appearing in Prasad's formula, and reduce the proof to the case of tori. The proof of Prasad's conjecture then reduces to a comparison of various quadratic characters appearing naturally in the above process. We also have some new observations on these characters and study the relation between them in detail. For some particular examples, we show the coincidence of these characters, which gives a new purely local proof of Prasad's conjecture for regular supercuspidal representations of these groups. We also prove Prasad's conjecture for regular supercuspidal representations of G(E), when E/F is unramified and G is a general quasi-split reductive group.", "question": "none", "title": "2201.00447", "qa_pairs": "none"}
{"input": "Modular many-valued semantics for combined logics\u2020\u2020thanks: Research funded by FCT/MCTES through national funds and when applicable co-funded by EU under the project UIDB/50008/2020.\n\n\nCarlos Caleiro and S\u00e9rgio Marcelino\n{ccal,smarcel}@math.tecnico.ulisboa.pt\nSQIG - Instituto de Telecomunica\u00e7\u00f5es\nDep. Matem\u00e1tica - Instituto Superior T\u00e9cnico\nUniversidade de Lisboa, Portugal\n\n\n1 Introduction\nModularly putting together logics, or their fragments, namely by joining corresponding calculi, while keeping control of the metatheoretic properties induced and, in particular, of the resulting underlying semantics, is the core idea of the general mechanism for combining logics known as fibring\u00a0[38, 40, 65, 18, 25, 24].\nGiven its fundamental character and abstract formulation, this mechanism is a key ingredient of the general theory of universal logic\u00a0[12, 14]. Further, due to its compositional nature, a deep understanding of combined logics is crucial for the construction and analysis of complex logics, a subject of ever growing importance in application fields (see\u00a0[37], for instance). Given logics  and , fibring combines them into the smallest logic  on the combined language which extends both  and . This simple idea, however, is far from well understood, to date, despite the long track of work on the subject. An interesting running example of the difficulties at hand consists of the combination of the conjunction-only and disjunction-only fragments of classical logic, which does not coincide with its conjunction-disjunction fragment (see, for instance,\u00a0[15, 21, 46]), and which we will also address.\nTo date, we have many interesting general results regarding conservativity, decidability, finite model properties, or interpolation, as well as soundness and completeness preservation with respect to different forms of symbolic calculi\u00a0[39, 23, 67, 68, 34, 10, 18, 25, 60, 65, 76, 30, 63, 51, 52]\nfor combined logics, but there is no generally usable tool support for the obtained logics, due mainly to the absence of a satisfactory semantic counterpart of fibring that naturally relates models of the component logics with models of the combined logic. With the honorable exception of fusion of modal logics\u00a0[70, 74, 41, 35, 48], a very particular case of fibring, the available general semantics for combined logics, so far, are either not constructible from the semantics of the component logics\u00a0[76, 67, 60] (due to the use of fullness assumptions), or use highly uncommon semantic structures\u00a0[66, 63].\nFor these reasons, general fibred semantics is still an open problem: how to combine, in the general case, the semantics  (adequate for logic ) and  (adequate for logic ) into a semantics\n built directly from  and , providing an adequate semantics for\n? We have known for some time that this question is far from straightforward. Namely, when taking logical matrices as models, as is most common, we know that combining two logics, each given by a single finite matrix, can result in a logic that cannot even be given by a finite set of finite matrices, nor by a single matrix, even if infinite\u00a0[52, 22]. This fact led us to considering non-deterministic logical matrices (Nmatrices), as introduced by Avron and coauthors\u00a0[4, 5], and in\u00a0[53] we understood how this expressive gain could solve the problem in a neat way, but just for disjoint combinations, that is, when the logics being combined do not share any connectives.\nIn this paper, finally, we define a simple and usable general semantics for combined propositional-based logics. We do so by further enriching our semantic structures with partiality, and adopting partial non-deterministic logical matrices (PNmatrices), as introduced in\u00a0[8]. As we shall see, the added expressivity brought by partiality is crucial not just in keeping our semantic structures as compact as possible, but mostly in dealing with shared language.\nOur work has an additional fundamental ingredient. We consider a very enlightening step forward from traditional Tarski-style  single-conclusion consequence relations (see\u00a0[73]) to Scott-like  multiple-conclusion consequence relations as introduce in\u00a0[64]. This abstraction really sheds new light into the overall problem, as shall be made clear.\nWe will thus show that semantics for combined logics can always be obtained in the form of a PNmatrix obtained directly from given PNmatrices characterizing the original logics. Further, the resulting semantics will be finite as long as the given PNmatrices are finite, at least in the setting of multiple-conclusion logics. The connections between single-conclusion and multiple-conclusion consequence relations (see\u00a0[69]) are fundamental, at this point, in understanding how much more demanding it is to obtain a similar result in the single-conclusion setting, where indeed finiteness may be lost.\nOur approach is anchored on the observation that semantics, be they given by means of matrices, Nmatrices, or PNmatrices, are simply clever ways of defining suitable collections of bivaluations (see\u00a0[13]). Since a collection of bivaluations characterizes in a unique way a multiple-conclusion logic (see\u00a0[69]), it is relatively simple to express the combination of multiple-conclusion logics in terms of bivaluations. Then, we just need to come up with a matching construction over PNmatrices, generalizing the finiteness-preserving strict-product operation proposed in\u00a0[53]. The single-conclusion case is harder, simply because the characterization of a Tarski-style consequence in terms of bivaluations is no longer unique. The situation can be restored, however, when the\ncollection of bivaluations is meet-closed, once we consider a simple (though not finiteness-preserving) corresponding operation over PNmatrices. Furthermore, we show that the constructions above enjoy universal properties, consistent with the definition of  as the least logic that extends  and , as advocated in\u00a0[65, 18].\nBesides providing a range of meaningful concrete examples, we also explore three concrete applications of the semantic characterizations obtained, which can be seen as relevant contributions in their own right: a semantic characterization of logics obtained by imposing new axioms to a given many-valued logic (with some perhaps surprising consequences, such as a denumerable semantics for intuitionistic propositional logic); an analysis of when and how to split a logic into syntactical fragments whose combination is the original logic, as a method for obtaining a calculus for a given many-valued logic by putting together axiomatizations for simpler syntactic fragments; and some general, preliminary, results on the preservation of decidability when combining logics.\nThe rest of the paper is organized as follows. In Section\u00a02 we recall the necessary notions, namely regarding logics, their syntax, semantics and calculi, and define the relevant notions regarding combined syntax and combined logics, along with examples illustrating the particularites both of single-conclusion versus multiple-conclusion consequence, and of partiality and non-determinism. The section is a bit long, but the reader can browse through faster, and come back for details when necessary. Section\u00a03 is devoted to the main contributions of the paper, namely the semantic characterization of combined logics in terms of bivaluations, and PNmatrices, first in the multiple-conclusion setting and then in the more complex single-conclusion scenario, by means of simple strict-product and -power operations on PNmatrices. Section\u00a04, then, shows that the characterizations previously obtained enjoy natural universal properties. Section\u00a05 showcases the three mentioned applications of our characterization, including some relevant important contributions by themselves. The paper concludes, in Section\u00a06, with a summary of the results obtained, their implications, and an outlook of further research.\n2 Logics and their combination\nWe start by introducing our main objects of interest, fixing notation, and setting up the technical framework necessary for studying the semantics of combined logics, as well as of their associated calculi and semantics.\n2.1 Syntax\nThe syntax of a (propositional) logic is defined, as usual, by means of a signature, an indexed family  of denumerable sets where each  contains all allowed -place connectives, and an infinite denumerable set  of variables (which we consider fixed once and for all). As standard,  denotes the set of all formulas111In our setting, the set  of all formulas is always denumerably infinite. This is not just a (relatively common) choice. This cardinality constraint plays an essential role in some technical results, where it is crucial to avoid the pitfalls of ill-defined natural extensions as observed in\u00a0[32, 28]. constructed from the variables in  using the connectives in . We will use  to denote variables,  to denote formulas, and  to denote sets of formulas, in all cases, possibly, with annotations.\nWe use , ,  to denote, respectively, the set of variables occurring in , the set of subformulas of , and the head constructor of , given a formula . These notations have simple inductive definitions: , and  for ; and if  and , , , and\n. These notations extend to sets of formulas in the obvious way.\nAs we will consider combined logics, with mixed syntax, we need to consider different signatures, as well as relations and operations between signatures.\nSignatures being families of sets, the usual set-theoretic notions can be smoothly extended to signatures. We will sometimes abuse notation, and confuse a signature  with the set  of all its connectives, and write  when  is some -place connective . For this reason, the empty signature, with no connectives at all, will be simply denoted by .\nLet  be two signatures. We say that  is a subsignature of , and write , whenever  for every . Expectedly, given signatures , we can also define their shared subsignature\n, their combined signature , and their difference signature . Clearly,  is the largest subsignature of both  and , and contains the connectives shared by both. When there are no shared connectives we have that . Analogously,  is the smallest signature that has both  and  as subsignatures, and features all the connectives from both  and  in a combined signature. Furthermore,  is the largest subsignature of  which does not share any connectives with .\nA substitution is a function , that of course extends freely to a function  for every . As usual, we use  to the denote the formula that results from  by uniformly replacing each variable  by , and  for each .\nNote that if  then . Still,  and  are both infinite denumerable. In fact, the pair can be endowed with a very useful bijection capturing the view of an arbitrary  formula from the point of view of , the skeleton function  (or simply , or even ), whose underlying idea we borrow from\u00a0[52]. Note that, given ,  may be in , in which case we dub  a -monolith or simply a monolith. The idea is simply to replace monoliths by dedicated variables, just renaming the original variables. Let  be the set of all monoliths. It is easy to see that  is always denumerable, though it can be finite when  contains nothing but a finite set of -place connectives.\nIn any case,  is always infinite denumerable, because  is, and thus we can fix a bijection . The\n bijection is now easily definable from , inductively, by letting  for , and for  and ,\n if , and  if .\nThe  bijection thus defined can be easily inverted by means of the substitution  (or simply , or even ) defined by . Note, namely, that  for every .\nNote also that the restriction of  to ,  (with a slight abuse of notation, we will use the same name) is a substitution, and  for every .\n2.2 Consequence relations\nWith respect to the very notion of logic, we will not only consider the traditional Tarski-style set-formula notion of consequence (single-conclusion), but also the more general Scott-style set-set notion of consequence (multiple-conclusion), which plays an essential role in our results.\nA multiple-conclusion logic is a pair  where  is a signature, and  is a consequence relation satisfying the properties below, for every  and :if  then , if  then , if  for each partition222Here and elsewhere,  is partition of  if  and .  of , then , if  then . \nOften, the relation also satisfies the following property, for every :\nif  then there exist finite sets  and\n such that .\nProperty (C) is best known as cut for sets.\nThe other properties are usually known as overlap (O), dilution (D), substitution invariance (S),\nand compactness (F)\n(see\u00a0[64, 69, 73]). As is well known, a multiple-conclusion logic  has a compact version\n defined to be the largest compact logic such that .\nA pair of sets of formulas  is said to be a theory-pair of  (see\u00a0[16]) when, for every , if\n then , and also, if\n then . It is clear that, given sets , the pair of sets\n is the least theory-pair containing .\nA theory-pair  is consistent if  (otherwise, by dilution, we necessarily have ). A consistent theory-pair is maximal if there is no consistent theory-pair that properly contains it, that is, if  is a consistent theory with  and  then  and . Equivalently, using cut for the set of all formulas, a consistent theory-pair  is maximal precisely if  is a partition of . This implies, obviously, that a consistent theory-pair can always be extend to a maximal one.\nWe say that a pair  is a single-conclusion logic if  is a signature,  is a relation, and  is a multiple-conclusion logic where, for ,  if and only if there exists  such that . It is well known (see\u00a0[69]) that this constitutes an alternative definition of the usual notion of Tarski-style consequence relation, inheriting the usual properties of reflexivity, monotonicity, transitivity, and structurality from properties (ODCS), as well as compactness from (F), when it holds. Again, a single-conclusion logic  has a compact version\n defined to be the largest compact logic such that .\nMore standardly, now, a set of formulas  is said to be a theory of \nwhen, for every , if  then .\nGiven a set , we know that  is the least theory that contains .\nAs usual, a theory  is consistent if . A consistent theory  is maximal relatively to  if every theory that properly contains  must also contain , that is, if  for every . A consistent theory  is relatively maximal if it is maximal relatively to some formula .\nAccording to the usual Lindenbaum Lemma (see, for instance,\u00a0[73]), if a single-conclusion logic is compact then a consistent theory always has a relatively maximal extension.\nEvery multiple-conclusion logic  has of course a single-conclusion companion defined simply by  where, for ,  if and only if .\nWhen  is a single-conclusion logic, it is clear that the single-conclusion companion of\n is precisely . There may however be many multiple-conclusion logics whose single-conclusion companion coincides with\n, which we dub as multiple-conclusion counterparts of . Indeed,\namong the many possible multiple-conclusion counterparts of , we have that  is precisely the minimal\u00a0[69].\nNote that whenever , it is easy to see that  is a theory of\n if and only if there exists  such that the pair  is a theory-pair of .\nFor both types of logics (we will use  as a placeholder for either a multiple-conclusion  or a single-conclusion ), it is well-known that the logics with a common signature form a complete lattice (under the inclusion ordering on the consequence relations), as in both cases it is relatively straightforward to check that intersections of consequence relations are consequence relations (see\u00a0[73, 69]). These facts make it relatively easy to enrich the signature of a logic. Namely, if  and  is a logic then the extension of  to , denoted by\n, is the least logic (of the same type) with signature  such that\n.\nIt is relatively simple to see that . Just note that for each substitution  we have that  is also a substitution, and also . The fact that  are bijections make it straightforward to show that  is indeed a consequence relation of the correct type.\nLet . Concretely, in the multiple-conclusion case, we have that  if and only if  if and only if there exist  and  such that , , and .\nAnalogously, in the single-conclusion case, we have that  if and only if  if and only if there exist  and  such that , , and .\nIt is also quite natural to formulate the combination of logics (also known as fibring) as follows.\nLet .The combination of type-conclusion logics , , which we denote by\n, is the least type-conclusion logic  such that . The combination is said to be disjoint if .\nNote that it follows easily that the combination of compact logics is necessarily compact. Namely, if ,  are compact then the least logic such that  is also the\nleast logic such that . Since it is clear that , it follows that .\n2.3 Calculi\nLogics are often defined by syntactic means, using symbolic calculi. Again, we will consider multiple as well as single-conclusion calculi.\nA multiple-conclusion calculus is pair  where  is a signature, and  is a set of (schematic) (multiple-conclusion) inference rules, each rule  being usually represented as  where  is the set of premises and  the set of conclusions of the rule, also represented as  when  and . We can easily associate a multiple-conclusion logic  to a given calculus  by means of a suitable tree-shaped notion of derivation (see\u00a0[69, 54, 19]). For the purpose of this paper, however, it is sufficient to characterize  as the least multiple-conclusion logic such that , being compact when the rules in  all have finite sets of premises and conclusions.\nA single-conclusion calculus is pair  where  is a signature, and  is a set of (schematic) (single-conclusion) inference rules, each rule  being usually represented as  where  is the set of premises and  the conclusion of the rule. It is clear that single-conclusion calculi can be rephrased as particular cases of multiple-conclusion calculi, namely those whose rules all have singleton sets of conclusions, and that the corresponding notion of derivation will now be linear-shaped, and coincide with the usual notion of proof in Hilbert-style calculi, giving rise to an associated single conclusion logic . Again, in any case,  is the least single-conclusion logic such that , and again it is finitary if all the rules in  have finitely many premises. In that case, if we use  for both a single conclusion-calculus and its singleton-conclusion multiple-conclusion rephrasal, it is straightforward to see that\n.\nWhen  and  is a calculus, it is immediate that , that is, the extension of  to  is precisely .\nCombining calculi at this level is quite simple, as has been known for a long time in the single-conclusion case\u00a0[17]. The logic associated to joining the rules of two calculi is precisely the combination of the logics defined by each calculi.\nLet .If  are type-conclusion calculi,  their associated type-conclusion logics, then .\nThe reasoning is straightforward. Let , which means that  is the least consequence with .As  and  it follows that , and since  is the least\nconsequence with this property we can conclude that .Reciprocally, as  it follows that , and since  is the least consequence with this property we can conclude that .\u220eFor simplicity, whenever  (in either the single or the multiple-conclusion scenarios), we will say that  constitutes an axiomatization of the logic .\n2.4 Semantics\nAnother common way of charactering logics is by semantic means. For their universality we shall consider logical matrices, but will consider an extension of the usual notion which also incorporates two less common ingredients: non-determinism and partiality, following\u00a0[4, 8]. These two ingredients play essential roles in our forthcoming results.\nA partial non-deterministic matrix (PNmatrix) is a pair  where  is a signature, and  is such that\n is a\nset (of truth-values),  is the set of designated values, and\nfor each  and ,  provides the truth-table  of\u00a0 in . When appropriate we shall refer to  as a -PNmatrix.\nWhen  for all  we say that the truth-table of  in\n is total. When  has at most one element for all  we say that the truth-table of  in\n is deterministic.\nWhen all the truth-tables are total, we say that  is also total, or equivalently that it is a non-deterministic matrix (Nmatrix).\nAnalogously, when all the truth-tables are deterministic, we say that  is also deterministic, or equivalently that it is a partial matrix (Pmatrix).\nFinally, if  is total and deterministic we say that it is simply a matrix (the usual notion of a logical matrix, up to an isomorphism).\nA -valuation is a function  such that  for every , every -place connective , and every . We denote the set of all -valuations by .\nAs is well known, if  is a matrix then every function  with  can be extended to a -valuation (in an essentially unique way for all formulas  with ). When  is a Nmatrix, a function  as above can possibly be extended in many different ways. Still, we know from\u00a0[4] that a function  with  can be extended to a -valuation provided that  and\nthat  whenever . We dub such a function a prevaluation of the PNmatrix .\nIn case  is not total, in general, one does not even have such a guarantee\u00a0[8], unless . In other words, given , we have  if the values in  are all together possible in some valuation of . Of course,  if .\nGiven a signature , a bivaluation is a function . The set of all such bivaluations is denoted by .\nA set of bivaluations  is known to characterize a multiple-conclusion relation  defined by\n when, for every , either  or . Of course,  also characterizes the more usual single conclusion relation\n such that  when , i.e., . In both cases,\n is a logic whenever  is closed for substitutions, that is, if  and  then . Easily, by definition, if  then .\nA PNmatrix  with  easily defines a set of induced bivaluations, closed for substitutions, namely , where  such that  if , and  if , simply captures the distinction between designated and undesignated values.\nWe will write  instead of , and say that  is the type-conclusion logic characterized by , for , which is always compact (finitary) when  is finite. Clearly, .\nNote that if  is a maximal consistent theory-pair of  then there must exist  such that , and consequently also . In the single-conclusion case, it is well-known that if  is a relatively maximal theory of  then there must also exist  such that  (see\u00a0[69]).\nWhen  and , it is straightforward to check that\n characterizes the extension to  of the logic characterized by .\nIt is worth noting that  is still closed for substitutions because  is a substitution, and ; consequently, we have that  and  is in  if  is.\nWhen  is a PNmatrix it is very easy, making essential use of non-determinism, to define a PNmatrix  that characterizes the extension to  of the logic characterized by . If , one defines  such that  if , and  for every  if  is a -place connective. It is straightforward to check that .\nOur work in the next Section of the paper is to prove results that enable us to describe the semantics of the combination of logics characterized by (P)(N)matrices, analogous to Proposition\u00a02. Before tackling these problems, it is certainly useful to ground all the relevant notions to concrete illustrative examples.\n2.5 Illustrations\nIn this subsection we present a few examples illustrating the relevant notions, as introduced earlier, including the new semantic phenomena brought by partiality and non-determinism, the divide between the single and multiple-conclusion settings, and also the idiosyncrasies of combined logics.\n(Classical logic, fragments and combinations).\nLet  be the usual connectives , that is, , ,\n, and  for .For simplicity, given some connectives  of the signature, we will write  to denote the subsignature of  containing only the connectives in .Take, for instance,  and\n. The formula  is such that its skeleton from the point of view of  is , if  and for the monolith we have . However, from the point of view of  we have that  is itself a variable, as  is a monolith.Consider now the Boolean -matrix\n\ndefined by the following tables. It is well-known that this matrix characterizes classical propositional logic, and we will write .\nHowever, we can also define a multiple-conclusion version of classical logic . Of course, we have that\n, but in this case\n. Namely, note that\n and , but one has .The multiple-conclusion version of classical logic  is known from\u00a0[69] to be alternatively characterized by the following multiple-conclusion calculus.It is crucial to observe that the axiomatization above is completely modular with respect to syntax, as each rule involves a single connective.\nSaid another way, the axiomatization is obtained by joining axiomatizations of each of its single-connective fragments, or equivalently\nwe have thatwhere  for each  is the corresponding single-connective fragment of the logic.\nThis fact marks a sharp contrast with respect to the single-conclusion setting, which goes well beyond classical logic, and that will play a key role in our developments. Namely, the single-conclusion version of classical logic is known to be characterized by the following single-conclusion calculus.The fact that the single-conclusion axiomatization is not at all modular with respect to syntax, and that most rules refer to more than one connective, is definitely not a coincidence, as shown in\u00a0[21]. Indeed, each of the single-connective fragments  of  for each connective  can be axiomatized as follows (see\u00a0[62]).It is clear that joining all these rules will yield a logic much weaker than classical logic (see\u00a0[21]), that is,A suitable semantics for the resulting combined logic is not obvious. \nThe previous example, though very familiar, was useful for illustrating some of the notions and notations used in this paper, and in particular the differences between the single and multiple-conclusion settings, namely when combining logics. However, even in a two-valued scenario, non-determinism allows for characterizing some interesting non-classical connectives and logics.\n(Some new two-valued connectives).\nConsider the signature  such that , ,\n, and  for , and the Boolean-like -Nmatrix\n\ndefined by the following tables.The first connective  is a completely free -place connective, known as botop in\u00a0[55]. Its logic is characterized by the empty calculus, without any rules. Then,  is a -place modal-like box operator whose logic is characterized by the usual necessitation rule:The -place implication-like connective  is characterized solely by the rule of modus ponens:All rules above serve both the single and multiple-conclusion settings.Lastly, the -place connective , was named platypus in\u00a0[50], and features some properties of classical conjunction mingled with classical disjunction. Namely, its multiple-conclusion logic is characterized by the following two (familiar) rules.As shown in\u00a0[50], the single-conclusion logic of platypus cannot be finitely axiomatized. \nOf course, the added richness provided by non-determinism goes well beyond the two-valued cases seen above.\n(Information sources).\nIn\u00a0[3], the authors introduce a logic for modelling the reasoning of a processor which collects information from different classical sources. Namely, each source may provide information that a certain formula of classical logic is true, or false, or no information at all. This situation gives rise to four possible situation as, for each formula,  the processor may have information that it is true and no information that it is false, or  information that it is false and no information that it is true, or  have information that it is true and also information that it is false, or  have no information at all about the formula. This situation is easily understandable if one reads the situations as collecting the available classical truth-values (0,1) for each formula asAs originally presented, the logic is defined over the signature  and characterized by the Nmatrix\n defined by the tables below.Clearly, both conjunction and disjunction have non-deterministic interpretations. For instance, note that . Thus, a valuation  may be such that there exist formulas  with  and .From\u00a0[54, 19] we know that both  and  are axiomatized by the following\nrules.The fact that this single-conclusion calculus characterizes the multiple-conclusion consequence  is remarkable, implying that\n.\nNamely, given any set of formulas , note that , as the function such that  for all formulas , is such that .Note that these logics could not possibly be characterized by finite matrices. Namely, let  be a variable, and define  and  for . Note that  satisfies , and consider for each  the prevaluation  of  defined byEach  thus extends to a valuation  showing that  for . Hence,  fails to be locally finite and therefore cannot be characterized by a finite set of finite matrices\u00a0[22]. The same applies to , simply because .\n \nBesides allowing for a great amount of compactification, non-determinism has another outstanding property regarding modularity with respect to syntax.\n(Language extensions).\nAbove, given a logic  and ,\nwe have defined its extension to the larger signature as\n. If  has an associated calculus , then it is clear that the extension  is associated to the exact same rules via the calculus .Take, for instance, single-conclusion classical propositional logic  as defined in Example\u00a03. Suppose that we wish to consider its extension to a larger signature  containing a new connective . We know that the exact same calculus presented above is associated to the extended logic\n. What is more, we also have that the extended logic is characterized by the -Nmatrix\n which extends the -matrix  by lettingwhere the connective is interpreted in a (neutral) fully non-deterministic manner.\nThis extension could not be possibly characterized finitely without using non-determinism\u00a0[4].\n \nAt last, we should illustrate the advantages and intricacies that result from introducing partiality.\n(Kleene\u2019s strong three-valued logic).\nWe consider the implication-free fragment of Kleene\u2019s strong three-valued logic as defined in\u00a0[36]. The logic is defined over the signature  and is usually characterized by means of two three-valued -matrices. Equivalently, the logic is given just by the four-valued Pmatrix  defined by the following truth-tables.Note that several entries of the tables contain , namely . As such, it is clear that a valuation in  cannot both use the values  and . As a consequence, we have that\n The two three-valued matrices mentioned above correspond to\nthe (total) restrictions of  to  and to .The single-conclusion logic  is known to be associated with the calculusThe multiple-conclusion logic  is known from\u00a0[19] to be associated with the calculusThis latter multiple-conclusion calculus is clearly more natural. As it contains genuinely multiple-conclusion rules, in this case,\n. Note, for instance, that , but that\n and . \nPartiality can indeed be used in almost all cases to provide a single PNmatrix for a logic characterized by a set of Nmatrices, as we will see later.\n3 Semantics for combined logics\nIn this section, we are seeking semantic characterizations for combined logics, using bivaluations, and then PNmatrices. The multiple-conclusion abstraction, which we will analyze first, is important for its purity with respect to combination. As we will show, the step toward the single-conclusion case is then a matter of controlling, semantically, the relationship with the multiple-conclusion companions.\nIn both cases, non-determinism and partiality play fundamental roles (as we know that similar results are impossible with respect to matrices).\n3.1 The multiple-conclusion case\nIn the multiple-conclusion case, the characterization we need is really very simple, if one considers bivaluations.\nThe result stems directly from the known fact (see\u00a0[69]) that for every multiple-conclusion logic  there exists a unique set of bivaluations  such that , namely . Note that this also implies that  if and only if .\nWe fix signatures , and sets of bivaluations  and , both closed for substitutions.\nWe have that\n with .\nLet , meaning that  is the least consequence with .As  it follows that  and . Since  is the least\nconsequence with this property we can conclude that , and therefore .Reciprocally, as  and  it follows that , and so .\u220eThis result allows us to obtain a clean abstract characterization of the combination of multiple-conclusion logics. One just needs to note that, given a signature , a partition  of  is essentially the same thing as a bivaluation  with  and .Let ,  be multiple-conclusion logics, and consider their combination . For every , we have:Using Proposition\u00a08, and letting  and , we have\n if and only if\nthere exists  such that  and  if and only if\nthere exists  such that  and  if and only if\nthere is a partition  of  such that  and .\n\u220eThe question is now whether we can mimic this simplicity at the level of PNmatrices.\nIt turns out that one can define a\nvery simple but powerful operation (already studied in\u00a0[53] with respect to Nmatrices, but only in the disjoint case) in order to combine PNmatrices.We fix PNmatrices  and , with  and .The strict product of  and  is the PNmatrix  such that  where,, andfor every ,  and , we define  by letting  if and only if the following conditions hold:if  then , andif  then .Note that  contains all pairs of truth-values which are compatible, that is, either both designated, or both undesignated. The pairs where both values are designated constitute . The truth-table of a shared connective  comprises all the pairs of values in the truth-tables of  which are compatible. The truth-table of a non-shared connective, say , has each possible value in the truth-table of  paired with all compatible values in . Clearly, the resulting PNmatrix is fundamentally non-deterministic for non-shared connectives whenever the given PNmatrices have several designated values, and several undesignated values. For shared connectives, non-determinism may appear if inherited from some of the given PNmatrices. Partiality, on its turn, is crucial to the interpretation of shared connectives, showing up whenever the values given by the truth-tables of  cannot be paired compatibly. For non-shared connectives, partiality may still appear if inherited from the given PNmatrices, or in pathological cases where the given PNmatrices do not have designated values, or do not have undesignated values.Before characterizing the exact scope of this construction, we should note that valuations in  are always suitable combinations of valuations in  and . For , we will use  to denote the obvious projection functions, i.e.,  and .\nEasily, if  then . Also, it is easy to see that , ,  are all compatible for every formula  in the combined language. Further, if , , and  is compatible with  for every , then  with  for each . These properties apply also to prevaluations over any set of formulas closed for subformulas..Pick . If  then . By definition of , it follows that\n and\n are compatible for every formula in , and thus induce the same bivaluation. We then have that .Reciprocally, given valuations  and  inducing the same bivaluation, it turns out that they must be compatible for all formulas,  if and only if . Therefore,  is compatible with both, as  if and only if , and induces the exact same bivaluation. We conclude that .\n\u220eNow, we can easily identify the multiple-conclusion logic characterized by a strict product as the corresponding combined logic.The combination of multiple-conclusion logics characterized by PNmatrices is the multiple-conclusion logic characterized by their strict product, that is,\n.The result follows directly from Proposition\u00a08 and Lemma\u00a011.With  and , just note that\n.\u220eThis result, besides being based on a simple operation on PNmatrices, has a very useful feature: it provides a finite-valued semantics for the combined logic whenever we are given finite-valued semantics for both given multiple-conclusion logics.Let us look at some examples, starting with the two-valued case.(Multiple-conclusion two-valued combinations).\nTake two signatures  and consider two-valued PNmatrices  with\n and , such as those in Examples\u00a03 or\u00a04.Note that according to Definition\u00a010,  is also two-valued, having values  and , with the latter designated. In the following discussion, for simplicity, we shall rename the two values to just 0 and 1, respectively, and assume that the strict product is .If  is a shared connective, and assuming for the sake of exposition that  is a -place connective, we have that  behaves as depicted below.\u2009\u2009This behaviour is absolutely similar for connectives with any number of places, that is,\n for any  and . Consequently,  whenever .If  is not a shared connective, and assuming without loss of generality that , , then in the strict product we have . This implies that one could simply consider the extended PNmatrices  and just use the equation above, as .It is clear that the resulting PNmatrix may be genuinely partial in case some of the sets are disjoint, and in general will be a Pmatrix whenever starting with two matrices.Recalling Example\u00a03, we see that given any two sets of classical connectives , if  and  are the\ncorresponding fragments of the classical matrix ,\nit follows that  is the fragment of  corresponding to\n. According to Theorem\u00a012, this implies that\n and thus we haveWe will see later that in the single-conclusion case the situation can be dramatically different. Let us now consider a richer example.(Combining the three-valued implications of Kleene and \u0141ukasiewicz).\nConsider the signature  with  and  for . The three-valued implications of Kleene and \u0141ukasiewicz are defined by the well known matrices  and\n defined below.According to Theorem\u00a012, we know that  is characterized by the five-valued -Pmatrix  given by the truth-table below, where for simplicity we have renamed each truth-value  to .Analyzing  it is clear that the values  and  are spurious, in the sense that they cannot be used by any valuation. This happens because the two corresponding diagonal entries of the table are empty, that is, .Removing these spurious elements we obtain the following table.Further, we also have that , which then implies that the total components of the Pmatrix are , which implies that  is precisely the set of all classical interpretations of classical implication. We can conclude, thus, that\n coincides with the multiple-conclusion implication-only fragment of classical logic, as defined in Example\u00a03.Confirmation of this interesting fact can be obtained by putting together calculi for the logics, according to Proposition\u00a02. These multiple-conclusion versions of the logics are not very well known, but a calculus for  can be readily obtained using the technique of\u00a0[54, 19], whereas a calculus for  can be found in\u00a0[2]. Of course, all the rules in these calculi are classically valid, because  (all classical valuations are permitted in both matrices). Further, as we know the rules of classical implication from Example\u00a03, it suffices to note that: (1) , and also ; (2) , and also ; and (3)\n and  which implies that .We will return to this example in the more familiar single-conclusion setting.\n We shall now illustrate how different it is to combine logics with or without shared connectives.(The three-valued implications of Kleene and \u0141ukasiewicz, disjointly).\nWe shall revisited Example\u00a014 above, combining the (multiple-conclusion) logics of Kleene\u2019s and \u0141ukasiewicz\u2019s three-valued implications, but now assuming that the connectives are syntactically different, i.e., that Kleene\u2019s implication comes from a signature  with  and  for , whereas \u0141ukasiewicz\u2019s implication comes from a disjoint signature  with  and  for . The corresponding matrices are now  with  and  with\n defined below.According to Theorem\u00a012, we know that  is characterized by the five-valued -Nmatrix  given by the truth-tables below.Of course, this is quite different from simply considering the given three-valued interpretations of each connective.\nNote, namely, that since all designated entries of  are also designated in  one could perhaps wrongly expect to have that . This assertion can be easily shown to fail by considering, for instance, any valuation  with  and , simply because\n is necessarily designated but  contains no designated value. \n3.2 The single-conclusion case\nThe results above really illustrate the simplifying power of using multiple conclusions. Of course, things are not so simple in the single-conclusion scenario. Still, we know enough to be able to take nice conclusions from the same line of reasoning. Let us start with bivaluations.\nIf we analyze the proof of Proposition\u00a08, it is simple to understand why it cannot be simply replicated in the single-conclusion case.\nEasily, the same line of reasoning would allows us to conclude that  with . However, in general,\n may very well not be the least such single-conclusion logic. Given  with , we cannot guarantee that .\nConcretely, assuming that  we still know that  and .\nThus, we still have bivaluations  such that  and , for . However, now, despite the fact that  and  coincide for all formulas in , we have no way of making sure that .\nThis problem lies in a crucial difference from the multiple-conclusion case, as the same single-conclusion logic can be characterized by distinct sets of bivaluations.\nGiven , let its meet-closure be the set\n with each meet defined by  precisely if  for every , for each . It is well known that\n if and only if , and thus that two sets of bivaluations characterize the same single-conclusion logic precisely when their meet-closures coincide. Namely, every single-conclusion logic  is such that  with , which is the largest set of bivaluations that characterizes .\nThe trick is then to work with meet-closed sets of bivaluations, that is, .\nIn that case, it is worth noting that .\nWe have that\n with .\nLet , meaning that  is the least consequence with .As  it follows that\n and . Since  is the least\nconsequence with this property we can conclude that , and therefore .Reciprocally, as  and  it follows that , and so .\u220eNote that  is necessarily meet-closed, as it is the intersection of meet-closed sets. Hence, not only  and , but also .The next abstract characterization of combined single-conclusion logics follows. Just note that given  closed for substitutions, it is always the case that  is a theory of . The converse is in general not true, unless  is meet-closed. Concretely, if\n is a theory of  then there always exists  such that .Let ,  be single-conclusion logics, and consider their combination . For every , we have:Using Proposition\u00a016, and letting  and , we have\n if and only if\nthere exists  such that  and  if and only if\nthere exists  such that  and  if and only if\nthere is  such that  is a theory of both\n and\n with .\n\u220eThis result captures neatly the intuition one already had from Proposition\u00a02, namely that  precisely when  is obtained by closing\n with respect to both  and .Turning to PNmatrices, expectedly, Theorem\u00a012 does not immediately apply to single-conclusion logics, as shown by the next counterexample.(Limitations of the strict product operation).\nWe present an example showing that, contrarily to the multiple-conclusion setting, the single-conclusion logic characterized by the strict product of two PNmatrices may fail to be the combination of the single-conclusion logics characterized by each of the given PNmatrices.Consider the -only and -only fragments of classical logic,  and  respectively, as defined in Example\u00a03. As we have seen in Example\u00a013, the strict product of their two-valued matrices is simply the classical two-valued matrix for both connectives  which characterizes the -fragment of classical logic.However, letting , and taking into account the single-conclusion calculi for each of the fragments, shown also in Example\u00a03 and also Proposition\u00a02, it is not at all clear that . As a matter of fact, this is not the case, as  is a strictly weaker consequence, as shown in\u00a0[21, 53]. Namely, . We will show exactly why in a forthcoming example.Clearly, the set of classical bivaluations for conjunction is meet-closed, and therefore the phenomenon above can only be justified by the fact that the set of classical bivaluations for negation is not meet-closed. Concretely, it is clear that there is a unique classical (bi)valuation  such that  for all , and thus  and so on, and also a unique classical (bi)valuation  such that  for all . Letting , it is immediate that  for , but it is also clear that  is not a classical bivaluation.\n As before, the problem lies with the fact that, in general, the set of bivaluations induced by a PNmatrix does not have to be meet-closed. In order to cope with this possibility, we consider the following property.A PNmatrix  with  is saturated if for each consistent theory  of  there exists  such that\n.If  with  is a saturated PNmatrix and  then it is worth noting that  is also saturated.\nIndeed, it suffices to observe, first, that  is a consistent theory of  if and only if  is a consistent theory of , and second, that if  for some valuation  then  with\n.Of course, a PNmatrix that has a meet-closed set of bivaluations is necessarily saturated.\nIt turns out, however, that saturation does not necessarily imply a meet-closed set of bivaluations, but it gets sufficiently close. Let  be the trivial bivaluation such that  for every . It is well known that  for . is saturated if and only if .Let  be saturated and . If  then . Otherwise,  is a theory of : if  is inconsistent then again ; if  is consistent then saturation implies that . We conclude that .\nTo conclude the proof note that , simply because , and any bivaluation  is such that  with .Conversely, assume that . If  is a consistent theory of  then, for each formula  there is a bivaluation  such that  and . Take . The meet bivaluation  and , which implies that  as  is consistent. We conclude that  and thus that  is saturated.\u220eUnder the assumption that the PNmatrices are saturated, Theorem\u00a012 can now be adapted to the single-conclusion case too.The combination of single-conclusion logics characterized by saturated PNmatrices is the single-conclusion logic characterized by their strict product, that is, if both\n and  are saturated then we have\n.The result follows directly from Proposition\u00a016, and Lemmas\u00a011\u00a0and\u00a020.With  and , note that we necessarily have\n.\u220eAs a corollary of this proof it also results that  is a saturated PNmatrix, and thus that saturation is preserved by the strict product operation.(Strict product and saturation).\nRecall the discussion in Example\u00a018 about the single-conclusion combination of the -only and -only fragments of classical logic,  and .Since the set of all classical bivaluations for the -only language is meet-closed, the classical -matrix  with , whose truth-table is shown below, is saturated.On the other hand, as seen before, the set of all classical bivaluations for the -only language is not meet-closed, and the corresponding two-valued matrix is not saturated. Instead, let us consider\nthe three-valued -matrix  as defined below.It turns out that . Further,  is saturated. To see this, given a consistent theory\n of , it suffices to consider the valuation  such thatBy the consistency of  we know that  is well defined, because  and  cannot both be in  due to rule\n. Additionally, rules  and  guarantee that  is indeed a valuation of .Given the saturation of the two matrices, according to Theorem\u00a021, the resulting combined logic  is characterized by the strict product . By Definition\u00a010 the resulting truth-values are  (where, again, we are simplifying each pair  to simply ). Renaming these values to simply , respectively, we have that  is defined by the truth-tables below.A valuation  such that ,  and  shows that\n.Of course, this implies that putting together calculi for each of the connectives is not enough to fully characterize the way they interact in classical logic, as can be visually confirmed from the rules in Example\u00a03.\n As this point, we should question the scope of applicability of Theorem\u00a021, and how often we can expect to find naturally saturated PNmatrices as in the example above. What should we do when given PNmatrices that are not saturated? Fortunately, there is a simple way of transforming a PNmatrix into a saturated PNmatrix both characterizing the same single-conclusion logic\u00a0333Note that the operation works precisely by weakening the associated multiple-conclusion logic, a subject to which we will return later on..Let  with  be a PNmatrix. The -power of  is the PNmatrix  with  such that,, andfor every ,  and , we let  if and only if the following condition holds:For each  we use  to denote the obvious projection function, i.e., . Clearly, we have that  if and only if  for every .If  is a PNmatrix then  is saturated, and further we have .We first show that .Suppose that , and let  be such that .\nFor every , this means that  and thus that .\nWe conclude that  and so .Suppose now that , and let  be such that .\nEasily,  defined by  for every  is such that , and .\nTherefore, we have that  and therefore, for any , .\nWe conclude that .To show that  is saturated, let  be a consistent theory of , and fix .\nFor each formula  we know that there exists a valuation  such that  and .\nFix an enumeration  and define, for each , the valuation  such thatLet  be such that  for every .\nWe have that  because  for every ,\nand for every , we have that  because with  we have .\nWe conclude that  is saturated444The proof of Lemma\u00a024 actually shows that the bivaluations of  are closed for non-empty denumerable meets. This is enough, in our case, since the empty meet corresponds to the irrelevant  bivaluation, and also because non-denumerable meets are not necessary given that we always work with denumerable languages..\u220eThe following result follows easily from Theorem\u00a021\u00a0and\u00a0Lemma\u00a024.The combination of single-conclusion logics characterized by PNmatrices is the multiple-conclusion logic characterized by the strict product of their -powers, that is,\n.Though still usable, this result does not provide us with a finite-valued semantics for the combined logic, even if departing from finite-valued PNmatrices. Indeed, in the relevant cases, a -power PNmatrix is always infinite (and not even denumerable), the exceptions being -powers of PNmatrices with at most one truth-value, easily seen to be saturated to begin with. Note also that the situation is not unexpected, as we know that some combinations cannot be endowed with finite-valued semantics\u00a0[52], and it is playing the role of meet-closure in the case of bivaluations. Still, there are cases when saturation is not necessary (we will see a relevant example of this phenomenon in Subsection\u00a05.1 below), or when saturation can be achieved by a finite power of the given PNmatrix. We present some examples below, and further discuss this question in the conclusion of the paper.(Three-valued implications of Kleene and \u0141ukasiewicz).\nRecall Example\u00a014, where we discussed the combination of the three-valued implications of Kleene and \u0141ukasiewicz in the multiple-conclusion setting, with shared implication, and we concluded that the resulting logic coincided with the multiple-conclusion version of the implication-fragment of classical logic.Now, we shall see that, incidentally, the corresponding single-conclusion combination also coincides with classical implication, albeit for distinct reasons.\nFor easier readability, we recall here the signature  with  and  for , and the three-valued implication matrices of Kleene and \u0141ukasiewicz, namely  and\n, defined below.Concerning the combined logic ,\nTheorem\u00a021 cannot be applied directly as the matrices are not saturated, which renders the strict product obtained in Example\u00a014 useless as our envisaged semantics for the combined logic.Concerning , let . The theory is consistent, as in particular we have\n (as can be confirmed by any valuation  with ) and also\n (as witnessed by any valuation  with  and ). Therefore,\n. However, there is no valuation  such that , simply because if  and  then by just inspecting the truth-table we conclude that  and .Concerning , consider . The theory is consistent, as in particular we have\n (as can be confirmed by any valuation  with ),\n (as witnessed by any valuation  with  and ), and also\n (as witnessed by any valuation  with  and ). Therefore,\n. However, there is no valuation  such that , simply because if  then by just inspecting the truth-table we conclude that ,  and .We must therefore consider the -power of each of the matrices. Note that in both cases, the resulting truth-values are infinite denumerable tuples  with each , which for simplicity we will represent as pairs of sets  with  and .\nOf course, then, . The resulting set of truth-values corresponds to\n. As both matrices have  as their unique designated value, we also get in both cases that . The resulting matrices are thus\n and\n, defined according to the tables below.According to Theorem\u00a025, we know that  is characterized by the infinite -Pmatrix . Representing pairs of pairs as four-tuples we get the set of truth-values\n, and designated values\n. The resulting strict product is then\n as defined by the table below.This semantics has a non-trivial look, but it turns out that one can still draw valuable conclusions from it. Due to the partiality of  it is worth noting that the Pmatrix has a lot of spurious values  useless for valuations, that is, values such that  . Note that, if defined, . Of course, this happens only when , or otherwise we have a spurious value.This observation implies that if  then  never uses the  value of matrix . As  behaves classically for the  values, we conclude that all bivaluations in  are classical. On the other hand, we know from Lemmas\u00a011, 20 and\u00a024 that , because obviously . Since not just  but also  behaves classically for the  values, we conclude that all classical bivaluations are in . Thus, we have that  is precisely the implication fragment of classical logic.Again, we can confirm this fact by putting together calculi for the logics, according to Proposition\u00a02. Even without listing the rules, and since it is well known that , it suffices to check that all rules of the calculus for  (see Example\u00a03) obtain when we join them. The rule of modus ponens is unproblematic, as we have both  and . Concerning the classical axioms , or actually any other classical tautology , note that , simply because a valuation  such that  must be classical, as .\nOn the side of \u0141ukasiewicz, it is clear that  for any formula . Hence, in the combined logic, we know that  for each , and also that  which implies that  for any classical tautology .\n One must, of course, look again at the combination of fragments of classical logic, now in the single-conclusion setting.(Combining fragments of classical logic).\nRecall Example\u00a03, as well as the multiple-conclusion scenario that we have explored in Example\u00a013. We will now see how much challenging and interesting it is to combine fragments of classical logic in the single-conclusion setting, by means of four distinct cases.(1)\u00a0Let us first consider the combination of the fragments of classical logic corresponding to  and . It is easy to see that the corresponding two-valued classical matrices are both saturated. Hence, the combined logic  is directly characterized by the corresponding strict product, which coincides with the\ntwo-valued classical matrix for the fragment . We conclude thus, that , which is compatible with our knowledge that joining single-conclusion calculi for  and  yields a calculus for .(2)\u00a0Now, let us reanalyze the combination of  and . We already know from Examples\u00a018 and\u00a022 that the combination  is weaker than . However, since the two-valued classical matrix for negation is not saturated, we have instead considered an adequate three-valued saturated matrix. Of course, we did not need to know that such a matrix existed, and instead we could have blindly obtained the -power of the two-valued classical matrix for negation, and then obtained its strict product with the saturated two-valued classical matrix for negation. The semantics thus obtained would be less amiable, but still characterizes the combination. Alternatively, we could have noted that the four-valued -power of the matrix of negation would already be saturated (the three-valued matrix used before is a simplification of it).(3)\u00a0As a last interesting example of disjoint combination let us consider the fragments  and . We already know from\u00a0[21] that the combination  is weaker than . Namely, we have that , as can be confirmed by any valuation with\n and , which then implies that , on the Nmatrix resulting from the strict product of the two-valued classical matrix for conjunction and the -power of the two-valued classical matrix for disjunction, corresponding (after renaming) to  as defined by the tables below.Of course a simpler semantics would be desirable, but we know that the two-valued classical matrix for disjunction is not saturated. Namely, note that  and  but any valuation  of the two-valued matrix that sets  necessarily must have  or .(4)\u00a0Finally, we shall look at a non-disjoint example, the combination of the fragments corresponding to  and . It seems clear, from the calculus for  shown in Example\u00a03, that all rules involving negation or disjunction only additionally use the shared connective of implication. We may therefore conjecture that\n. To confirm this, we first note that none of the two-valued classical matrices for the fragments is saturated. This is simply because both include implication,  and\n but any classical valuation will have  or . Thus, we need to consider the strict product of the -power of each of the matrices, which results (after renaming) in the PNmatrix\n as defined by the tables below, where we use .All classical bivaluations can be simply obtained in  by taking only the two values  and .\nSeeing that all valuations of  are classical (i.e., they respect the operations in ) is slightly harder. Let .Easily, we have  and hence  for some . Consequently, for any formula , if  then  and thus , which implies , or equivalently .\nFurther,  for some  such that . We can see that , which means that  and thus that . Also, we can see that , which means that  and thus that . From these observations, we conclude that .Let  be any surjective function. We claim that the function defined by  is a valuation over  (on the relevant connectives), which is compatible with , as whenever  we have  if and only if . Namely, it is straightforward to check that  and , and also easy to see that  using the observations in the previous paragraph.\n \n4 Universal properties\nAccording to the very successful mathematical approach to General Systems Theory initiated by J. Goguen in\u00a0[44, 45], composition operations should always be explained by universal properties, in the sense of category theory\u00a0[49, 1]. This approach has been used also with respect to combinations of logics, for instance in\u00a0[18, 65]. Herein, we briefly show how our results are explained by simple universal constructions.\n4.1 PNmatrices and rexpansions\nIn order to explore the relationships among PNmatrices, let us consider a suitable notion of homomorphism. If ,  and  are PNmatrices, with  and , a strict homomorphism  is a function  such that , and for every , , and , .\nEasily, if  then . Further, the strictness condition  implies that  and  are compatible for every formula . Consequently, we have that\n, and therefore  both in the single and the multiple-conclusion cases. PNmatrices with strict homomorphisms constitute a category\u00a0.\nExpectedly, the strict product of PNmatrices as introduced in Definition\u00a010 enjoys a universal characterization, whose proof is straightforward.\nLet  and  be PNmatrices.\nTheir strict product  is a product in , with projection homomorphisms\n for each .\nIt goes without saying that the relationships between valuations in the PNmatrices  and valuations in  mediated by the projection homomorphisms that were presented in Section\u00a03.1 are simple consequences of the universal property enjoyed by products in a category.\nA dual construction is also possible. The key idea is that one can take crucial advantage of partiality to blend together PNmatrices. Let  be a set of PNmatrices, each .\nThe sum of  is the PNmatrix  where\n is defined by ,\n, and\nfor  and ,\n.\nIt is clear that  is a coproduct of  in\u00a0,\nwith inclusion homomorphisms  defined, for each  and each , by . Therefore, we have . Perhaps surprisingly, however, it may happen that\n.\n(A badly-behaved sum).\nLet  be the signature whose only connectives are  and , and consider the matrices  with  and , and  with  and .Easily, we have that  with  such that  for every formula . We also have that .However, it is clear that  contains bivaluations which are neither in  nor in . For instance, given a variable , it is clear that\n such that  if  occurs in A, and  otherwise, defines a valuation . Hence,  contains the bivaluation  such that  if and only if  does not occur in , which is clearly not in . \n4.1.1 The good, the bad, and the ugly\nNow, we will prove the (good, very good) fact that \u2018almost\u2019 every logic (in the single or multiple-conclusion sense, it does not matter) can be characterized by a single PNmatrix (actually, a Pmatrix). This property is striking, as it is well known to fail for matrices, or even Nmatrices (see\u00a0[22, 69, 73]), and at the same time reinforces the wide range of applicability of our results. The bad and the ugly are actually both related to the \u2018almost\u2019 part of our statement. On the one hand, we need to understand the reason for the exception, which actually lies on the (bad) fact that valuations on PNmatrices cannot be locally assessed for a sublanguage (or subsignature). On the other hand, the nature of the exception is related to a rather annoying (and mathematically ugly) syntactic property. Both are suitably illustrated by Example\u00a029, as the the crucial reason for the behaviour shown in this example is the absence of a 2-place connective (actually, of any connective with at least two places).\nLet  be a set of PNmatrices. If  for some \nthen .\nObserve that if  and  are such that  and  then it must be the case that . This is a consequence of the existence of a connective  for some , as  and, by definition, we have  if .Hence, it is clear that if  then letting  if  defines a valuation . As the compatibility of these values is granted by the definition of designated values in , it easily follows that .\u220eWe can now take advantage of well-known results about logical matrices.\nRecall that a Lindenbaum matrix over  is a matrix of the form  for some , with  for every , , and . Given a bivaluation , we will use  as a synonym for the Lindenbaum matrix\n.In the single-conclusion case, we know that a logic  is precisely characterized by the set of its theories\u00a0[73]. Hence, the Lindenbaum bundle  consists of the Lindenbaum matrices  over  such that  is a theory of  (when the logic is compact, we could as well consider only its relatively maximal theories).In the multiple-conclusion case, a logic  is known to be precisely characterized by its maximal theory-pairs\u00a0[69, 31, 77]. Thus, the Lindenbaum bundle  contains precisely the Lindenbaum matrices  over  such that  is a maximal theory-pair of  (see\u00a0[16]).Given a set of bivaluation  closed for substitutions, we also define  as consisting of the Lindenbaum matrices  for every .The following result is an immediate consequence of Lemma\u00a030, taking into account the Pmatrix corresponding to summing the Lindenbaum bundle into consideration.Let  be a logic.If  for some  then\n.We should note that when considering signatures with no connectives with two or more places, it really may happen that the logic characterized by a set of PNmatrices does not coincide with the logic characterized by their coproduct.(A badly-behaved sum, continued).\nRecall Example\u00a029, with a signature  whose only connectives are  and , and matrices  with  such that , and  with  such that . Let . Recall also that  contains the bivaluation  such that  if and only if  does not occur in , which is clearly not in .It is not hard to see that given any PNmatrix  with  such that  it must also be the case that . Namely, since we have , there exist valuations  such that  and  for every . Therefore, the valuation such thatcan be easily seen to be also in . Just note that , and that , because both  and  are in  and  occurs in  if and only if  occurs in . We conclude that .It turns out that it is impossible for a PNmatrix to have , and thus necessarily  for every PNmatrix .Moreover, it is easy to see that  is meet-closed, and that if  is such that  is closed for substitutions and  then one must have . Thus, it is impossible for a PNmatrix to have , and one can also conclude that  for every PNmatrix .For the sake of closure, we should note that  and  where  contains the two ruleswhich are both single-conclusioned rules simply because  is meet-closed. Indeed, we have that  if and only if  for some , and additionally  if and only if  and , i.e.,  is not a variable.\n \n4.2 Multiple-conclusion combination\nThe results of Section\u00a03, namely Proposition\u00a08, Lemma\u00a011 and Theorem\u00a012, allowed us to characterize the combination of the multiple-conclusion logics defined by two PNmatrices as the logic defined by the intersection of their induced bivaluations, or equivalently as the logic of their strict product. Our aim is to provide a categorial explanation for these results.\n\nQBValMult\n\nIn the terminology of\u00a0[6], that we extend here to PNmatrices,\nthe existence of a strict homomorphism  means that  is a rexpansion of . For simplicity, we will consider the quotient of\n obtained by identifying all strict homomorphisms between the same two PNmatrices, thus obtaining a thin category that we will dub . Equivalently,  consists of the preordered class of all PNmatrices under the rexpansion relation, and we write  precisely when  is a rexpansion of . The obvious quotient functor  that sends each PNmatrix to itself is trivially continuous and cocontinuous. Therefore,\nit follows that  is a (non-unique) join in ,\nand we can say that  is the least PNMatrix of which all PNmatrices in  are rexpansions.\nDually,  is a (non-unique) meet in , and we can say that the strict product of two PNmatrices is the largest PNmatrix that is a rexpansion of both  and .\nWe need also to consider the posetal category , consisting of all pairs  where  is a signature and  is closed for substitutions, partially ordered by the relation defined as  if  and . Easily, the mapping BVal extends easily to a (order-preserving) functor  such that . If we further define  by  we also obtain a (order-preserving) functor, which is actually left-adjoint to BVal.\nThe functors  constitute a Galois connection, that is, for every  in  and every  in , the following conditions are equivalent:,.\nFirst assume that , i.e., there exists a strict homomorphism . Obviously,\nwe have . Given , we have the inclusion homomorphism . Composing, we have  and therefore . We conclude that\n, and so\n.Reciprocally, assume that . This means that not only\n but also . The latter inclusion implies that for each  there exists  such that , and thus  is a strict homomorphism. The universal property of  then implies that there exists an homomorphism  (actually a unique one with the property that  for every ). We conclude that .\u220eConsequently, BVal preserves meets (limits) and we rediscover Lemma\u00a011, as then\n, which is easily seen to be equal to .Finally, we consider another posetal category , of multiple-conclusion logics ordered by inclusion, that is,  if  and . It is clear that a combined logic  is a join  in . The mapping  such that  is now easily seen to establish an order isomorphism between . and . is a dual order isomorphism, that is:Mult is bijective, and if and only if .Mult is bijective precisely because for every multiple-conclusion logic  there exists one unique set  such that . We know from\u00a0[69] that , which relates to the set of all maximal theory-pairs of the logic.As a consequence, just note that  is equivalent to having that, for every ,  implies . On its turn, the later is equivalent to having, for every , that , which actually means that for every  there exists  such that , or simply that .\u220eAs a consequence, we can recover Proposition\u00a08, because   which, by duality, is equal to .Theorem\u00a012 can also be recovered, simply, by noting that  , which is equal to\n .\n4.3 Single-conclusion combination\nThe results of Section\u00a03, namely Proposition\u00a016 and\nTheorems\u00a021 and\u00a025, allowed us to characterize the combination of the single-conclusion logics defined by two PNmatrices as the logic defined by the intersection of the meet-closure of their induced bivaluations, or equivalently as the logic of the strict product of their -powers (or the PNmatrices themselves, when saturated). In order to explain these results categorially, we can adopt a similar strategy.\n\nQSing\n\nGiven the properties of -powers, as stated in Lemma\u00a024, we can restrict our attention to the full subcategory  of  whose objects are just the saturated PNmatrices. We apply the same restriction to obtain the full subcategory  of . As we know that the strict product of saturated PNmatrices is still saturated, the operation will still correspond to a (non-unique) meet in . Interestingly, however, coproducts of saturated matrices need not be saturated.\n(Sums and saturation).\nLet  be the signature whose only connectives are  and , and consider the PNmatrix  with  such that , , , and the matrix  with  such that .Easily, we have that , and\n. Since  we can conclude from Lemma\u00a020 that both PNmatrices are saturated.However, the PNmatrix  is not saturated. In fact, it suffices to show that\n, which clearly contains the bivaluation , is not meet-closed.\nTo see this, fix a variable  and note that  such thatare valuations . Hence,  such that  if and only if  with  even, and  if and only if  with  odd, both are bivaluations . Letting  we have  such that  if and only if  occurs in . It is not difficult to conclude that , noting that  is the only value not designated and that\nany valuation  such that\n must have .\n \nFollowing the lines developed in Section\u00a03, we shall also consider\nthe full subcategory  of  whose objects are meet-closed sets of bivaluations.\nThe functor  is such that . The functor \nis defined by\n. The following result shows that, despite of Example\u00a035, it is well-defined.\nIf  is a signature and  is closed for substitutions and meet-closed then  is saturated.\nFor simplicity, let .The result is immediate if  contains a connective with two or more places. When that is the case, Lemma\u00a030 guarantees that . As one can easily check, for Lindenbaum matrices,\n is simply  closed for substitutions,\nand thus  since  is itself closed for substitutions. Therefore, we have that , and by Lemma\u00a020, since  is meet-closed, we can conclude that  is saturated.Things are less straightforward when  for every , since we know that the set  may include bivaluations not in . Indeed,\nletting\n be the unique atomic subformula of , one has  if and only if there exists a function  such that  for every formula . For simplicity, we use  instead of just  to denote each such substitution\n555To make it more explicit, this means that each valuation  can be made to correspond with\nchoosing a bivaluation  for each , and setting \n(which is designated precisely when ) for each formula .\nA similar characterization would apply, mutatis mutandis, to arbitrary coproducts of (total) Nmatrices over a signature without connectives with two or more places..To establish that  is saturated, using again Lemma\u00a020, it is sufficient to show that given  if the meet  then . First note that if  then it is the case that , and we can fix . For each  consider . As  is meet-closed, the meet , but it may still happen that . Define  byWe claim that . To see this, consider a formula  and let .If  then  if and only if  for every  if and only if .If, on the contrary, we have  this means that  for every . Therefore, it follows that , since  for every .\u220eSimilarly, we have that  is left-adjoint to .The functors  constitute a Galois connection, that is, for every  in  and every  in , the following conditions are equivalent:,.Let  be a meet-closed set of bivaluations closed for substitutions, and\n be a saturated PNmatrix.\nThe result follows from Proposition\u00a033. Indeed,  if and only if\n in , which is equivalent to having  in .\u220eConsequently,  preserves meets (limits). Note also that, in the category , we have that .Finally, we consider another posetal category , of single-conclusion logics ordered by inclusion, that is,  if  and . It is clear that a combined logic  is a join  in . The mapping  such that  is again an order isomorphism, now between  and . is a dual order isomorphism, that is:Sing is bijective, and if and only if .Sing is bijective precisely because for every single-conclusion logic  there exists one unique meet-closed set of bivaluations  such that . We know from\u00a0[73] that .As a consequence, just note that \nif and only if , just because  is meet-closed and thus, equivalently,\n.\u220eAs a consequence, we can recover Proposition\u00a016 too, just because we have which, by duality, equals \n .Theorem\u00a021 can also be recovered. If  and  are saturated PNmatrices, then note that  , which equals\n . Theorem\u00a025 also follows, by the same argument, using Lemma\u00a024.\n5 Examples and applications\nBesides illustrating examples, of which we have already shown a few, our aim is now to present concrete applications of the tools we defined for obtaining usable semantics for combined logics, namely with respect to the modular conception and analysis of logics.\n5.1 Adding axioms\nOften, one works with a single-conclusion logic which can then be streghtened by the addition of new axioms\u00a0[6, 26, 20] (and possibly also new syntax). Concretely, let  be a single-conclusion logic,  be a signature,  be a set of axiom schemata, and define . The strengthening of  with the schema axioms  is the single-conclusion logic \ndefined by  if and only if , for every .\nOur aim is to apply the ideas developed above in order to obtain a semantic characterization of  from a given semantic characterization of .\nIn terms of bivaluations, the following simple result from\u00a0[21] is instrumental.\nLet  be signatures,  closed for substitutions, and .\nThe single-conclusion logic  is characterized by .\nGiven , note that  if and only if there exists  such that  and  if and only if there exists  such that\n and  if and only if\n if and only if .\n\u220eClearly, . Of course,\n is easily seen to be meet-closed, but such a requirement is clearly not necessary for .With respect to PNmatrices, we can take advantage of non-determinism for building a simple semantics for the logic associated to the calculus whose rules are precisely  for each , also equivalently defined by the set of bivaluations .The Nmatrix  with  is defined by,, andfor every ,  and , we letIt is easy to characterize the properties of this construction.We have that .Easily, if  and  then necessarily . Therefore, we have .If  is such that , then we can easily build a compatible valuation  by letting\n for each . We conclude that .\u220eOf course, it is simple to check that  if and only if , and thus that\n. It is worth noting too that  is saturated.The strengthening with  of the single-conclusion logic characterized by a PNmatrix is the single-conclusion logic characterized by its strict product with , that is,\ngiven a PNmatrix , we have that\n.The result follows directly from Proposition\u00a039, and Lemma\u00a011\u00a0and\u00a041.With , note that we necessarily have\n.\u220eNote that this construction, though similar to the ones presented in the previous section, has a remarkable difference: the PNmatrix  does not need to be saturated.\nThe proof technique is essentially the same, but takes advantage of the fact that any set extending a theory of  is still a theory, as it retains all the instances of axioms. The end result, though, is still infinite-valued (denumerably infinite, now, provided  is denumerable), but has really interesting consequences.For instance, we have seen in Example\u00a04 that the logics defined by the rules of modus ponens and/or necessitation,can be given a very simple non-deterministic two-valued semantics. Hence, according to Theorem\u00a042, every logic obtained from these by the addition of axioms can be characterized by a denumerable PNmatrix, which of course includes every modal logic, normal or not. A most interesting consequence of this idea is shown in the following example.(Intuitionistic logic).\nFix a signature  containing the desired set of intuitionistic propositional connectives, including implication, i.e., . Also, fix a set of axioms  which together with the rule of modus ponens constitutes a calculus for intuitionistic propositional logic  ( could consist of just the first two axioms in the axiomatization of , in case implication is the only connective of ).Take a signature  whose only connective is implication, that is,  and consider the -Nmatrix  where  as defined in Example\u00a04. That is to say that  is the logic axiomatized by the rule of modus ponens.Obviously, , and Theorem\u00a042 tells us that it is characterized by the PNmatrix .\nSince  is finite and  is denumerable, we can conclude that  is denumerable, which means that intuitionistic propositional logic\ncan be characterized by a single denumerable PNmatrix. This is a remarkable property of PNmatrices, witnessing their compactification abilities, as it contrasts with the known fact that a characteristic matrix for intuitionistic logic needs to be non-denumerable\u00a0[43, 75, 73].  Nicer, finite-valued, semantics can be obtained in particularly well-behaved scenarios, which (unsurprisingly) do not include the examples above. We refer to reader to\u00a0[20] for further details.\n5.2 Axiomatizability by splitting\nObtaining symbolic calculi, or axiomatizations, for logics of interest, namely if presented by semantic means, is well-known to be a non-trivial task, even harder when one seeks particularly well-behaved calculi. Herein, we show that to some extent, our results about combined semantics can have an impact on the possibility of splitting this task into the problem of obtaining calculi for suitably defined syntactic fragments of the logic, which can then put together, in a modular way, to produce a calculus for the original logic. Indeed, in abstract, given a logic  we will be looking for ways to obtain logics  such that .\nConcretely, let  with  be a PNmatrix, and split the associated logical language into signatures  such that .\nFor , consider the component PNmatrix  where  is the reduct of  to the subsignature , that is  for every connective . Under which conditions can we obtain an axiomatization of  by just putting together axiomatizations of  and , in either the single and multiple-conclusion settings?\nIt is useful to introduce the following notation. Given , a formula  with , and values , we define . Given formulas  we will also use  to denote the formula  where  is a substitution such that .\nRecall from\u00a0[69, 54, 19] that  is said to be monadic provided that\nfor every two values  with  there exists a one-variable formula , to which we call a separator of  and , such that  and  and , or vice-versa. When all the separators  can be found in  for a subsignature , we say that the PNmatrix is -monadic.\nIf  is -monadic then .\nTaking advantage of rexpansions, and the universal property of strict products from Proposition\u00a028, it is clear that there are two identity strict homomorphisms  and , and thus there exists a strict homomorphism  (namely,  and  for every ). Therefore, we know .To prove the converse inclusion, we need to take into account that  may have spurious values, that is, pairs  such that  for whatever  and . Indeed, we can show that if  then it must be the case that , using the proviso of monadicity on the shared subsignature. Indeed, if  then there exists a separator  of  and . Easily, then,  which is impossible because the strict product does not have pairs of values where one is designated but not the other. Hence, it is easy to see that  such that  if , for each formula , defines a compatible valuation . We conclude that .\u220eWe can now state our split axiomatization result for multiple-conclusion logics.If  is an axiomatization of , for each , then  is an axiomatization of ,\nprovided that  is -monadic.Clearly, using Theorem\u00a012 along with Proposition\u00a02, we have\n, that is,  is an axiomatization of the multiple-conclusion logic characterized by the strict product . Using the monadicity proviso, Lemma\u00a044 ensures that  and therefore , which concludes the proof.\u220eThe previous result allows us to obtain a multiple-conclusion calculus for the logic characterized by a given PNmatrix by simply putting together calculi for simpler logics, under the appropriate provisos. For instance, taking advantage of techniques such as\u00a0[54], one can even obtain incrementally analytic axiomatizations for the logic of a given monadic PNmatrix.It is worth noting that the result of Theorem\u00a045 has some simple immediate consequences. Namely, it trivially applies to any PNmatrix having no more than one designated value and one undesignated value, namely in Boolean like PNmatrices like those in Examples\u00a03 and\u00a04, by simply using the separator  (this actually shows that one can provide axiomatizations for each connective separately, not just for fragments of classical logic, but also covering less common two-valued non-deterministic connectives). Let us look at another interesting example.(Kleene\u2019s strong three-valued logic, revisited).\nRecall the multiple-conclusion version of the implication-free fragment of Kleene\u2019s strong three-valued logic  from Example\u00a07, defined on the signature  containing the connectives . The characteristic four-valued -Pmatrix  is easily monadic, using  as its separators. Namely,  separates the designated values  from the undesignated values , and  separates  from , and also  from .Consider the splitting corresponding to the signatures  with  containing  and  containing , and let  and  be the corresponding reducts of .\nSince , Theorem\u00a045 tells us that we can obtain a calculus for  by simply joining calculi for the fragments  and .It is worth noting that in the multiple-conclusion calculus for  put forth in Example\u00a07, the rules where  does not appear constitute a calculus for , and the rules where  does not appear constitute a calculus for .\n In the following example we will see that monadicity in the shared language is only a sufficient condition for splitting axiomatizations, but that it really plays an important role in the result.(Three-valued \u0141ukasiewicz logic).\nExpanding from Example\u00a014, let us now consider the signature  with ,  and  for . The three-valued matrix of \u0141ukasiewicz for these connectives is  as defined below.Besides the familiar connectives of negation and implication, \nis a possibility operator that can be traced back to \u0141ukasiewicz and Tarski (see [72]).\n\nNote that  is definable as , and thus .The matrix  is monadic, namely using  as its separators, but also alternatively using\n, as both  and  separate  from . However, one cannot separate these values using only implication. This said, we could of course apply Theorem\u00a045 to splittings of signatures sharing , or , or both, as in the previous example. Instead, let us look at some more informative cases.(1) Let us first consider the splitting corresponding to the signatures  with  containing  and  containing , and let  and  be the corresponding reducts of .\nSince , Theorem\u00a045 cannot guarantee that we can obtain a calculus for  by simply joining calculi for the fragments  and . Indeed, this can never be the case as  is strictly weaker that the \u0141ukasiewicz logic . To see this, note that the strict product\n is defined by the tables belowand that , as witnessed by a valuation  with , , which necessarily has .This example shows that although the given PNmatrix, in this case , is both -monadic and -monadic, the splitting may behave badly precisely because  is not -monadic.(2) Let us now consider the splitting corresponding to the signatures  with  containing  and  containing , and let  and  be the corresponding reducts of .\nAgain, since , Theorem\u00a045 cannot guarantee that we can obtain a calculus for  by joining calculi for the fragments  and . However, in this particular case, it turns out that one can safely join split axiomatizations, simply because\n. To see this, note that the strict product\n is\nsimilar to the one above, but with implication interpreted now as in the table below.Clearly, all bivaluations in  are also in , namely if one considers the total component  whose tables, depicted below, are simply a renaming of the truth-tables of .This example shows that the requirement that the given PNmatrix is -monadic is sufficient, but not necessary, for the splitting axiomatization result to follow.\n Although obtaining axiomatizations for single-conclusion logics is known to be substantially harder, our line of reasoning may still apply, as long as we further demand saturation.If  is an axiomatization of , for each , then  is an axiomatization of ,\nprovided that  is -monadic and saturated.It is easy to see that if  is saturated, then  is also saturated, for . If  is a consistent theory of  then  is a consistent theory of . From the fact that  is saturated it follows that there exists  such that . If we set  such that  for every  it is clear that\n. Further,  because, for ,  if and only if  if and only if  if and only if .Using Theorem\u00a021 and Proposition\u00a02, we can conclude that\n, that is,  is an axiomatization of the single-conclusion logic characterized by the strict product . Using the monadicity proviso, now, Lemma\u00a044 ensures that  and therefore , which concludes the proof.\u220eNote that the saturation proviso makes the result of Theorem\u00a048 harder to use. In any case, the result is in line with the results of\u00a0[21], namely about the (im)possibility of independently axiomatizating each Boolean connective in fragments of classical logic.(Classical logic can hardly be split).\nRecall Example\u00a03, and the analysis of combined fragments of classical logic in the single-conclusion setting that we developed in Example\u00a027. Much as these combinations differ substantially from the multiple-conclusion case, also splitting axiomatizations of classical logic, universally possible in the multiple-conclusion scenario, as we saw above, become a rarity in the single-conclusion case.We have seen that classical matrices are always trivially monadic, but now Theorem\u00a048 further demands saturation. It turns out that the two-valued interpretation of most interesting classical connectives is not saturated, namely for fragments containing , , or , as we have seen previously, which leads mostly to the failure of split axiomatizations as already shown in Example\u00a027.Connectives whose interpretation is saturated include, however, , , and . Hence, Theorem\u00a048 tells us that fragments of classical logic corresponding to signatures  can be axiomatized by putting together axiomatizations for each of the connectives. Namely, as seen in Example\u00a027, joining single-conclusion calculi for  and  yields a calculus for .\n We next analyze another interesting example.(Axiomatizing information sources).\nRecall from Example\u00a06 the logic of information sources defined over the signature  containing the connectives  by the characteristic four-valued -Nmatrix\n. It is easy to see that  is -monadic, with separators .According to Theorem\u00a045, the observations above imply that a multiple-conclusion calculus for  can be obtained by joining multiple-conclusion calculi for fragments based on splitting signatures  such that  as long as .Further, the Nmatrix  is saturated. Given a consistent theory  of , it is easy to see that  where  is defined as follows.Actually, the saturation of  can also be seen as a consequence of the fact that  is axiomatized by a single-conclusion calculus.Hence, according to Theorem\u00a048, we know also that a single-conclusion calculus for  can be obtained by joining single-conclusion calculi for fragments based on splitting signatures  such that  as long as . This is apparent in the calculus put forth in Example\u00a06, if we consider  and .\n \n5.3 Decidability preservation\nTransference theorems have always been a main drive of the research in combining logics. Decidability is certainly one of the most desirable properties a logic should have, opening the way for the development of tool support for logical reasoning. There are some known results\u00a0[30, 51], namely with respect to disjoint combinations, but it is worth looking carefully at the semantic characterizations developed in the previous section, and analyzing their contribution to decidability preservation in general. That is, when given two decidable logics, under which conditions can we guarantee that their combination is still decidable?\n5.3.1 Deciding multiple-conclusion combined logics\nLet us first look at the decision problem for multiple-conclusion logics. We will say that a multiple-conclusion logic  is decidable if there exists an algorithm , which terminates when given any finite sets  as input, and outputs  if , and  if . According to this definition it is clear that one is actually deciding the compact version  of the logic, and hence we will henceforth assume, without loss of generality, that the logic at hand is compact.\nOf course, any logic characterized by a finite PNmatrix is decidable\u00a0[8]. This case covers the combination of any two logics when they are each characterized by a finite PNmatrix, given that the strict product operation preserves finiteness. But we can go beyond the finite-valued case.\nCorollary\u00a09 is quite appealing, and mathematically clean, but a decision procedure based on it would require (potentially) running through all partitions of the set of all formulas. As the similarity with cut for sets is striking, one may try to obtain a more usable version inspired by cut for a suitable finite set, namely in relation to the input, which we will dub context.\nIn general, we demand a context function  such that . Aiming at decidability preservation, of course, we will further require that  is finite for finite .\nLet  and  be sets of bivaluations closed for substitutions.\nWe say that  are -extensible when, for any finite set\n,\nif there exist  and  such that  for every , then there must exist  such that  for every .\nWe say that multiple-conclusion logics ,  are -extensible when  and  are the (unique) sets of bivaluations characterizing them, that is,  and , and  are themselves -extensible.\nThis definition has a more abstract alternative characterization.\nLet ,  be multiple-conclusion logics,  their combination, and  a context function. The following are equivalent:,  are -extensible;given any partition  of  for finite , if\n and  then\n.\nThe result is immediate, taking into account Proposition\u00a08 and the fact that, for each , the unique set of bivaluations characterizing\n is .\u220eWe can now obtain a more decidability-friendly version of Corollary\u00a09.Let ,  be -extensible multiple-conclusion logics, and consider their combination . For every finite , we have:Using Corollary\u00a09, if  then there exists a partition  of\n such that  and\n.\nIt is easy to see that  is a partition of , and by dilution,\n and\n.Reciprocally, if there is a partition  of  such that  and  then, directly from -extensibility and Lemma\u00a051, we can conclude that , or equivalently, since monotonicity implies that  and , that .\u220eWe now apply these ideas toward decidability preservation we assume that the context function  is computable.Let  be -extensible logics.\nIf  is computable and  are both decidable then their combination\n is also decidable.Let  be algorithms deciding , respectively.\nTo decide  consider the following non-deterministic algorithm .The correctness of  is an immediate consequence of Lemma\u00a052, noting that the no output is always correct, independently of the non-deterministic choice of the partition, whereas the yes output is only correct when it holds for all choices.\n\u220eLet  be PNmatrices with a total strict product .\nIf  are both decidable then their combination  is also decidable.Given Theorem\u00a053, it is enough to observe that  are -extensible whenever  is total. Note also that  is computable.Just note that given a set  and valuations  such that  is compatible with  for every , the function  defined by  is a prevaluation of . Therefore, as  is total,  extends to a valuation . Lemma\u00a011 thus guarantees the envisaged -extensibility property.\u220eIt should be noted that -extensibility, or totality of the strict product in the case of PNmatrices, is a sufficient condition for preserving decidability, but further research needs to be done in order to find tighter conditions.(Decidability preservation for disjoint combinations).\nA major result of\u00a0[51] was the preservation of decidability for disjoint combinations of single-conclusion logics. We will get back to this particular result in the next subsection, but for now we will show that decidability is preserved also by disjoint combination of multiple-conclusion logics. Assume that both  are decidable, and .As a first, partial, approach, let us consider the case when one knows that there exist (total) Nmatrices  such that  and . If each of the Nmatrices has both designated and undesignated values, it follows easily from Definition\u00a010 that  is also a (total) Nmatrix, and the combined logic  is decidable as a consequence of Corollary\u00a054.Of course, if any of the two Nmatrices only has all its values designated (or all undesignated), the corresponding component logic will be trivially decidable, and the same applies to the resulting combined logic. However, in general, there is no reason to assume that the given logics can be characterized by (total) Nmatrices. Still, a very general but simple argument can be drawn along the lines of Theorem\u00a053.In order to prove that  is decidable\nusing Theorem\u00a053, it suffices to show that  are -extensible for a suitable\ncomputable context function. Let  be a finite theorem-set of either  or , that is,  for some , if such a set exists. In that case, if  is the set of bivaluations characterizing  and  then it is clear that . When none of the component logics has a finite theorem-set then , and compactness implies that . Symmetrically, let  be a finite anti-theorem-set of either  or , that is,  for some , if such a set exists. In that case, if  then it is clear that . As before,  if none of the component logics has a finite anti-theorem-set, in which case compactness implies that .We consider , which can clearly be computed.\nSuppose now that  are the sets of bivaluations (closed for substitutions) characterizing the component logics ,\nand that  agree in  for some finite set , that is  for every .If  for every  then none of the component logics has a finite theorem-set, , and hence . On the other hand, if  for every  then none of the component logics has a finite anti-theorem-set, , and hence . Thus, we proceed knowing that we can fix formulas  such that  and .First we modify  so that they also agree on  (for simplicity, we chose to evaluate them all to ). Consider the substitution  such thatand let  and . Easily,  extend  on , and further agree on all formulas in .Inductively, let  and obtain bivaluations  extending the previous on , and further agreeing on . For each formula  with  we evaluate  and modify the skeleton variable  accordingly when building . Hence, consider for each  the substitution  such thatand set . Easily, if , or  and ,\nthen , and thus .\nFurthermore, if  and  then\n.Partitioning each  in two disjoint parts , and , for , it is clear that , , and also that  and  are a partition of . Further, each  shows precisely that . The compactness of both  and  then implies that\n and . Therefore, the bivaluation  such that  if , and  if  (resulting as a limit of the above sequences of bivaluations) is such that . Of course,  agrees with  on , which concludes the argument. We will further illustrate the use of such general results to concrete combined logics in the more familiar case, below, of single-conclusion logics.\nOf course, our general decidability preservation technique using a suitable context function resembles many of the decidability preservation techniques used in concrete examples, such as fusions of modal logics\u00a0[41], or even beyond in combining equational and first-order theories\u00a0[58, 57, 7, 71, 61]. A deeper account of the scope of the abstraction we propose is beyond the reach of this paper.\n5.3.2 Deciding single-conclusion combined logics\nAs before, the single-conclusion case can now be addressed as an application of the same ideas. A single-conclusion logic  is decidable if there exists an algorithm , which terminates when given any finite set  and formula  as input, and outputs  if , and  if . As before, we will henceforth assume with lost of generality that the logic at hand is compact, as this definition is equivalent to deciding the compact version  of the logic.\nThe following very simple result will help us to apply the ideas used in the multiple-conclusion scenario, to the single-conclusion case.\nThe following implications hold.If a multiple-conclusion logic  is decidable, then so is its single-conclusion companion .If a single-conclusion logic  is decidable, then so is its minimal multiple-conclusion counterpart .\nWe consider each property.Let , and  be an algorithm deciding .\nTo decide  consider the following algorithm .Clearly,  if and only if , and  decides .Let , and  be an algorithm deciding .\nTo decide  consider the following algorithm .Clearly,  if and only if  for some . Hence,  decides .\n\u220eNow, to go directly to the results, we say that single-conclusion logics ,  are -extensible when  and  are sets of bivaluations characterizing them, that is,  and , and their (uniquely determined) meet-closures  are -extensible.Again, this definition has a more abstract alternative characterization, based on theories.Let ,  be multiple-conclusion logics,  their combination, and  a context function. The following are equivalent:,  are -extensible;given  and theories  of  for , if\n then there exists a theory  of  such that .The result is immediate, taking into account Proposition\u00a016 and the fact that, for each , the unique meet-closed set of bivaluations characterizing\n is .\u220eAs before, we obtain a general decidability preservation result.Let  be -extensible logics. If  is computable and  are both decidable then their combination  is also decidable.Let  and , both closed for substitutions, be such that  and . From Proposition\u00a056\u00a0(b), we know that  and  are both decidable. From the hypothesis of -extensibility of , we know that  are -extensible, and thus also\n. Then, Theorem\u00a053 guarantees that  is decidable.\nBut we know that , and Proposition\u00a056\u00a0(a) guarantees that it is decidable.Putting together the algorithms obtained in the proofs of Theorem\u00a053 and Proposition\u00a056, if  are algorithms deciding , respectively, we obtain the following\nnon-deterministic algorithm  for deciding .\u220eLet us illustrate some particular applications of Theorem\u00a058.Let  be saturated PNmatrices with a total strict product .\nIf ,  are both decidable then also their combination  is decidable.Given Theorem\u00a058, it is enough to observe that  are -extensible whenever  is total.By saturation, Lemma\u00a020 guarantees that  for each . Their -extensibility follows easily from the fact that also  are -extensible, implied by the hypothesis that the strict product is total, as in the proof of Corollary\u00a054.\n\u220eThe case of disjoint combinations is also worth revisiting.(Decidability preservation for disjoint combinations, again).\nWe are now able to obtain a simple proof of the the major result of\u00a0[51]: the preservation of decidability for disjoint combinations of single-conclusion logics. Namely, let  be decidable and\n. Using Proposition\u00a056 we know that  are decidable as well, and the result in Example\u00a055 tells us that  is also decidable. Finally, note that using again Proposition\u00a056, we have that\n is decidable, and we know that\n.A more direct proof of the same result could instead be obtained from Theorem\u00a058, along an argument similar to the one used in Example\u00a055 for the multiple-conclusion setting. Ultimately, our results followed simply as applications of the corresponding results in the multiple-conclusion case. In any case, a result analogous to Lemma\u00a052 can still be obtained, which would imply Theorem\u00a058 and Corollary\u00a059, as well, and which can be understood as a decidability-friendly version of Corollary\u00a017.Let ,  be -extensible single-conclusion logics, and consider their combination . For every finite , we have:Using Corollary\u00a017, if  then there exists  such that  is a theory of both\n and\n. Easily then, one has  for each ,\nand .Reciprocally, if there is  such that , but with  for each  then\nit follows that \nand  are theories such that .\nThus, directly from -extensibility and Lemma\u00a057, we can conclude that\nthere exists a theory  of  such that\n.\nIt follows that  and we conclude that .\u220e\n6 Conclusion\nThe main contribution of this paper is the definition of a first modular semantics for combined logics, in both the single and multiple-conclusion scenarios.\nIt is worth emphasizing again that the analysis of the latter scenario was crucial for the development, due to its tight connection with bivaluations. Of course, bivaluations could be simply seen as partitions of the language, or as theories, but looking at them as semantic functions helps to smoothen the path to many-valued interpretations. Naturally, the adoption of PNmatrices as models was also fundamental, as partiality enables us to deal with possibly conflicting interpretations of shared language, whereas non-determinism makes it straightforward to accomodate language extensions.\nDiscovering the finiteness-preserving strict-product operation on PNmatrices and its universal property were certainly central to the results obtained.\nFurther, it should be said that it provides a solution to the problem at hand which is quite close to the abstract idea of Gabbay\u2019s fibring function\u00a0[38, 40, 18], and a very natural modular version of Schechter\u2019s proposal\u00a0[63]. Unfortunately, when combining single-conclusion logics, this is simply not enough. The solution we found uses the -power operation for saturation purposes, but at the expense of losing finite-valuedness. This path hinders the easy application of these techniques in practice for single-conclusion logics, in general, also because checking saturation does not seem to be a trivial task. Nevertheless, we have seen that -powers may ultimately be too radical a solution, namely as finite powers are sometimes sufficient. Clearly, a better understanding of saturation is necessary, namely also regarding its connection with admissibility of rules, as studied for instance in\u00a0[47, 27, 11].\nAt this point we should remark that the fact that we only consider logics defined by a single PNmatrix, instead of a collection of PNmatrices, is a simplifying assumption with almost no loss of generality, as we have shown that partiality allows for summing collections of PNmatrices whenever one has at least one connective with more than one place.\nThe three applications developed taking into account our semantic characterizations are also worth mentioning as valuable contributions.\nFirst, the construction of a semantics for strengthening a given many-valued logic with additional axioms is interesting in its implications, but just a reinterpretation of a result in\u00a0[20], where less general but finite semantics for certain well-behaved particular cases are also obtained. Nevertheless, obtaining a denumerable PNmatrix for intuitionistic propositional logic is a worth example of the compressing power of partiality and non-determinism, and deserves to be further explored, namely in connection with ideas for aproximating logics (see, for instance,\u00a0[9, 33, 42, 56, 59]).\nSecondly, studying conditions under which the problem of obtaining a calculus for a logic may be split into the problem of obtaining axiomatizations for suitable syntactically defined fragments of the logic is quite crucial for a modular understanding of combining logics. A related approach was considered in\u00a0[29], but aiming at a disjoint split with additional axioms. On the contrary, the results we obtain here are inline with ideas explored in\u00a0[21] concerning axiomatizations of classical logic, and fit well with our running track of research on extracting calculi for PNmatrices in an automated way, namely using monadicity requirements\u00a0[54, 19].\nThird, and last, having a clear semantics for combined logics is a crucial tool for studying their decidability. The very general criteria we obtained already cover previous results regarding disjoint combinations, as we have shown. We believe they are also powerful enough to encompass other results in the literature, like the decidability of fusions of modal logics\u00a0[74, 41], and even adaptations of Nelson-Oppen-like techniques for deciding certain equational and first-order theories\u00a0[58, 57, 7, 71, 61]. A thourough analysis of the complexity of the obtained decision algorithms was intentionally not addressed in this paper, but certainly deserves future attention.\n", "output": "We obtain, for the first time, a modular many-valued semantics for combined logics, which is built directly from many-valued semantics for the logics being combined, by means of suitable universal operations over partial non-deterministic logical matrices. Our constructions preserve finite-valuedness in the context of multiple-conclusion logics whereas, unsurprisingly, it may be lost in the context of single-conclusion logics. Besides illustrating our constructions over a wide range of examples, we also develop concrete applications of our semantic characterizations, namely regarding the semantics of strengthening a given many-valued logic with additional axioms, the study of conditions under which a given logic may be seen as a combination of simpler syntactically defined fragments whose calculi can be obtained independently and put together to form a calculus for the whole logic, and also general conditions for decidability to be preserved by the combination mechanism.", "question": "none", "title": "2202.02189", "qa_pairs": "none"}
{"input": "Adaptive Analytical Ray Tracing of Black Hole Photon Rings\n\n\nAlejandro C\u00e1rdenas-Avenda\u00f1o\n\n0000-0001-9528-1826\nPrinceton Gravity Initiative, Princeton University, Princeton, NJ 08544, USA\n\nPrograma de Matem\u00e1tica, Fundaci\u00f3n Universitaria Konrad Lorenz, 110231 Bogot\u00e1, Colombia\n\n\u2003\u2003\nAlexandru Lupsasca\n\n0000-0002-1559-6965\nPrinceton Gravity Initiative, Princeton University, Princeton, NJ 08544, USA\n\nDepartment of Physics & Astronomy, Vanderbilt University, Nashville, TN 37212, USA\n\n\u2003\u2003\nHengrui Zhu\n\n0000-0001-9027-4184\nPrinceton Gravity Initiative, Princeton University, Princeton, NJ 08544, USA\n\n\nI Introduction\nAccording to general relativity, black holes display unique lensing behavior: for instance, any two spatial points outside the event horizon are connected by infinitely many light rays, each of which executes a different number of orbits around the black hole under its extreme gravitational pull Darwin (1959); Luminet (1979); Ohanian (1987); Bozza (2010); Gralla\u00a0and\u00a0Lupsasca (2020a).\nAs a result, images of a black hole surrounded by a non-spherical, optically thin emission region decompose into a sequence of superimposed layers indexed by photon half-orbit number , with each layer consisting of a full lensed image of the main emission Gralla\u00a0et\u00a0al. (2019); Johnson\u00a0et\u00a0al. (2020); Gralla\u00a0and\u00a0Lupsasca (2020a); Hadar\u00a0et\u00a0al. (2021); Chael\u00a0et\u00a0al. (2021); Paugnat\u00a0et\u00a0al. (2022); Vincent\u00a0et\u00a0al. (2022).\nThe direct () layer typically displays a central dark area\u2014the black hole\u2014encircled by the weakly lensed, primary image of the accretion flow onto the hole, whose details depend sensitively on astrophysical conditions.\nOn the other hand, the higher- layers arise from photons on highly bent trajectories that are strongly lensed to form a series of narrow \u201cphoton rings.\u201d111For an animation of this effect, see: https://youtu.be/4-DvyMPs-gA.\nSpherical emission produces a \u201cshadow\u201d inside the critical curve Falcke\u00a0et\u00a0al. (2000); Narayan\u00a0et\u00a0al. (2019); Vincent\u00a0et\u00a0al. (2022).\nThese rings are usually stacked on top of the broader  emission and their shape rapidly converges (exponentially fast in ) to that of the \u201cKerr critical curve\u201d Bardeen (1973): a theoretical curve in the observer sky that corresponds to the apparent image of asymptotically bound photon orbits.\nIn contrast to the astrophysics-dependent  image, this \u201c photon ring\u201d is completely determined by the Kerr black hole\u2014depending only on its mass, spin and inclination\u2014and delineates its cross-sectional area in the sky.\nRecently, 1.3\u2009mm interferometric observations by the Event Horizon Telescope have resolved the horizon-scale emission from sources in the immediate vicinity of two nearby supermassive black holes: M87* Akiyama\u00a0et\u00a0al. (2019a), the central compact object at the core of our neighboring galaxy Messier 87, and Sgr\u00a0A* Akiyama\u00a0et\u00a0al. (2022a), our own black hole at the center of the Milky Way.\nTheir reconstructed images display a central brightness depression within a thick ring consistent with theoretical expectations for the direct image of the surrounding accretion flow Akiyama\u00a0et\u00a0al. (2019b); Arras\u00a0et\u00a0al. (2022); Carilli\u00a0and\u00a0Thyagarajan (2022); Lockhart\u00a0and\u00a0Gralla (2022a); Akiyama\u00a0et\u00a0al. (2022b).\nHowever, these observations have thus far not provided any evidence for the presence of a lensed photon ring Lockhart\u00a0and\u00a0Gralla (2022b).\nThey are instead dominated by  photons Gralla\u00a0et\u00a0al. (2019); Johnson\u00a0et\u00a0al. (2020), which form the image layer that is more sensitive to the astrophysics of the flow than to purely relativistic effects Gralla (2021); Lara\u00a0et\u00a0al. (2021); Bauer\u00a0et\u00a0al. (2022).\nAs a result, the bounds placed on possible deviations from general relativity are on the order of several percent Akiyama\u00a0et\u00a0al. (2019c, 2022c), and comparable to the constraints derived from gravitational-wave observations of stellar-mass, binary black holes C\u00e1rdenas-Avenda\u00f1o\u00a0et\u00a0al. (2020), or x-ray spectroscopy measurements of low-mass binaries and active galactic nuclei Ayzenberg\u00a0and\u00a0Bambi (2021).\nBy contrast, future detections of orbiting () photons will open a new window into strong gravity and enable higher-precision probes of the Kerr geometry, since it is this orbiting light which forms the part of the image\u2014the photon ring\u2014that belongs to the black hole itself, rather than to its plasma.\nThere are three major obstacles to measuring a photon ring.\nFirst, since the photon rings are exponentially narrow (in ) features, resolving them requires interferometric observations on exponentially long baselines Johnson\u00a0et\u00a0al. (2020).\nAt the current observing frequency of 230\u2009GHz, even Earth-spanning baselines are too short to resolve the first ring, but it should become accessible to next-generation space-based interferometers.\nIn particular, SALTUS (the Single Aperture Large Telescope for Universe Studies) is a bold proposal\u2014currently a contender for NASA\u2019s upcoming Probe mission\u2014to launch within the next decade a spacecraft far enough to access the first two rings of M87*.\nOptical depth poses a second hurdle: even though photons could in principle circumnavigate the black hole indefinitely (albeit unstably), in practice, those that traverse its emission region multiple times are eventually reabsorbed by the matter they intersect\u2014an effect that cuts off image layers past some .\nNevertheless, since absorptivity decreases with photon energy, the first few rings still ought to be present in images taken at sufficiently high frequencies.\nSimple models suggest that at 230\u2009GHz, the  ring is always visible while the  ring may only be marginally observable, whereas both rings should be clearly visible at 345\u2009GHz Vincent\u00a0et\u00a0al. (2022).\nState-of-the-art simulations of general-relativistic magnetohydrodynamic (GRMHD) flows Wong\u00a0et\u00a0al. (2022a) also confirm these expectations Wong\u00a0et\u00a0al. (2022b).\nFor this reason, SALTUS is slated to simultaneously observe at both frequencies.\nM87* makes for a particularly exciting prospective target because a measurement of its  ring diameter could deliver a stringent test of the Kerr hypothesis, which predicts a definite shape for its higher- rings: photons orbiting just outside the horizon of a black hole can probe its extreme gravity and carry away information about its spacetime geometry, encoded in the observable shape of the rings that these photons produce in their observer\u2019s sky Gralla (2020); Gralla\u00a0and\u00a0Lupsasca (2020b); Gralla\u00a0et\u00a0al. (2020).\nTime variability introduces a third significant complication.\nWhile time-averaged GRMHD-simulated movies have shown that the photon rings are persistent, sharp features that come to dominate observations with very-long-baseline interferometry (VLBI) after averaging over sufficiently long timescales Johnson\u00a0et\u00a0al. (2020), it remains to be understood how clearly visible the rings will be to a realistic, near-future, space-VLBI mission like SALTUS, which will be limited in the number of snapshots it can collect.\nIn each snapshot, such an interferometer\u2014with a single space leg\u2014can only sample the radio visibility on one space-ground baseline, thereby only measuring the projected diameter  of the photon ring at one angle  in the image.222The angle in the image corresponds to the space element\u2019s baseline angle in the Fourier plane Gralla (2020); Gralla\u00a0and\u00a0Lupsasca (2020b); Gralla\u00a0et\u00a0al. (2020), while the baseline length determines the index  of the subring whose interferometric signature dominates the signal Johnson\u00a0et\u00a0al. (2020); Paugnat\u00a0et\u00a0al. (2022).\nTo compensate for its sparse baseline coverage, the instrument can observe at regular intervals along its orbit around the Earth, eventually filling in every angle  in the Fourier domain, with each  thus sampled twice per orbit.\nThe baseline lengths over which the ring signature dominates the signal fix the orbital radius (about lunar distance for the  ring of M87*) and hence the orbital period ( month), which in turn sets the cadence of these snapshots: , or roughly every two weeks.\nAs it is evidently impractical to maintain coherence over such timescales, the snapshots must be incoherently time-averaged;\nmoreover, only  snapshots of  can be sampled per year.\nIn a single snapshot, the \u201cclean\u201d interferometric signature of the ring\u2014a periodic ringing in the visibility amplitude\u2014is typically \u201cpolluted\u201d by noise from both the instrument and from astrophysical fluctuations (plasma flares, emission ropes, or other ring mimickers), which can obscure the signal.\nThe key question is then:\nCan the interferometric signature of a photon ring\u2014and hence its projected diameter\u2014be recovered from an incoherent time-average over  snapshots of its visibility amplitude on very long space-ground baselines?\nAn affirmative answer to this question would open the door to a consistency test of the Kerr hypothesis\u2014a cornerstone of general relativity (GR) in the strong-field regime\u2014via space-VLBI measurements of the photon ring shape.\nThe paper\u00a0Gralla\u00a0et\u00a0al. (2020) (henceforth: GLM) took the first steps towards establishing the viability of such a test for M87*.\nGLM examined a range of models of stationary, axisymmetric, equatorial disks that reproduce the time-averaged observational appearance of GRMHD-simulated flows, and found that the observable shape of their  ring always follows a specific functional form, independent of the source model.\nThey concluded that this ring shape is a robust prediction of strong-field GR.\nIn other words, observations of the  photon ring can in principle disentangle gravitational and astrophysical effects that are otherwise commingled in the direct image.\nMoreover, GLM simulated interferometric data of the kind that could be collected by a mission like SALTUS, and were able to extract this ring shape from the visibility amplitude on space-ground baselines.\nTheir experimental forecast achieved a sub-percent level of precision for the resulting test of the Kerr hypothesis, suggesting that M87* holds exceptional promise as a target for such a test in practice.\nThis analysis was recently reviewed in depth and extended to an even larger selection of equatorial disk models, supporting these conclusions Paugnat\u00a0et\u00a0al. (2022).\nWhile these early results are encouraging, demonstrating the feasibility of a ring shape measurement requires further theoretical work.\nCrucially, even though the GLM analysis did include realistic instrument noise, it only considered time-averaged images of equatorial disks.\nThe latter limitation was recently tackled with a study of geometric thick-disk models Vincent\u00a0et\u00a0al. (2022), but to date a detailed investigation of source fluctuations and time variability has yet to be carried out.\nThe present work is the first attempt to remedy this lacuna.\nThe main obstruction is technical: as high-order photon rings are exponentially narrow compared to the overall structure of a black hole image, resolving them in the image plane incurs a large computational cost.\nMore precisely, their presence in the image introduces a large separation of scales between the pixel grid size (which must be large enough to capture the entire field of view) and the pixel spacing (the grid must achieve a sufficiently fine resolution to see the narrow rings).\nWhile a brute-force approach\u2014pumping millions of pixels in the grid\u2014can overcome this scale separation for a handful of images, it becomes intractable when dealing with a black hole movie consisting of several hundred snapshots, in which case adaptive ray tracing is necessary Wong (2021); Gelles\u00a0et\u00a0al. (2021) (and less wasteful).\nHere, we present a numerical tool333The code is publicly available at\u00a0https://github.com/iAART/aart. designed to efficiently compute high-resolution \u201cslow-light\u201d movies of generic (non-stationary and non-axisymmetric) equatorial sources around a Kerr black hole, together with their associated radio visibility on very long baselines; we present example outputs in Fig.\u00a01.\nThe code was developed with the intent to maximize speed while still guaranteeing the accuracy of its output, particularly the radio visibility on very long baselines, which encodes the high-frequency components of a snapshot\u2019s Fourier transform and is therefore extremely sensitive to its most minute image features.\nThe code\u2019s structure is highly modular and most of its individual components reproduce pre-existing capabilities; its main novelty is arguably to combine all these routines into one single and convenient-to-use (we hope!) package.\nOne new and important technique from which AART derives much of its power deserves special mention: it turns the very feature of photon rings that makes them so difficult to fully resolve\u2014namely, their thinness\u2014to its advantage.\nIt does so by decomposing the full image into multiple layers labeled by half-orbit number , and ray tracing in each layer the image of the  photon ring with exponentially high (in ) resolution.\nMore precisely, the lensing behavior of a black hole forces the  photon ring to lie within an exponentially small (in ) region of the image plane, dubbed the  lensing band, with each band completely fixed by the Kerr geometry Gralla\u00a0et\u00a0al. (2020); Paugnat\u00a0et\u00a0al. (2022).\nA key innovation of AART is to first compute (once and for all) the lensing bands associated with a given black hole spin and inclination, and then to ray trace, for the  layer, only pixels lying in the  lensing band.\nSince each lensing band contains an exponentially demagnified image of the main emission, by also increasing the resolution in each band exponentially,444Successive subrings are demagnified by an analytically known, angle-and-spin-dependent factor , where  is the Lyapunov exponent that governs the instability of nearly bound photons at orbital radius  Johnson\u00a0et\u00a0al. (2020); Gralla\u00a0and\u00a0Lupsasca (2020a). the code is guaranteed to resolve the source with roughly the same effective resolution in every layer.\nIn other words, AART adapts its ray-tracing resolution (grid spacing) to each layer, but also adjusts the ray-tracing region (grid size), so as to resolve the increasingly fine features present in higher layers using only a fixed number of pixels per layer.\nOther ray tracers use adaptive mesh refinement to increase pixel density in regions where they detect long geodesic path lengths Wong (2021) or large gradients Gelles\u00a0et\u00a0al. (2021); White (2022).\nThis results in a new, non-uniform grid for every new snapshot, which is recursively refined until a desired criterion is met, or else the number of recursions exceeds a hard-set limit.\nTherefore, small image features can sometimes be missed when this limit is hit.\nBy contrast, the adaptiveness provided by the lensing bands is determined by the Kerr geometry alone and results in the same, uniform grid for every image of a given black hole spin and inclination.\nThese grids therefore need be computed only once, and provided that their resolution increases at the proper rate set by the demagnification factor, they cannot miss any feature that is already resolved in the direct  image.\nFinally, high- layers comprise photons that execute many orbits in the Kerr photon shell Teo (2021) where their radial potential almost develops a double root and geodesic integrals diverge logarithmically, leading to a growing risk of numerical error.\nTo minimize error, AART performs analytical ray tracing using an exact solution of the Kerr null geodesic equation recently given in terms of Legendre elliptic integrals and Jacobi elliptic functions Gralla\u00a0and\u00a0Lupsasca (2020c), similar in spirit to previous implementations based on Carlson symmetric forms Dexter\u00a0and\u00a0Agol (2009); Yang\u00a0and\u00a0Wang (2014).\nTo summarize: AART uses lensing bands to prevent a large separation of scales (between the grid size and its spacing) and thereby maintain its speed as it increases the pixel density in higher- photon rings, which is necessary to ray trace the fine image features that (due to the nonlocal character of the Fourier transform) influence the visibility on long baselines; moreover, the rings are ray traced analytically to avoid errors.\nThese features of AART are specially tailored to the photon ring and its interferometric signature; with this tool in hand, it becomes feasible to investigate the effects of time variability on measurements of the  ring shape, and we can begin to answer the key experimental question posed above.\nTo study the effects of source fluctuations on the observed visibility amplitude, we call upon both AART and inoisy Lee\u00a0and\u00a0Gammie (2021): a code that can rapidly generate realizations of a 2D Gaussian random field with Mat\u00e9rn covariance.\nSuch a field can provide a simple statistical model for a generic (non-stationary and non-axisymmetric) stochastic source in the equatorial plane of a Kerr black hole, with prescribed two-point function.\nSince a \u201crealistic\u201d choice of autocorrelation structure is not yet known (and will require additional research into the plasma physics of the fluid), our goal will be to vary the statistics of the model within a wide range of \u201creasonable\u201d possibilities (informed by GRMHD simulations), so as to parameterize our uncertainty in the expected variability of signals from sources like M87*.\nCompleting such a parameter survey is a large undertaking beyond the scope of this first paper.\nHere, we will be content with a proof-of-concept demonstration that AART is up to the task for such a study.\nTo showcase its capabilities, we ray trace 100 snapshots of an inoisy source with statistics set by the \u201cbest-guess\u201d parameters for M87* (listed in Table\u00a02).\nSample snapshots and their associated visibility amplitude are shown in Fig.\u00a01, while Fig.\u00a02 includes all of the snapshots, with the left panel displaying their time-averaged image and the right panel all the individual visibility amplitudes together with their incoherent time average (solid lines).\nAs expected, we find that the astrophysical fluctuations wash out from the time average, leaving an image that is visibly dominated by a prominent photon ring with clear  and  subrings.\nCorrespondingly, the incoherently time-averaged visibility amplitude is dominated on long baselines by the perfectly clean interferometric signature of the  ring.\nIn particular, we find that the signal in the range G\u2014which a satellite at lunar distance from the Earth could access with \u2009GHz observations\u2014exactly follows the periodic ringing pattern predicted for a thin ring (black overlay in panel inset).\nAs we show in Fig.\u00a03, the projected diameter  of the  ring can then be extracted from the periodicity of this ringing in the visibility amplitude .\nThe top panels display the ring diameter  inferred from an average over  snapshots, with , and finally 100, by which time the smooth shape of the ring has emerged.\nThe bottom panels display the relative deviation from this fiducial shape that is induced by astrophysical fluctations, whose noise clearly averages out of the image; it is encouraging to see this noise is also beat down in measurements of the ring shape using only a few snapshots.\nOf course, whether these conclusions are likely to hold for M87* has yet to be established, and a systematic investigation of astrophysical fluctuations remains to be done.\nIn a soon-to-be-released paper, we will initiate such a study by repeating this analysis for multiple models of M87*, varying both the parameters of the black hole (its spin and inclination) and of the source (the inoisy model).\nWe also hope to report on the signature of the  ring and how it may encode the spin.\nWe now turn to a brief summary of the rest of the paper.\nSummary\nIn Sec.\u00a0II, we review the problem of light propagation in the Kerr spacetime.\nWe write down the null geodesic equation and its exact analytical solution as it is implemented in AART, and describe the key concept of lensing bands (Fig.\u00a04).\nWe then illustrate the lensing behavior of the black hole by plotting its \u201ctransfer functions\u201d: mappings of directions in the observer sky to the spacetime points where the corresponding light rays intersect the equatorial plane.\nThe transfer functions for polar coordinates  in the plane are shown in Figs.\u00a05, 6, and 9 for the , , and  images, respectively.\nLikewise, the time lapse  between source and observer is also shown in Figs.\u00a07 and 8 for the  and  images, respectively.\nThe  image always fills out the  lensing band, as expected.\nWe also give an approximate formula for light bending that was derived by Beloborodov Beloborodov (2002) for nonrotating black holes in the weak-deflection regime.\nWe express his result in a very simple form [Eq.\u00a0(43)] that proves to be remarkably accurate for the computation of  images of axisymmetric sources, for most black hole spins and inclinations.\nThis observation, which is illustrated in Fig.\u00a010, highlights the fact that  photons barely carry an imprint of the black hole spin, as they do not spend enough time near it to be strongly affected by its gravitational field.\nBeloborodov\u2019s approximation can thus be regarded as a generalization to all inclinations of the \u201cjust add one\u201d prescription for the transfer function of a spin-aligned observer, for whom the impact parameter  is simply related to emission radius  by adding one:  Gralla\u00a0and\u00a0Lupsasca (2020a); Gates\u00a0et\u00a0al. (2020).\nAART can also parallel transport linear polarization.\nWe check that Beloborodov\u2019s approximation is adequate for ray tracing  polarimetric images (Fig.\u00a011), which can be done using simple algebraic equations that we write down explicitly.\nIn Sec.\u00a0III, we describe our model of equatorial emission.\nFirst, we review stationary and axisymmetric equatorial disk profiles that can reproduce the time-averaged observational appearance of M87* in GRMHD simulations Gralla\u00a0et\u00a0al. (2020); Chael\u00a0et\u00a0al. (2021).\nThen, we add in astrophysical fluctuations with prescribed statistics.\nIn Sec.\u00a0IV, we use inoisy to simulate a variable source.\nWith AART, we ray trace its instantaneous snapshots (Fig.\u00a012) and compute its light curve (Fig.\u00a013).\nGreat care must be taken in the choice of resolution and field of view used in each layer: Sec.\u00a0V discusses these issues in depth (Figs.\u00a015, 16, and 14).\nWe can then produce movies of a stochastic, non-stationary, non-axisymmetric source. In Sec.\u00a0VI, we compute movies of the associated visibility amplitude and use this synthetic data to reconstruct the projected diameter  of the  ring, before concluding with a brief discussion of future prospects in Sec.VII.\nWe relegate some details to Apps.\u00a0A, B, and C.\nThroughout the paper, we work in  metric signature with geometric units in which .\nOur conventions for Legendre elliptic integrals are listed in App.\u00a0A of Ref.\u00a0Kapec\u00a0and\u00a0Lupsasca (2020).\nII Theoretical framework\nThe special integrability properties of the Kerr spacetime reduce its geodesic equation to a problem of quadratures Carter (1968), resulting in elliptic integrals that are expressible in Legendre normal form Rauch\u00a0and\u00a0Blandford (1994); V\u00e1zquez\u00a0and\u00a0Esteban (2004); Gralla\u00a0and\u00a0Lupsasca (2020c).\nModern computers can evaluate the Legendre elliptic integrals very fast and to arbitrary precision, reducing the computational cost of ray tracing in Kerr.\nIn this section, we review the exact solution of the Kerr null geodesic equation in Legendre form Gralla\u00a0and\u00a0Lupsasca (2020a, c) as well as the approximate solution derived in Schwarzschild by Beloborodov Beloborodov (2002), and we use them to plot the transfer functions mapping Bardeen\u2019s coordinates in the observer sky Bardeen (1973) to the equatorial plane.\nII.1 Null geodesics of the Kerr exterior\nAstrophysical, rotating black holes of mass  and angular momentum  are subject to the Kerr bound  and are described by the Kerr geometry, whose metric is written in Boyer-Lindquist coordinates  in terms of functions  and .\nThe roots of  give the outer/inner event horizon radiiWith respect to Mino time , a photon with four-momentum  follows a null geodesic  obtained by solvingThe resulting trajectory is independent of the photon energy  and can be parameterized by two conserved quantities: the energy-rescaled angular momentum and Carter constantWe are interested in solving for the trajectories  that connect two spacetime events  and , where the labels \u2018s\u2019 and \u2018o\u2019 stand for \u2018source\u2019 and \u2018observer\u2019, respectively.\nWe will specialize to distant observers () at nonzero inclination  above the equatorial plane  where we place the source.\nThe symmetries of the Kerr geometry\u2014its stationarity and axisymmetry\u2014allow us to set  and  without loss of generality.\nA photon that reaches an observer with four-momentum  and conserved quantities  appears in the sky at Cartesian position  given in terms of  by Bardeen Bardeen (1973),for .\nIf the photon carries a linear polarization, then its observed electric vector polarization angle (EVPA) is Li\u00a0et\u00a0al. (2009); Lupsasca\u00a0et\u00a0al. (2020); Himwich\u00a0et\u00a0al. (2020); Narayan\u00a0et\u00a0al. (2021)where  denotes the complex-valued Penrose\u2013Walker constanta quantity that is also conserved along null geodesics\u2014thanks to the Petrov type D nature of the Kerr metric Chandrasekhar (1983)\u2014and can be used to algebraically solve the parallel transport problem for a linear polarization vector  by evaluating  at the source.\nThe separability of Kerr geodesic motion allows the  and  trajectories to be decoupled Carter (1968),\nThese independent motions are then controlled by radial and angular geodesic potentialswhose zeros give the turning points of their respective motion.\nBoth potentials have exactly four (not always real) rootswhich depend only on the conserved quantities  via555Here,  denotes the real cube root of  if  is real, or else, the principal value of the function  (that is, the cubic root with maximal real part.)We will now restrict our attention to positive spins .\nII.2 Kerr critical curve\nThe radial potential (9) develops a double root at  (that is, ) if and only if Bardeen (1973); Gralla\u00a0and\u00a0Lupsasca (2020a)where  withA geodesic with critical conserved quantities  and  asymptotes to an unstably bound orbit at radius  in the Kerr photon shell.\nFor a distant observer, the Kerr critical curve  is the image in the sky of these asymptotically bound orbits:Though this purely theoretical curve is not in itself observable, it does play a key role in the study of lensing by a Kerr black hole\u00a0Bardeen\u00a0et\u00a0al. (1972).\nIt is traced using Eqs.\u00a0(4) evaluated on Eqs.\u00a0(19) for all the values  such that .\nIt is always closed, convex, and reflection-symmetric about the  axis Gralla\u00a0and\u00a0Lupsasca (2020b).\nII.3 Analytical backwards ray tracing\nThe character (real or complex) and ordering of the radial roots  (when they are real) lead to a classification of radial motion into four types Hackmann (2010); Gralla\u00a0and\u00a0Lupsasca (2020c); Comp\u00e8re\u00a0et\u00a0al. (2022).\nWe are, however, only interested in the rays that connect a distant observer to an equatorial source.\nThis excludes two of the motion types, leaving only two others corresponding to rays that start from infinity at one endpoint before they either cross the horizon or return to infinity at the other.666The angular motion also has two possible behaviors according to whether .\nWe ignore vortical rays with  as they cannot reach the equator Kapec\u00a0and\u00a0Lupsasca (2020).\nSuch rays always lie within the apparent image of the horizon.\nThe boundary between these two behaviors in the phase space of null geodesics constitutes the Kerr photon shell of asymptotically bound orbits, a special locus in phase space with emergent conformal symmetry Hadar\u00a0et\u00a0al. (2022).\nWe now describe how this separation is manifested in the sky.\nGiven a black hole spin and observer inclination , we can pick a direction  in the observer sky and shoot a light ray backwards into the geometry in that direction.\nSuch a ray will cross the equatorial plane a total number of times , which can be determined by computing the total Mino time  elapsed along the entire development of the trajectory.\nRays in the interior of the critical curve all fall into the black hole; that is, they encounter no radial turning point and terminate their motion across the Kerr exterior on the event horizon at .\nRays in the exterior of the critical curve are all deflected back to infinity; that is, their radial motion encounters a turning point at , whereupon they bounce back toward .\nThus, the critical curve (21) delineates the boundary between photon capture (its interior) and photon escape (its exterior), and may be regarded as the cross-sectional area of the hole.\nIn-between rays that lie exactly on  are trapped in the photon shell where they can in principle orbit forever; in practice, this never occurs because such orbits are unstable (or equivalently, because  is infinitely thin).\nLet  and define , , andwhere  is an incomplete elliptic integral of the first kind.\nThese functions are the antiderivatives (137) and (149), and all the radial geodesic integrals  are definite integrals that can be obtained from their respective antiderivative  as follows.\nIf a ray lies inside of , then its motion is, following the labelling introduced in Ref.\u00a0Gralla\u00a0and\u00a0Lupsasca (2020c), of type (2) when all roots are real (in which case ), or else of type (3) when  are complex-conjugate roots with .777There exist type (4) rays with both  and , but they are vortical.\nIn either case, the definite integrals down to radius  on the ray are\nIf a ray lies outside of , then its motion is always of type (2), and the definite integrals down to radius  on the ray arewith sign  before/after reaching the turning point at .\nThe Mino time  elapsed along a ray inside  is thusHence, the total Mino time elapsed along the full light ray isLikewise, the Mino time  elapsed along a ray outside  iswhere the sign is  before the turning point at  (), and  after the bounce ().\nHence, the total Mino time elapsed along the full light ray isand its radial turn occurs at the \u201chalf-way\u201d Mino timeWe will use  to denote the appropriate choice of .\nAt last, the total number of equatorial crossings  iswhere  denotes the Heaviside function while  and  are defined in Eqs.\u00a0(131)\u2013(132); see also App. A of Ref.\u00a0Paugnat\u00a0et\u00a0al. (2022).\nA light ray crosses the equatorial plane for the  time at Mino time , wherewith  given in Eq.\u00a0(128).\nThis equatorial crossing occurs atwith  given in Eqs.\u00a0(147) and (159) for type (2) and (3) geodesics, respectively, while the angular integrals  are given in Eqs.\u00a0(129)\u2013(130).\nMeanwhile, the radial integralsdecompose via Eqs.\u00a0(135)\u2013(A.2) into definite integrals that are to be evaluated via Eq.\u00a0(24) for rays inside  or via Eq.\u00a0(25) for rays outside , using the antiderivatives  given by Eqs.\u00a0(137)\u2013(140) for type (2) geodesics or Eqs.\u00a0(149)\u2013(A.2.2) for type (3) geodesics.\nIn practice, we take  to be very large but not infinite, for reasons described in Eq.\u00a0(41) below.\nII.4 Kerr lensing bands\nThe functions , , and  defined in Eqs.\u00a0(33)\u2013(35) are the \u201ctransfer functions\u201d that map the equatorial plane to its  lensed image in the observer sky, where the index  may be thought of as a photon half-orbit number Johnson\u00a0et\u00a0al. (2020); Gralla\u00a0and\u00a0Lupsasca (2020a).\nTo describe the lensing behavior of a Kerr black hole, it is helpful to draw contour plots of these function\u2014that is, level sets of fixed , , and  within each image layer .\nFirst, however, one must determine the regions of the image plane in which these functions have support.\nThis is a nontrivial problem because these functions always evaluate to some value: for instance,  always returns some source radius, even when the ray shot back from  does not in fact intersect the equatorial plane  times.\nIn such cases,  may sometimes be obviously unphysical (it could, for example, take a negative value), but not always.\nWe define the  lensing band to be image-plane subregion consisting of those rays that cross the equatorial plane at least  times after being shot back from the observer, before either terminating on the horizon (if they are shot back from inside the critical curve ) or else returning to infinity (if they are shot back from outside ) after an elapsed Mino time .\nBy definition, the  lensing band is the physical domain of the transfer functions , , and .\nThis definition also implies that it is the subregion of the image plane in which the function  defined in Eq.\u00a0(31) is precisely equal to .\nThis last observation leads us to a formula that characterizes the boundary of the  lensing band: it is the set of points  in the image plane for whichsuch that  jumps by one across the boundary of each lensing band.\nThis condition can equivalently be written aswith  given in Eq.\u00a0(128).\nThe  lensing bands have a different character than the  layer\u2014we now focus on the former and defer a discussion of the latter to the next section.\nEach  lensing band is annular in shape and foliated by contours of fixed , with every source radius mapping onto a unique closed curve within the band.\nMoreover, this bijective map is order-preserving: moving radially outwards within a band, one crosses contours of monotonically increasing .\nThus, the inner edge of the  lensing band is the  image of the equatorial event horizon (the contour of fixed ), while its outer edge is the  image of the equatorial circle at infinity (the contour of fixed ).\nRays that connect a distant observer to the event horizon cannot encounter a radial turning point along their trajectory, so the inner edge must always appear inside the critical curve.\nConversely, rays that connect a distant observer to infinity have to make a turn along their radial trajectory, so the outer edge must alway appears outside the critical curve.\nHence, the  lensing bands are annuli that always straddle the critical curve.\nSince successive images of a source are demagnified and appear exponentially closer to the critical curve Johnson\u00a0et\u00a0al. (2020); Gralla\u00a0and\u00a0Lupsasca (2020a), the lensing bands form a stack of nested annuli, as seen in Fig.\u00a04.\nTo summarize, the inner edge of the  lensing band is the solution of Eq.\u00a0(38) with  given in Eq.\u00a0(27), while its outer edge is the solution with  given in Eq.\u00a0(29).\nThe two sides of Eq.\u00a0(38) are continuous functions  and  of the image-plane position .\nIn practice, we use the following procedure to determine these edges.\nWe first select a set of polar angles  around the image plane, with associated positions  on the critical curve (21)\u2014that is,  is the point where the critical curve is intersected by the ray emanating from the origin at polar angle .\nNext, we parameterize these rays as .\nFor each , we compute  along the corresponding ray over the range .\nWe also compute  on the range  and  on the range .\nWe then determine the unique parameters  within each of these ranges such that .\nThese values correspond to the points  along the ray of constant  where it intersects the lensing band\u2019s outer and inner edges, respectively.\nConnecting the points  thus obtained at every angle  traces out the edges of the lensing band, which is finally obtained as the annular region between these two closed curves.\nThese boundaries\u2014and hence, the lensing band\u2014can be determined to arbitrarily high precision by sampling sufficiently many .\nTo check the computation, one can verify that for each ,  and  up to numerical error.888In principle, one could also determine the inner and outer boundaries of the  lensing band as those contours of fixed  (inside ) or fixed  (outside ), respectively, which are closest to .\nHowever, this method is impractical because  can vary significantly across these contours.\nYet, it is this very behavior that makes this check effective.\nFurther discussion of lensing bands may be found in Ref.\u00a0Paugnat\u00a0et\u00a0al. (2022).\nII.5 Apparent image of the horizon\nWe now return to the  lensing band, which (unlike its higher- counterparts) is noncompact.\nThis difference can be understood intuitively: if the black hole mass shrinks to zero, the  lensing bands must disappear with the hole, whereas the  band must extend to fill the entire image plane.\nMathematically, the equations in the previous section still hold.\nThe inner and outer edges of the  band are still the contours of fixed  and fixed , respectively.\nThese curves respectively correspond to the primary image of the equatorial event horizon (appearing inside ) and of the circle of infinite radius (appearing outside ).\nThe inner edge can be determined via the same root-finding procedure outlined above (with ), resulting in a closed curve  contained within the critical curve .\nOn the other hand, the outer edge is at infinity in the image plane (as it would be in flat space), so the  lensing band is no longer an annulus.\nInstead, it consists of the entire (unbounded) exterior of .\nMeanwhile, the interior of  may technically be viewed as the  band, since it consists of rays that never reach the equator before terminating on the horizon.\nIn an equatorial disk model, this region would be completely dark, giving rise to an \u201cinner shadow\u201d feature Chael\u00a0et\u00a0al. (2021), and may naturally be viewed as the apparent image of the horizon.\nIn Fig.\u00a04, we display this image as a shaded black region for the case of a black hole with spin  observed from an inclination .\nII.6 Analytic grid adaptiveness\nIt has long been known that images of the equatorial plane of a Kerr black hole are lensed into increasingly demagnified, compact regions of the image plane Luminet (1979); Beckwith\u00a0and\u00a0Done (2005).\nMore recently, this lensing behavior has been exploited to efficiently ray trace equatorial disk models in which the , 1, and 2 image components are all fully resolved Gralla\u00a0et\u00a0al. (2020).\nAART is designed with this goal in mind and is built around the lensing behavior of a Kerr black hole.\nIt ray traces images of an equatorial source layer-by-layer, using a non-uniform grid adapted to this layered structure.\nThe  image layer, which consists of the  image of the source, is only ray traced on pixels within the  lensing band, which is precisely the region of the image plane occupied by this image.\nAs a result, AART avoids computing unneeded pixels in each layer, substantially improving its efficiency.\nThis layer-by-layer approach naturally allows for different resolutions to be used in each image layer.\nThis is important because the exponential-in- demagnification of successive images of a source requires the use of exponentially higher resolutions to resolve the source at the same level of detail in higher- layers.\nAART increases the resolution in successive lensing bands by roughly the same demagnification factor  that shrinks them ( is a Lyapunov exponent governing the orbital instability of bound photon orbits\u00a0Johnson\u00a0et\u00a0al. (2020)) such that every image of the source is resolved by roughly the same number of pixels\u2014see Sec.\u00a0V for a more detailed discussion of the resolution requirements in each layer.\nThis approach enables ray tracing up to arbitrarily high  and ensures that all images of the source are equally well resolved, with a roughly fixed computational cost per layer.\nTo summarize, AART makes use of a non-uniform adaptive grid composed of multiple layers, each of which it ray traces at a resolution adapted to the lensing band that makes up the layer.\nSince the lensing bands are completely determined by the Kerr geometry via the analytic formula (38), this form of adaptiveness is analytic, with the ray tracing also carried out analytically using the exact transfer functions (33)\u2013(35).\nThis adaptiveness is purely geometrical and independent of image features or gradients (unlike, for example, the method in Refs.\u00a0Wong (2021); Gelles\u00a0et\u00a0al. (2021)).\nIn practice, to produce the  grid points, AART creates a Cartesian grid covering the desired area of the image plane, but excluding points in the apparent image of the horizon (that is, the interior of ).\nIn each  layer, the code produces a Cartesian grid of points in an area centered around the critical curve and then discards those points which do not lie within the  lensing band.\nNumerically, the code only keeps those points which lie within the concave hull of the points  and outside the concave hull of the points .\nWe caution the reader that the  bands are not always convex: at high inclinations and moderate to high spins, their edges may become non-convex curves, as may be seen for instance in the right column of Fig.\u00a06 for the  band or in Fig.\u00a09 for the  band.\nIn such cases, using the convex hull of the boundary points  to define the lensing band can produce an incorrect grid that overestimates the size of the band and includes points which do not really belong in it, which is why must use the concave hull instead.\nIn Fig.\u00a04, we display an example of an AART grid (with a coarse resolution for visualization purposes), which includes points in the  (orange dots),  (purple crosses) and  (magenta dots) lensing bands.\nII.7 Visualization of the equatorial transfer functions\nHaving defined the transfer functions (33)\u2013(35) that map the equatorial plane of a Kerr black hole onto the image plane of a distant observer, we will now illustrate their behavior with the help of contour plots.\nThough we have yet to describe their range, we have already elucidated their domain of definition: as described in Sec.\u00a0II.4, the functions , , and  are only physical within the corresponding  lensing band.\nFollowing Refs.\u00a0Luminet (1979); Gralla\u00a0and\u00a0Lupsasca (2020a), in Figs.\u00a05 and 6, we display contours of fixed  and , which foliate the  and  lensing bands, respectively.\nPhysically, these \u201cisoradial\u201d curves are the direct () and first relativistic () images of the rings of constant Boyer-Lindquist radius  in the equatorial plane .\nSince the  lensing band is unbounded,  has noncompact support, while  maps the entire Kerr equatorial plane into a finite annulus: the  lensing band.\nIn each band,  spans the entire range  once and only once, so every equatorial ring produces precisely one image in each lensing band.\nMoreover, the map  is order-preserving: the source radius grows monotonically in the radial direction.\nThese two figures also illustrate the behavior of  and  by painting the Kerr equatorial plane with a color wheel, as in Ref.\u00a0James\u00a0et\u00a0al. (2015).\nThis wheel changes colors across \u201cisopolar\u201d curves of fixed , which are drawn at every  in the source plane.\nTheir corresponding images\u2014the curves of fixed \u2014form a swirling pattern that illustrates the effects of frame-dragging.\nWe emphasize that this swirl is a purely geometric effect, and that gravitational redshift is not yet included at this stage (its effects will be described in Sec.\u00a0III below).\nUnlike ,  has a rather complicated range.\nWhile  spans the entire range  once and only once, so that every point source produces precisely one direct image (as in flat spacetime), as  grows large, the maps  cover this range an increasing (linearly divergent) number of times Gralla\u00a0et\u00a0al. (2018); Gates\u00a0et\u00a0al. (2020, 2021).\nAs a result, the equatorial plane is unfolded increasingly many times in higher lensing bands, which therefore contain multiple images of a single point source!\nThis surprising and intricate lensing behavior is connected to the development of caustics Bozza (2008) and will be explored elsewhere.\nWhile the transfer functions  and  suffice to describe the lensing of a static source, one still needs  to describe a time-dependent source and account for its time-delay effects.\nSince light takes forever to reach a distant observer that is truly at asymptotic infinity,  is technically infinite when .\nMore precisely, the null geodesic equation in Kerr dictates thatHence, the coordinate time elapsed along a geodesic grows aswith the leading linear divergence arising from the first term in Eq.\u00a0(39), and the subleading log-divergence from the second.\nBecause of these divergences,  is inherently dependent on the observer radius.\nHowever, subtracting these (\u201cinfrared\u201d) divergences yields a \u201crenormalized\u201d timewhich remains finite even as .\nMoreover, in this limit, the dependence on  drops out, and  tends to a constant along any outward-propagating light ray.\nIn the limit ,  and  is the future light cone of the origin.\nIn other words, in flat space, a ray emitted radially outwards from  at  reaches null infinity  with .\nWe display density plots of  and  in Figs.\u00a07 and 8, respectively.\nIn practice, to take the limit , we evaluate Eq.\u00a0(41) at a large value of .\nThe color scale in Fig.\u00a07 ensures that  is white and sits in the middle of the scale.\nAt higher spins and inclinations, the range of  grows wider and more skewed towards negative values.\nAccordingly, we use a different color scale in each panel.\nWe also display three contours of fixed time:  (solid),  (dashed), and  (dotted).\nThese \u201cisochronous\u201d curves may be either open or closed, and in some cases, they may even be composed of multiple disconnected segments, highlighting the warped nature of the black hole spacetime.\nThe range of  is always infinite in every lensing band.\nMore precisely, it is unbounded below but bounded above: the reason is that, if the entire equatorial plane emits light forever, then an observer can see light from arbitrarily far back in the past (emitted from regions that are either very close to the horizon or very far behind it) but it does take some minimum time for any light to reach an observer, even when it is emitted from the nearest point in the plane.\nIn Fig.\u00a07, we do not see arbitrarily large negative values of  because we have a finite resolution (and therefore do not have pixels that resolve rays arbitrarily close to the horizon) and because we cut off the disk at  (and therefore do not see rays emitted from farther behind the black hole).\nThe infinite range of  is more readily apparent in Fig.\u00a08, where we use a different color scale to highlight the divergent time elapsed along light rays at the edges of the lensing band: the inner edge consists of rays that asymptote to the horizon infinitely far back in the past, while the outer edge consists of rays that bounce back towards null infinity, incurring another time lapse that diverges as Eq.\u00a0(40).\nThe rapidly changing colors at the edges of the lensing band illustrate this behavior.\nAgain, the finite resolution near the inner edge, together with the cut-off at  near the outer edge, preclude us from resolving light rays emitted arbitrarily far back in the past.\nIn Fig.\u00a08, we chose a color scale spanning 99.9% of the range of time lapses sampled by the pixels making up the  grid.\nComparing Figs.\u00a07 and 8, we see that successive images of the equatorial plane are delayed by a time of order .\nLikewise, comparing the  image of the equatorial plane in Fig.\u00a06 to its  image in Fig.\u00a09 shows that successive images are not only time-delayed, but also demagnified and rotated.\nThis lensing behavior results in a self-similar photon ring substructure that is governed by Kerr critical exponents , , and , which respectively control the demagnification, rotation, and time delay of successive subring images Johnson\u00a0et\u00a0al. (2020); Gralla\u00a0and\u00a0Lupsasca (2020a).\nII.8 Analytic ray tracing with Beloborodov\u2019s approximation\nDirect () light rays experience the smallest deflection.\nIn Schwarzschild, Beloborodov used an ingenious expansion to derive an excellent analytic expression that approximates the trajectories of such rays Beloborodov (2002).\nHis small-deflection-angle expansion is remarkably effective because its leading, linear term only receives its first subleading correction from a cubic term with a small coefficient.\nTo describe this result, we defineIn terms of these variables, a straightforward manipulation of Beloborodov\u2019s formulas leads to the approximate expressionwhich is highly accurate for low-to-moderate inclinations , as shown in Fig.\u00a010.\nThe agreement may seem surprising in the Kerr case, since this formula is derived for Schwarzschild.\nIn practice, the approximation (43) is excellent for rays that never get within  of the black hole\u2014for rays that come closer and experience greater deflection, it remains good along the portion of the ray up to the first equatorial crossing, but breaks down afterward, once the deflection angle grows large.\nIntuitively, the reason Eq.\u00a0(43) holds even for nonzero spins is that  rays are only weakly lensed, and do not spend sufficient time orbiting the black hole to explore its geometry.\nTypically,  rays only come close enough to the black hole to probe the leading, monopole moment of its gravitational field (the mass), but are largely insensitive to its subleading, dipole moment (the spin), which contributes small corrections to the transder function in an inverse-radius expansion.999This observation also underlies the \u201cjust add one\u201d prescription\n, which gives an excellent approximation to the transfer function for a polar observer at  and for any value of the spin, as first noticed in Ref.\u00a0Gralla\u00a0and\u00a0Lupsasca (2020a) and then derived, along with subleading  corrections, in Ref.\u00a0Gates\u00a0et\u00a0al. (2020).\nWith a little effort, under the Beloborodov approximation for the direct image, one can show that the sign of the quantitywhere  is the Schwarzschild critical impact parameter (apparent image radius of the critical curve), determines whether a ray shot back from image-plane position  with , which must necessarily encounter a radial turning point, does so before () or after () first crossing the equatorial plane at radius (43).\nII.9 Photon four-momentum at equatorial crossings\nLastly, we describe how to compute the source momentum of a photon that is loaded onto a ray as it crosses the equator.\nThe four-momentum  of a Kerr photon iswhere  is the photon energy, while  and  are the radial and angular geodesic potentials (9)\u2013(10), which depend on the specific (energy-rescaled) angular momentum  and Carter constant  of the photon defined in Eq.\u00a0(3).\nA ray shot backwards from image-plane position  has conserved quantities  obtained by inverting Eq.\u00a0(4).\nWhen such a ray crosses the equatorial plane for the  time at the radius  given by Eq.\u00a0(33), a photon of energy  loaded onto the ray will have a geodesic momentum given by Eq.\u00a0(45) evaluated at  and  with those values of .\nThis specifies the momentum up to discrete signs .\nWe now describe how to also determine these two signs.\nFirst,  is trivial to compute, since  photons must be emitted towards the observer, so they always have .\nThis sign must flip at every crossing, soat the  equatorial crossing.\nAs for , two possibities arise.\nRays that appear inside the critical curve can never encounter a radial turning point and are therefore always outgoing; as such, for rays inside of , we always haveOn the other hand, rays that appear outside the critical curve do encounter a radial turning point at radius , which they reach at Mino time  given in Eq.\u00a0(30).\nHence, for rays outside of ,\n depends on whether the Mino time  of the  equatorial crossing, which is given in Eq.\u00a0(128), precedes or follows the radial turn at Mino time ; that is,\nWhen using the Beloborodov approximation from Sec.\u00a0II.8 to ray trace  images, one merely replaces the exact  in the preceding discussion by its approximation (43), which specifies the geodesic momentum at first equatorial crossing up to signs .\nThe angular sign is still .\nFor the radial sign , we must again distinguish between rays inside and outside , but this time the relevant critical curve is that of Schwarzschild: a circle of constant radius , where  and .\nRays inside  (with ) have  as always, while rays outside  with () have\nIII Equatorial emission model\nIn the previous section, we described how Kerr black holes lens light.\nWe will now introduce a simple, phenomenological model of electromagnetic emission from the equatorial plane and describe how to compute its observational appearance as seen by distant observers such as ourselves.\nIII.1 Intensity images\nOur goal is to compute an observed intensity  at every image-plane position .\nFor each pixel in the image, we compute  by tracing the corresponding ray backwards into the geometry; each time it passes through the emission region\u2014in this case, the equatorial plane\u2014we load additional photons onto the ray according to the local source intensity .\nSince  is the invariant number of photons of frequency  along a ray, it follows thatwhich generalizes to non-stationary and non-axisymmetric sources the analogous formula in Ref.\u00a0Gralla\u00a0et\u00a0al. (2020).\nIn this expression,  is a geometric \u201cfudge\u201d factor and  is the observed redshift, while the transfer functions , , and , which are given in Eqs.\u00a0(33)\u2013(35), denote the spacetime position of the ray\u2019s  equatorial crossing, with  ranging from 0 to the total number  of crossings given in Eq.\u00a0(31).\nThe factor  is meant to account for the (neglected) effects of geometrical thickness, which we can mimick with Gralla\u00a0et\u00a0al. (2020)The inclusion of this geometric factor significantly improves the agreement of this simplified equatorial model of emission with time-averaged radiative GRMHD simulations Chael\u00a0et\u00a0al. (2021).\nFinally, to derive the observed redshift , we must prescribe a four-velocity for the accretion flow of radiating matter.\nWe consider flows with a four-velocity of the general formwhere the angular and radial-infall velocities are defined asand  are the contravariant components of the four-velocity.\nIn App.\u00a0B, we introduce two purely circular flows: a geodesic, Keplerian flow , together with a non-geodesic, sub-Keplerian flow  obtained by rescaling the Keplerian angular momentum by a sub-Keplerianity parameter , such that  as .\nWe also introduce the four-velocity  of purely radial geodesic infall.\nThen, following Refs.\u00a0Pu\u00a0et\u00a0al. (2016); Vincent\u00a0et\u00a0al. (2022), we introduce a flow  given by a linear superposition of purely circular and purely radial motion.\nThe resulting combined motion, which we present and derive in detail in App.\u00a0B, is a non-geodesic family of flows with three parameters: the sub-Keplerianity factor , and two other parameters  and  controlling the radial and angular components of the superposition, respectively.\nFor ,  reduces to the -independent radial inflow .\nAt the other extreme, when ,  reduces to the sub-Keplerian flow , which for  recovers the circular-equatorial geodesic flow first used by Cunningham Cunningham (1975).\nWe summarize these flows in Table\u00a01.\nOnce a specific four-velocity (52) has been prescribed, the observed redshift is then given by [Eq.\u00a0(54)]where the conserved quantities  of the photon trajectory are related to its apparent position  via Eqs.\u00a0(4), while  denotes the sign of the photon radial momentum at its source whose computation is described in Sec.\u00a0II.9 above.\nGiven a black hole spin , an observer inclination , some prescribed accretion flow , and an equatorial emission profile , we now have everything needed to compute an observed image (50).\nTo summarize, the procedure is the following:determine the lensing bands as described in Sec.\u00a0II.4;in each lensing band, define a regular Cartesian grid of appropriate resolution\u2014the resulting grids (indexed by ) form the different image layers described in Sec.\u00a0II.6;for each pixel in a given layer, trace the corresponding ray back into the geometry and compute its equatorial crossings  using the transfer functions in Sec.\u00a0II.3;use the prescribed flow  to compute the redshift (54);finally, for each pixel in the image, use the equatorial crossings from 3, the redshift from 4, and the prescribed source profile  to compute the observed intensity (50).A key observation is that the source profile  only enters this procedure at the very last step.\nIn particular, steps 1 through 3 depend only on the black hole spin and observer inclination, and can therefore be computed once and for all for each choice of .\nThe output can then be reused for each new choice of accretion flow  or source profile , offering a significant time advantage (particularly when ray tracing movie frames).\nSome comments are in order about step 2.\nFirst, while there is no reason to favor regular grids in principle, they do offer computational advantages in practice, since many numerical algorithms (such as grid interpolation) are optimized for such grids.\nSecond, there is no real reason to favor Cartesian grids, and AART only relies on them for simplicity\u2014it may be, however, that for extremely high , regular but non-Cartesian grids become more computationally efficient.\nThird, the exact choice of \u201cappropriate resolution\u201d adapted to each grid will be described in detail in Sec.\u00a0V below.\nIII.2 Polarimetric images\nIn principle, besides the observed intensity (Stokes ), we could also ray trace the observed linear polarization (Stokes ) to obtain a polarimetric image.\nIn practice, rather than computing the Stokes parameters  and  separately, we will instead simply express the observed linear polarization aswhere  is a fractional degree of polarization and  denotes the EVPA (5).\nIn a realistic model,  itself would vary across the image, since the degree of polarization of a photon usually depends on the angle at which the corresponding light ray intersects the local magnetic field at the source.\nHere, we will be content to set  to a constant, resulting in sufficiently realistic polarimetric images for our purposes.\nIn effect, this amounts to assuming that our astrophysical source emits isotropically, which is a convenient choice that allows us to continue treating the emission profile  as a scalar, rather than a directed quantity.\nWith this choice (redefining the color scale to absorb the proportionality factor ), the magnitude  of the observed linear polarization is identical to the image intensity , leaving only its direction\u2014the EVPA\u2014as the sole new feature to be displayed in polarimetric images.\nWe indicate the orientation of the plane of polarization using \u201cpolarimetric ticks\u201d: these are polarization vectors Roberts\u00a0et\u00a0al. (1994); Himwich\u00a0et\u00a0al. (2020)where  is chosen to make the ticks legible and  is computed from a prescribed source polarization profile (described in the next section) that we parallel transport along light rays using the conservation of the Penrose-Walker constant  defined in Eq.\u00a0(6).101010A slighly more realistic synchrotron emission model would set , where  denotes the angle of emission relative to the local magnetic field, but including this non-isotropy does not produce a large effect Narayan\u00a0et\u00a0al. (2021).\nThe length  of the ticks also encodes the magnitude of the polarization, which improves readability.\nWe present an example of a polarimetric image in Fig.\u00a011.\nIn the remainder of this section, we describe the equatorial emission profiles implemented in AART.\nThe modularity of the code makes it easy to include any quantity of interest in the ray tracing, but we limit ourselves to Stokes  and  in this paper.\nIII.3 Stationary and axisymmetric source profiles\nState-of-the-art time-averaged GRMHD-simulated images of realistic sources can be mimicked by ray tracing images of stationary, axisymmetric, equatorial emission profiles Chael\u00a0et\u00a0al. (2021).\nSuch models therefore offer a computationally cheap way to study either time-independent or long-time-averaged sources.\nFollowing Gralla\u00a0et\u00a0al. (2020); Paugnat\u00a0et\u00a0al. (2022), we model such sources by settingwhere we take the radial profile  to be the analytic functionwhich is derived from Johnson\u2019s SU distribution and can be rapidly computed to arbitrary precision everywhere.\nThe three parameters , , and  respectively control the location of the profile\u2019s peak, its width, and the profile asymmetry.\nWe invite the reader to consult Sec.\u00a05 of Ref.\u00a0Paugnat\u00a0et\u00a0al. (2022) for a more in-depth description of these parameters and their interpretation.\nTo illustrate the computation of a polarimetric image and the validity of Beloborodov\u2019s approximation in Sec.\u00a0II.8, we now consider a black hole of spin  viewed from an inclination .\nThis is the case in Fig.\u00a010 for which the differences between the exact and approximate  are largest.\nWe focus on the  image layer, which we ray trace with both the exact transfer function (33) and its approximation (43).\nWe adopt Cunningham\u2019s prescription  (described in App.\u00a0B.1) for the accretion flow, resulting in the redshift  given by Eq.\u00a0(182) for sources outside the ISCO (B.1) and by Eq.\u00a0(B.1.2) for sources within.\nThis completes steps 1 through 4 above.\nIn step 5, we set  with  [Eq.\u00a0(1)], , and , so the emission peaks past the horizon.\nFinally, to prescribe the source polarization , we imposeThe first condition states that the polarization is perpendicular to the direction of light propagation\u2014this must by definition be true everywhere, including at the source.\nMeanwhile, the second condition implies that the polarization vector is purely spatial in the emitter frame, sincewhere Latin indices  label tensor components in the local orthonormal frame  of the emitter, with time leg , while Greek indices  label spacetime components.\nImposing this condition does not lead to any loss of generality.\nRather, it is simply a way to fix gauge: under gauge transformations, the polarization undergoes a gauge shift  Himwich\u00a0et\u00a0al. (2020) that leaves the first condition invariant but shifts  by .\nThus, setting  results in a gauge-fixed  that obeys the second condition by construction.\nLastly, the third condition asserts that the polarization is perpendicular to the spacetime vector .\nThis is the only physical assumption imposed by the relations (59).\nA suitable choice for modeling synchrotron emission is to let\n be the local magnetic field.111111As a technical aside, we emphasize here that the condition  is also crucial for the following reason.\nSuppose that we start with a polarization  which only obeys , while  and .\nThen a gauge shift  with  results in a physically equivalent polarization vector that obeys .\nThus, one can always make the initial polarization perpendicular to the magnetic field by applying a gauge transformation that leaves the observed polarization invariant.\nThe gauge-fixing condition in Eq.\u00a0(59) is therefore essential.\nTogether, the three conditions (59) determine three out of four components  of the source polarization, which suffices to fix its spacetime orientation and hence the observed EVPA.\nThe remaining component essentially controls the magnitude of the observed polarization, which in our model is not fixed at the source, but rather at the observer where we peg it to the observed intensity .\nMathematically, this prescription fixes the Penrose-Walker constant (6) up to an overall scale factor that drops out of the formula (5) for the EVPA .\nMore precisely, solving (59) yields, in terms of ,where, for clarity, we have temporarily dropped the subscripts \u2018s\u2019.\nLowering indices in Eq.\u00a0(6) and evaluating it at  then gives the source Penrose-Walker constant :\nThe computation of the photon momentum  at the source is described in Sec.\u00a0II.9, while the parameters  of the flow  are given in App.\u00a0B.1.\nThe component  that controls the magnitude of the polarization remains undetermined, but it factors out of both  and , and therefore drops out of the ratio in the formula (5) for the EVPA , as mentioned above.\nThe resulting explicit expressions are implemented in AART.\nAll that is left to specify are the spacetime components  of the local magnetic field.\nThe decomposition of the electromagnetic field strength  into electric and magnetic fields is frame-dependent.\nIn a realistic synchrotron emission model, the polarization would be perpendicular to the local magnetic field in the emitter frame, with components .\nFor our example, we simply choose the spacetime field  to be purely radial, keeping only a nonzero  component whose magnitude also scales out of the EVPA .\nWe display the resulting  images, ray traced using both the exact and approximate , in the left and right panels of Fig.\u00a011, respectively.\nEven though the corresponding isoradial curves (plotted in the right column of Fig.\u00a010) differ noticeably, the ray-traced images in Fig.\u00a011 nonetheless look very similar and would be indistinguishable with near-term observations.\nThe Beloborodov approximation is thus excellent for ray tracing direct images of axisymmetric source configurations.\nHaving showcased the polarimetric capabilities of AART, we now leave polarization aside and turn to variable sources.\nIII.4 Modeling variable sources with Gaussian random fields\nVariable (non-stationary and non-axisymmetric) sources can broadly be divided into two classes.\nOn the one hand, one can consider specific physical phenomena that are governed by deterministic equations.\nA commonly studied example is that of a \u201chot spot\u201d: a localized source of enhanced emissivity that usually orbits around the black hole and thereby produces a characteristic pattern of light echoes (see, e.g., Cunningham\u00a0and\u00a0Bardeen, 1973; Broderick\u00a0and\u00a0Loeb, 2005, 2006; Hamaus\u00a0et\u00a0al., 2009; Zamaninasab\u00a0et\u00a0al., 2010; Gralla\u00a0et\u00a0al., 2018).\nAdding such a source to our model is straightforward in AART: one merely needs to insert the deterministic source to the RHS of Eq.\u00a0(57) before carrying out the usual ray tracing.\nOn the other hand, one can also consider sources subject to statistical fluctuations.\nHot spots are transient and unlikely to be present in any given observation of M87*, but we certainly expect its surrounding plasma to flare and produce emission ropes (or other photon ring mimickers), which in the absence of a definite physical model we can still represent as random fluctuations in the astrophysical source.\nA widely used tool to model such astrophysical noise is the Gaussian random field (GRF); see, e.g., Ref.\u00a0Bardeen\u00a0et\u00a0al. (1986) for applications to cosmology.\nA random field  is a function on a space  such that  is a random variable for every .\nA GRF is a random field that is completely determined by its mean  and covariance ,More precisely, we define a random field  with mean  and covariance  to be a GRF if it satisfies the propertywhich states that its joint probability distribution on any set of  points , with , is a -dimensional multivariate Gaussian distribution with mean vector  and covariance matrix , where .\nThe following discussion is technical and readers interested only in applications may skip down to Sec.\u00a0III.8 below.\nThe mean and covariance are also known as the one-point and two-point (or autocorrelation) function, respectively.\nAs a result of the defining relation (67), these low-point correlation functions determine all higher -point functions of a GRF via Wick\u2019s theorem (also known as Isserlis\u2019 theorem), which may be derived by differentiation with respect to multiple .\nFor instance, letting  denote  for a zero-mean GRF, it is immediately seen by differentiating Eq.\u00a0(67) with respect to , , and  that  must have a vanishing three-point function, .\nAn additional derivative with respect to  implies that the four-point function  isIn general, for a zero-mean GRF, all -point functions vanish for  odd, whereas for  even they are given by all the possible \u201ccontractions\u201d of the two-point functions .\nThis is Wick\u2019s theorem in a nutshell, and it makes precise the idea that a GRF is a \u201csimple\u201d random field whose correlation structure is fully determined by two functions  and .\nThis property is very convenient for our modeling purposes, since only two functions need to be specified to prescribe all of the statistics of our astrophysical source.\nFor example, Wick\u2019s theorem also fixes all the even moments of a zero-mean GRF:where the  case is compatible with Eq.\u00a0(68) evaluated at coincident points.\n(Of course, the odd moments all vanish.)\nWe now specialize to GRFs in -dimensional Euclidean space .\nA GRF is homogeneous if it is invariant under translations, so  for , and it is isotropic if it looks the same in all directions, so  with .\nA real-space GRF  defines a (generally complex) GRF  in momentum space via the Fourier transformIf  is homogeneous, then we let  and Fourier transform its autocorrelation to derive the covariance of :Similarly, higher-point functions of  may also be obtained by Fourier transforming those of .\nOne finds that  is a GRF obeying Eq.\u00a0(67) with mean\n and covariance (74), which is also referred to as the power spectrum  of .\nWhen  is also isotropic, so is  with .\nLike covariances, power spectra are always non-negative.\nThe most ubiquitous GRF is the white noise process .\nIt is the standard, homogeneous and isotropic GRF defined by a flat power spectrum with uniform , so thatWith Eq.\u00a0(67), this delta-function autocorrelation implies that  consists of independent Gaussian random variables at every , and likewise in momentum space for .\nThus, creating realizations of white noise is trivial: it suffices to draw from independent normal distributions at every point.\nIn fact, Eq.\u00a0(74) provides a straightforward way to produce realizations of any homogeneous GRF : first, one creates a realization  of white noise; next, one multiplies it by  to obtain a realization of ; finally, inverse Fourier transforming  yields a realization of .\n(We note that this procedure is well-defined since .)\nJust as a standard Gaussian distribution has zero mean and unit variance, we define a standard GRF as a zero-mean GRF with unit covariance at the origin:  and .\nWe now consider the Mat\u00e9rn field  of order , which is another standard, homogeneous, and isotropic GRF that is well-known to statisticians, who use it to model a wide range of processes; see, e.g., Ref.\u00a0Guttorp\u00a0and\u00a0Gneiting (2006) for its various applications.\nThis zero-mean GRF obeys the Mat\u00e9rn covariance of order ,where  denotes the Gamma function and  the modified Bessel function of the second kind of order .\nHere,  is a correlation length, while  is a differentiability parameter that we will always take to be  for some positive integer .\nAt short distances,  for some constant , so it is best (though not strictly necessary) to require .\nThe Mat\u00e9rn field  is also ubiquitous in physics:\nthough its position-space covariance (77) may seem unfamiliar, in momentum space it becomes121212Equivalently,  with  as in Ref.\u00a0Lindgren\u00a0et\u00a0al. (2011). (see App.\u00a0C for a derivation)which for , or , we recognize as the quantum propagator for a free scalar field of mass  in Euclidean signature.\nTo the best of our knowledge, this link has not been stated explicitly before, and we explore it in detail in App.\u00a0C.\nThe Mat\u00e9rn field  enjoys a special connection to linear stochastic partial differential equations (SPDE).\nRealizations of its Fourier transform  are related to white noise viaSuch a relation holds for any homogeneous GRF, but it takes a particularly simple form for the Mat\u00e9rn covariance (78):Returning to position space gives the linear (fractional) SPDEwhich exactly matches Eq.\u00a0(2) of Ref.\u00a0Lindgren\u00a0et\u00a0al. (2011) since .\nAs we show in App.\u00a0C, for  and , this SPDE is compatible with the identification , where  is a free Euclidean scalar field of mass , as expected.\nIf instead,  and , then the resulting Mat\u00e9rn field, which we will simply denote , obeys a linear SPDEwhich has no fractional derivative and is thus simpler to solve numerically, as explained in Ref.\u00a0Lee\u00a0and\u00a0Gammie (2021) below Eq.\u00a0(3) therein.\nThis connection between the Mat\u00e9rn field  and a linear SPDE is especially useful once we introduce inhomogeneities.\nInhomogeneous GRFs are hard to generate via other means than solving the associated SPDE; in particular, the trick (79) for generating realizations of  breaks down because the Fourier modes are no longer delta-correlated as in Eq.\u00a0(74).\nIII.5 Inhomogeneous and anisotropic Mat\u00e9rn fields\nBefore describing how to include inhomogeneity, we first discuss how to model homogeneous anisotropies, following closely the excellent treatment in Ref.\u00a0Lee\u00a0and\u00a0Gammie (2021).\nStill in  dimensions, we introduce  orthonormal vectors ,  correlation lengths , with , and defineWe will also allow the unit vectors  to not be orthogonal, as long as  retains the same form.\nThe matrix  is invertible,\nand its inverse  defines a metric on  with line elementWe now use this to define the generalized Mat\u00e9rn covarianceWhen , so that , this reproduces the homogeneous, isotropic Mat\u00e9rn covariance (77), as desired.\nHowever, if the constants  are unequal, then the resulting GRF remains homogeneous but becomes anisotropic along a direction set by the unit vectors . An example with  is displayed in Fig.\u00a01 of Ref.\u00a0Lee\u00a0and\u00a0Gammie (2021).\nFollowing the steps that led to Eq.\u00a0(74), the corresponding momentum-space covariance isIn this case, we can still use Eq.\u00a0(79) to obtain realizations of the anisotropic Mat\u00e9rn field.\nWe can also follow the derivation of Eq.\u00a0(81) to find that the anisotropic field obeys the SPDE\nFinally, to include inhomogeneity, we allow the unit vectors  to become functions.\nThen  becomes a function too\u2014with the same definition (83)\u2014but the rest of the previous discussion breaks down.\nInstead, we must reverse the logic and define the inhomogeneous, anisotropic Mat\u00e9rn field  by the SPDE (87) with variable coefficients .\nWe emphasize that the resulting field  no longer obeys the covariance (86), which is not a function on momentum space once  is position-dependent, but it is a well-defined GRF arising as a solution to the SPDE (87); see also Ref.\u00a0Fuglstad\u00a0et\u00a0al. (2015).\nAs explained below Eq.\u00a0(81), in practice, we will only use the field  with  and  as it obeys the SPDEwhich has no fractional derivatives and is therefore more tractable numerically.\nSince we took our white noise to have unit variance, this SPDE exactly matches Eq.\u00a0(5) of Ref.\u00a0Lee\u00a0and\u00a0Gammie (2021) (after setting  therein), which is what inoisy solves.\nOne last comment is in order: in the inhomogeneous case, the Mat\u00e9rn field  that inoisy produces by numerically integrating Eq.\u00a0(88) does not follow the covariance (85); in particular, it may not be standard with  and .\nTo \u201cstandardize\u201d it, we will always work with a rescaled fieldwhich also happens to be precisely what inoisy implements.\nFor a homogeneous field, this makes no statistical difference.\nIII.6 Non-stationary and non-axisymmetric source profiles\nWith the inhomogenous, anisotropic Mat\u00e9rn field  in hand, we are now in a position to model the fluctuations of an equatorial accretion disk and produce inoisy simulations.\nBefore doing so, we first describe what we want to achieve intuitively, without being too rigorous.\nWe let .\nAs in Ref.\u00a0(Hadar\u00a0et\u00a0al., 2021), we want the total intensity (57) to consist of a background radial profile  with some fluctuations :Here,  is the fractional variation in the source, which at first we assume to be fractionally small: .\nWe also want these fluctuations to wash out under averaging,so that after averaging over fluctuations using , we recover the stationary, axisymmetric profile (57):\nEventually, we will also want to consider large fluctuations with , or , but this could pose a problem: if at some point , a fluctuation grew so large and negative that , then we would have , and hence  at that point, which is nonsensical because an intensity is a (necessarily positive) count of photons\u2014we must therefore prevent this from happening.\nOf course, we could demand that the fluctuations always remain small, but there is a way to allow them to grow large while still ensuring they do not result in a negative intensity.\nThe idea is to note that for small fluctuations , , so we may well replace the RHS of Eq.\u00a0(90) by a (necessarily positive) exponential:For small fluctuations, this seems completely equivalent, sincereproducing Eq.\u00a0(90).\nThe advantage of this definition is that it can now be freely extended to arbitrarily large , even in the negative direction: a fluctuation  would just result in a small but still positive (and hence still physical) intensity, rather than an unphysical, negative emissivity.\nHence, our new definition (93) for  remains sensible even for large and negative field excursions, unlike our first attempt (90).\nHowever, as we are about to see, this new definition suffers from a subtle issue: it does not actually satisfy Eq.\u00a0(92). For now, we use \u2018\u2019 to remind us of this, and proceed naively.\nThe preceding intuitive discussion hinges on being able to produce a fluctuation field  with some desired properties, such as Eq.\u00a0(91).\nWe now make this mathematically precise.\nWe replace , where  is the standard, zero-mean Mat\u00e9rn field defined in Eq.\u00a0(89) as the solution to the SPDE (87).\nWe then define an emissivity field Lee\u00a0and\u00a0Gammie (2021)where the parameter  controls the scale of the fluctuations, since  has unit covariance .\nBecause  has zero mean, Eq.\u00a0(91) is satisfied.\nLet us now check Eq.\u00a0(92):where we series-expanded the exponential and used linearity of the expectation value.\nThen by Eq.\u00a0(69), relabeling ,Evaluating the sum results inand we now see why the definition (93) is not what we wanted,\nsince it does not satisfy the requirement (92).\nInstead, we letwhich does have the desired property (92), and hence recovers the background profile (57) after averaging.\nWe note that this can also be checked directly from the property (67) with ,by taking  and  with  and .\nThis also shows that  effectively rescales the covariance .\nIn particular, the fluctuations disappear as  and we recover the pure envelope  of the background surface brightness.\nIII.7 Complete statistics of the variable source\nWe can also use the GRF property to explicitly write down the complete correlation structure of the random field .\nWith , ,  and , Eq.\u00a0(67) becomesSince ,This result characterizes all the statistics of the variable source  in terms of a single covariance function, as advertized.\nOf course, this formula with  confirms that Eq.\u00a0(92) holds.\nMeanwhile, for  the double sum in the exponential is  so we obtain the two-point functionwhich is the exponential of the Mat\u00e9rn field\u2019s autocorrelation.\nGoing further, for  the double sum in the exponential is  soand one can check that  is a non-Gaussian random field.\nThat is, it does not quite obey the GRF property (67), though its statistics (102) are still governed by a single covariance.\nFor some intuition, let us reexamine the fractional variation , whose statistics are encoded in the random fieldIts one-point and two-point functions areIf the fluctuations are very small, then this is approximatelywhich is the autocorrelation of a GRF with covariance .\nThis is also true for higher-point functions, using Eq.\u00a0(102), we can show that the field  is approximately Gaussian at leading order in .\nThus, small fluctuations are Gaussian, but larger fluctuations introduce non-Gaussianities.\nIII.8 Generating realizations of an accretion flow using inoisy\nTo summarize, we model variable sources via the emissivity (99), which is defined in terms of the Mat\u00e9rn field (89) and displays the correlation structure (102).\nThe zero-mean field  and its statistics are fully determined by its covariance, which is controlled by a metric  of the form (83).\nGiven such a metric, a realization of  is obtained by solving the linear SPDE (88) with some realization  of white noise.\nThis is essentially what inoisy does, though in practice, the continuous SPDE (88) is actually discretized and its solution is a Gaussian Markov random field approximating  Lee\u00a0and\u00a0Gammie (2021).\nAs for the envelope , we use the radial profile (58).\nTherefore, all we need to do to specify our model is to fix a choice of unit vectors  and correlation lengths , where now .\nSuch a choice will define  and hence our non-stationary, non-axisymetric stochastic source profile.\nSince we want to produce \u201crealistic\u201d images and visibility amplitudes, we will choose  to be an inhomogeneous, anisotropic Mat\u00e9rn field whose power spectrum is comparable to that observed in GRMHD simulations Lee\u00a0and\u00a0Gammie (2021), and therefore serves as a good phenomenological model.\nInstead of , we use a regular Cartesian grid  in the Kerr equatorial plane, and inoisy solves the SPDE (88) on this grid with periodic boundary conditions.\nFollowing Eq.\u00a0(83), we pick a position-dependent anisotropyUnder this prescription,  sets the temporal correlation of the flow, with characteristic correlation time , while  and  determine its spatial structure, which at any given time exhibits correlations of characteristic lengths  and , respectively.\nFollowing Ref.\u00a0Lee\u00a0and\u00a0Gammie (2021), we take these 3D unit vectors to have  componentswhere we have yet to specify , , and .\nIn practice, we will only let these functions depend on the spatial position .\nWe note that  are always orthogonal to each other, but not to .\nNonetheless, the resulting  still has a determinant of the form required by Eq.\u00a0(83), since .\nAlso, the sign of  and  is arbitrary, as it only sets the spatial correlation; the flow in time is set by .\nTo be consistent with our choice of accretion flow (52), we must take the temporal correlations to have the same velocity:where  and  respectively denote the angular and radial-infall velocities (53). In Cartesian coordinates this velocity becomes  withAs for the spatial correlations, we adopt the prescription Lee\u00a0and\u00a0Gammie (2021)This sets the major axis  of the spatial correlation tensor to lie at a constant angle  relative to the equatorial circles of constant radius .\nThe resulting flow displays spiral features with opening angle .\nThe choice  produces spiral arms broadly consistent with GRMHD simulations Guan\u00a0et\u00a0al. (2009); Lee\u00a0and\u00a0Gammie (2021).\nThis completes the specification of our stochastic surface brightness.\nTo summarize, the accretion flow model takes as input twelve parameters, each of which is listed in Table\u00a02, along with a short description and the default value used for the main examples in this paper.\nTo compute images, we must also specify three more parameters: the black hole spin , the observer inclination , and the mass-to-distance ratiowhich combines the black hole mass  and observer distance , and which is defined relative to a fiducial value for M87*.\nIV Applications\nHaving fully described our stochastic source model, we can now simulate it with inoisy and then use AART to ray trace its appearance and compute its visibility.\nWe will present a whole suite of simulations in a follow-up paper, but for now we limit ourselves to one complete example from which Figs.\u00a01, 2, and 3 are derived.\nWe first explain in detail how to obtain Figs.\u00a01 and 2, while Fig.\u00a03 will be the focus of Sec.\u00a0VI below.\nFor this simulation, we ran inoisy on a regular Cartesian grid  of size .\nFor each of the spatial coordinates , we uniformly placed 2048 pixels within the range , resulting in a spacing of  between pixels, whereas for the time coordinate , we placed 512 pixels uniformly within the range , resulting in a cadence of one frame every .\nWe used the default values listed in Table\u00a02 for the fifteen parameters in the model.\nThe left panel in Fig.\u00a012 shows an example of a snapshot extracted from the resulting inoisy run.\nThe accretion flow appears qualitatively similar to GRMHD-simulated flows.\nIn particular, we tuned the scale  of fluctuations to ensure that the total observed flux (the blue light curve in Fig.\u00a013) varies by a factor of  between its minimum and maximum.\nThis level of variability mimicks the light curves obtained from GRMHD simulations: see, for example, Figs.\u00a03 and 4 of Ref.\u00a0Noble\u00a0and\u00a0Krolik (2009), Fig.\u00a08 of Ref.\u00a0Chatterjee\u00a0et\u00a0al. (2020) or Fig.\u00a05 of Ref.\u00a0Wong\u00a0et\u00a0al. (2022a).\nEnsuring that this agreement also holds quantitatively is an interesting challenge that we hope to tackle in the future.\nIV.1 Fast-light: stationary non-axisymmetric source\nAfter producing our inoisy simulation, we use AART to ray trace it.\nA commonly adopted simplification in carrying out ray tracing is the so-called \u201cfast-light\u201d approximation.\nWhen staring at a variable source, a single frame  of its observational appearance at a fixed moment in time is formed by photons that were emitted at different times  in the history of the source.\nThe reason is that photons that appear at different positions  in the image plane follow different paths in the geometry, thereby incurring different time delays  on their way from source to observer, as shown in Figs.\u00a07 and\u00a08.\nThe fast-light approximation simply ignores this variable time delay and maps the image plane  onto a single snapshot of the equatorial plane, using only the transfer functions  and  from Sec.\u00a0II.3 and replacing Eq.\u00a0(50) byMathematically, this is equivalent to keeping the emission time  fixed while letting the observation time  vary across the image.\nNaturally, if the source is stationary, then this is a moot distinction since the time-dependence drops out anyway, so this amounts to treating each individual inoisy snapshot as a stationary (though non-axisymmetric) source.\nThus, the fast-light approximation is exact for a stationary source, and it can offer a decent approximation as long as the source varies slowly relative to the \u201cfast\u201d light being traced, hence the name.\nAs an example, we take the first () snapshot from our inoisy simulation and ray trace it as described in Sec.\u00a0II.3, assuming a black hole spin of  and an observer inclination of .\nIn the  layer, we ray trace at the same spatial resolution as the underlying inoisy simulation; that is, we use a spacing of  between grid pixels.\nIn the higher- layers, we adaptively increase the resolution by a factor of two in each successive band, and ray trace on grids with spacings of  between pixels.\nThe right panel of Fig.\u00a012 displays the resulting image (in a logarithmic color scale to highlight the accretion flow), which looks qualitatively similar to the single snapshots produced with state-of-the-art GRMHD simulations Chael\u00a0et\u00a0al. (2021); Wong\u00a0et\u00a0al. (2022a).\nThe figure also displays a decomposition of the image into its  layers, which are shown individually in the inset panels.\nEach separate layer appears well-resolved, suggesting that our grid resolutions are sufficient to resolve the photon rings.\nIndeed, we have verified (using a convergence test detailed in Sec.\u00a0V) that the results derived from the observable of interest (which in our case is the visibility amplitude, presented in Sec.\u00a0IV.3 below) do not change when the resolutions are doubled.\nIV.2 Slow-light: non-stationary non-axisymmetric source\nWith the transfer functions (33)\u2013(35) implemented in AART, it is also easy to perform a \u201cslow-light\u201d ray-tracing that takes into account varying photon emission times across the image.\nWe simply use Eq.\u00a0(50) and plug in all the transfer functions defined in Sec.\u00a0II.3.\nThis requires us to use the entire series of snapshots generated by inoisy; that is, we must now use the full time evolution of the accretion flow.\nSlow-light tracing does introduce two new complications.\nFirst, since the pixels in a single frame of a movie of the source can depend on a very wide range of emission times , in order to produce a movie of some duration , we typically need to simulate the source over a longer duration .\nIn practice, we can estimate how much longer  needs to be by examining isochronal curves in the  layer, such as those displayed in Fig.\u00a07.\nAt low inclinations, the range of  over sampled pixels is about , but this range grows much larger at higher inclinations.\nIn addition, the higher- images are comprised of photons emitted roughly a time  earlier, so in order to ray trace a movie containing  layers, we expect to need .\nSome rays may occasionally require sampling the source even earlier than the start of the simulation, but this is not really an issue with inoisy thanks to its use of periodic boundary conditions (including in time).\nSecond, because  varies smoothly across the image plane, the code must be able to sample the source  for continuous values of , including at times in between the frames computed by inoisy.\nThis problem can be dealt with using interpolation, but only so long as the underlying inoisy simulation has sufficiently high resolution to smoothly resolve the flow\u2019s motion.\nThis is the case in our example simulation, as the inoisy movie of the equatorial source has high enough cadence to be smoothly interpolated in time.\nThus, AART readily produces a movie of the source (whose parameters are listed in Table\u00a02).\nWe display four snapshots from this movie, taken at intervals of , in the top row of Fig.\u00a01.\nWe also plot its light curves in Fig.\u00a013: the total observed flux (measured in the image plane) and total emitted flux (measured in the equatorial plane) are shown in blue and green, respectively, with the former appearing smoother and less variable than the latter due to relativistic effects.\nAs in the stationary (fast-light) case, the snapshot images in Fig.\u00a01 present bright transient features that are qualitatively similar to those seen in state-of-the-art snapshots of GRMHD simulations Chael\u00a0et\u00a0al. (2021); Wong\u00a0et\u00a0al. (2022a).\nThese transient features can obscure the photon ring in instantaneous snapshots, but they wash out of the average over 100 snapshots in Fig.\u00a02, leaving the photon ring as the only prominent feature in the time-averaged image shown in the left panel.\nThis image can be directly compared the one shown in Fig.\u00a01 of Ref.\u00a0Johnson\u00a0et\u00a0al. (2020), which was also obtained by time-averaging over 100 uniformly spaced snapshots taken from a GRMHD simulation with a time range of .\nIV.3 Visibility on long baselines\nA radio interferometer like the EHT samples a (complex) radio visibility .\nBy the van Cittert-Zernike theorem, this is related to a sky brightness  via a 2D Fourier transformHere,  are dimensionless image-plane coordinates measured in radians, such as , while the dimensionless vector  is a \u201cbaseline\u201d projected onto the plane perpendicular to the line of sight and measured in units of the observation wavelength Roberts\u00a0et\u00a0al. (1994).\nWe use radio-astronomy conventions to make this Fourier transform -symmetric, unlike the definition (70).\nTherefore, to relate simulated images to actual observables, we must Fourier transform them to compute their visibility.\nIn particular, the narrow image features\u2014like the photon rings\u2014that encode precise information about the spacetime dominate the interferometric signal on very long baselines  Johnson\u00a0et\u00a0al. (2020); Gralla\u00a0et\u00a0al. (2020), requiring us to compute Fourier transforms up to very high frequencies.\nTo do so, we again exploit the layered image structure: since the observed intensity (50) decomposes intowith  denoting the  image layer, we can likewise use the linearity of the Fourier transform (117) to decompose the total complex visibility into individual subring components:The subring images  with  consist of narrow rings of characteristic widths  (where  is a Lyapunov exponent) and roughly equal intensities.\nHence the total flux  of the  image layer also scales like  Johnson\u00a0et\u00a0al. (2020).\nMoreover, a narrow ring produces a characteristic, weak  power-law falloff in its Fourier transform: indeed one can show that in the regimethe visibility (117) in polar coordinates  of a ring of diameter  and width  takes the \u201cuniversal\u201d form Gralla (2020); Gralla\u00a0and\u00a0Lupsasca (2020b)where  encodes the polar intensity profile around the ring, while  and  are its projected diameter and centroid displacement at angle  in the image, respectively.\nAs first pointed out in Ref.\u00a0Johnson\u00a0et\u00a0al. (2020), this suggests that the  photon ring dominates the interferometric signal in the regimewhere  is the width of the  subring, producing a characteristic cascading structure of damped oscillations with periodicity encoding the diameter of successive subrings; see also Secs.\u00a02 and 4 of Ref.\u00a0Paugnat\u00a0et\u00a0al. (2022) for a more detailed discussion.\nSince we compute images layer-by-layer\u2014as described in Sec.\u00a0II.6\u2014with a different grid and resolution in each layer , it is convenient to also compute the visibility layer-by-layer as well, and obtain each  as the Fourier transform (119) of .\nInstead of taking this 2D Fourier transform directly, as in Refs.\u00a0Gralla\u00a0et\u00a0al. (2020); Paugnat\u00a0et\u00a0al. (2022), we make use of the projection-slice theorem to compute  along slices of fixed polar angle  in the Fourier plane.\nThe procedure is as follows.\nFor each angle , we first compute the Radon transform along the cut at angle  across the image; that is, in each lensing band, we integrate the observed intensity  along lines perpendicular to the slice of constant .\nThen, we interpolate each Radon transform to the resolution of the highest-order lensing band.\nLastly, we sum up the contributions from all the image layers , and perform a one-dimensional Fourier transform to finally obtain .\nThe bottom row of Fig.\u00a01 presents the visibility amplitudes  along slices of constant  (in red) and  (in blue) of the corresponding snapshots in the top row.\nSince these individual snapshots display a strong dependence on the variable emission profile, the visibility amplitudes also exhibit a large variability.\nNevertheless, as we mentioned previously, these fluctuations wash out under time-averaging, leaving the characteristic ringing signature of the photon ring as the main persistent feature that dominates the visibility.\nWe also display the visibility amplitudes at baseline angles  and  (again, in red and blue, respectively) for our 100 snapshots in the right panel of Fig.\u00a02.\nTheir incoherent time-average is also shown with bold solid lines.\n\u201cIncoherent\u201d here means that the averaging is performed at the level of the visibility amplitudes , as in a realistic experiment Gralla\u00a0et\u00a0al. (2020), rather than at the level of the complex visibilities themselves, before taking the amplitude\u2014these operations (averaging and taking amplitudes) do not commute for complex quantities.\n(Experimentally, the latter type of \u201ccoherent\u201d time-averaging would require tracking the visibility phase over the course of all observations, which is beyond our near-term capabilities.)\nThese time-averaged amplitudes can be directly compared to those of a radial profile; see, e.g., Figs.\u00a04 and 5 of Ref.\u00a0Gralla\u00a0et\u00a0al. (2020).\nV Ray tracing requirements\nAs described in Sec.\u00a0II.6, we decompose images into layers labeled by photon half-orbit number  and ray trace each layer separately.\nIn principle, one can choose any grid resolution in each lensing band.\nIn practice, however, these resolutions must be sufficiently high to resolve the image features present in each layer.\nOtherwise, the output is not a faithful image of the source, and the resulting visibility is likewise inaccurate.\nIn addition, the  lensing band occupies all of the image plane, whereas the  grid must of course have a finite size.\nHence, the direct image of the source may need truncatation, which could in turn introduce errors in the visibility.\nIn this section, we describe the requirements on grid resolution and size that must be met in order to ensure that both the image and visibility of a source are correctly computed.\nWe also strive to explain the types of errors encountered when these requirements are not met.\nWe first discuss grid resolution and then grid size.\nA finite resolution erases small-scale features and a finite field of view cuts off large-scale features, but these effects can be remedied with the use of interpolation and extrapolation, respectively.\nV.1 Resolution requirements\nV.1.1 Requirements on the underlying simulation of the source\nWhen computing images of some source model , we must be able to sample the source intensity  at arbitrary  within the range of the simulation.\nThis is because the transfer functions (33)\u2013(35) vary smoothly across the image plane, as discussed in Sec.\u00a0II.7 and as illustrated in Figs.\u00a05 through 9.\nFor a stationary and axisymmetric source profile of the form (57), this requirement is trivial, since we typically specify the radial profile  analytically, as we did in Eq.\u00a0(58) with Johnson\u2019s SU distribution (which can be computed anywhere to arbitrary precision).\nOn the other hand, if the source profile  is not known exactly, then we must define it everywhere in the range where it is to be sampled via interpolation.\nIn that case, it is important that the interpolation be done on a dense grid, so that we do not miss any features of the source.\nIn practice, this means that if its smallest features are of size , then before interpolating the source, we must first sample it on a grid with pixel spacing .\nOtherwise, if the grid spacing is some , then we may miss a feature of size  in between two successive grid points  and , leading to an error in both the computed image and its visibility.\nMoreover, the grid density must be high enough to resolve all the features in the source with many points, so as to ensure that the resulting interpolation is smooth: if some features are underresolved (for instance, if a bump in a radial profile has only one point underneath it), then interpolation will produce spurious sharp features in the image that will have a significant impact on its Fourier transform, and hence the visibility.\nThus,  is not enough\u2014we must in fact require that .131313This smooth interpolation effectively defines the source down to arbitrarily small length scales by decreeing that no new features appear below size , which is the minimal (most conservative) \u201cultraviolet completion\u201d of the model.\nAny other choice would modify the visibility on baselines  and should then be specified as part of the model itself, rather than by fiat.\nFor the GRFs that we introduced in Sec.\u00a0III to model astrophysical fluctuations, this means that the spacing between grid points  must be smaller than the characteristic size of fluctuations, which is set by the correlation lengths  with .\nThat is, we require a grid spacing .\nWe reiterate that interpolation is unavoidable here because the inoisy simulation grid does not coincide (barring some incredible fine-tuning) with the equatorial crossings of rays traced backwards from points in the image-plane grids.\nV.1.2 Requirements on the image grids used in ray tracing\nWe now describe the resolutions needed in the grids used to ray trace within each lensing band, as described in Sec.\u00a0II.6.\nFor the direct  image, we must ray trace on a grid with spacing  for precisely the same reasons as listed above for the underlying model\u2014provided we do so, we will not miss any image features and they will all be well resolved.\nLikewise, in the higher- layers, we must ray trace on grids with exponentially fine spacings .\nThe reason is simply that if the smallest feature in the  image is of size , then its  mirror image in the  lensing band will be roughly of size .\nTo avoid missing these features (or underresolving them), we must demand that , a condition that is automatically satisfied with this adaptive grid scaling tailored to the Kerr lensing behavior.\nProvided that each image layer is ray traced at a sufficiently high resolution to ensure that no sub-grid structure is omitted, we can safely interpolate the image layers .\nIn turn, we can evaluate their Radon transforms along any desired slice, and then take a 1D Fourier transform to obtain their correctly computed visibilities , as described in Sec.\u00a0IV.3.\nConversely, we note that if the resolution is not increased in each successive layer, then eventually some image layer  will have lensed features smaller than its grid spacing.\nThis unresolved sub-grid structure will render the visibility , and thus the full visibility , inaccurate.\nHence, adaptive ray tracing is necessary to guarantee accurate visibilities.\nV.1.3 Convergence tests\nTo summarize, for both the emission model  and its ray-traced image layers , we must use sufficiently high resolutions to ensure that we do not truncate any sub-grid structure (that is, structure on length scales smaller than the resolution).\nThis then allows us to safely interpolate  and , without missing any features or introducing any spurious new ones in the interpolation procedure.\nInterpolating  is needed to obtain the layers , as ray tracing requires us to compute the intensity loaded on rays that intersect the equatorial source at generic crossing points.\nInterpolating the image layers  is also needed to compute their Fourier transforms , and hence the visibility (119).\nAny errors in either of these steps introduce errors in the final visibility , so we must carefully avoid them by using the appropriate resolutions, as explained above.\nIn practice, however, these requirements are only heuristic.\nFor instance, the Lyapunov exponent is an angle-dependent function  around the image plane, so we cannot precisely realize the exponential scaling  on a Cartesian grid.\nIn addition,  can be as large as , but such an increase in pixel density is not always necessary.\nIn fact, recall that for the example in Sec.\u00a0IV, we simply set , a much more modest but still adequate scaling of pixel density.\nInversely, a realization of an inoisy source realization may occasionally make a field excursion that creates a far smaller fluctuation than the minimum size  typically expected from its correlation matrix .\nWhile statistically improbable, such events cannot be precluded from occurring, and could result in a too-large grid spacing .\nUnfortunately, it is intractable to directly check that this does not happen.\nInstead, it is best to numerically check for the absence of errors using a simple convergence test, in which one doubles all the resolutions (of the simulated profile and image grids) and computes again the observables (images and visibilities).\nIn Fig.\u00a014, we show an example of a convergence test for the example from Sec.\u00a0IV: after halving the grid resolutions, the changes in the visibility amplitude remain small, confirming that the resolution scaling  is adequate.\nV.2 Field of view requirements\nBeing able to completely resolve an emission profile  and a (central) part of its image  is a necessary but not sufficient condition to correctly compute its visibility .\nAnother requirement for the accurate computation of a source model\u2019s visibility is related to the size of its image\u2019s field of view (FOV), and how fast the emission profile decays past it.\nEven when all the photon rings are fully resolved (that is, the resolution in each lensing band is sufficiently high), it is still imperative to check that the FOV is sufficiently large for the image to include all of the features with significant flux.\nIf the FOV is too small and cuts out a portion of the source, then this truncation may create a sharp drop in the observed intensity at the edges of the image.\nSuch an artificial transition would effectively introduce high-frequency components to the image, polluting its Fourier transform, and hence its visibility.\nThis is the well-known Gibbs phenomenon.\nSince we are interested in narrow features of the image, and in particular the interferometric signature of its  photon ring that is encoded in the visibility on very long baselines, we cannot avoid dealing with this potential effect.\nV.2.1 Field of view of the direct image\nWe first focus on the direct image, as it is the most prone to the Gibbs phenomenon.\nThis is because it occupies the  lensing band, which has noncompact support: as described in Sec.\u00a0II.5, it fills the entire image plane (except for the interior of the apparent equatorial horizon).\nIf the emission profile has compact support in the equatorial plane , however, its direct image  will also have compact support within the  layer, and we can terminate our FOV just past the edge of this image without introducing any truncation errors or triggering the Gibbs phenomenon.\nOn the other hand, if the emission profile extends infinitely far in the equatorial plane (remaining nonzero as ), or else if its support is too large to fully ray trace over in practice, then we must necessarily cut off its  image.141414We saw in Sec.\u00a0V.1 that a finite grid resolution introduced an \u201cultraviolet\u201d cutoff; now we see a finite grid size as the corresponding \u201cinfrared\u201d cutoff.\nFor instance, consider the simple, stationary, axisymmetric source (57) with radial profile  given by Johnson\u2019s SU distribution (58).\nWhile this emission profile does decay very fast as , it always remains finite.\nIn Fig.\u00a015, we plot it in logarithmic scale for two sets of values of its parameters.\nFrom now on, we focus on the red profile, with parameters , , and .\nWe first ray trace its direct  image on a grid of size , and then we compute the corresponding visibility amplitude , which we plot as a black dashed curve in the top left panel of Fig.\u00a016.\nAt the edge of our FOV,  has dropped to  times its maximum intensity.\nAs such, the sudden drop introduced by our truncation is too small to produce a significant ringing effect on long baselines, and so it cannot meaningfully affect the signal.\nWe will consider this large FOV and its associated visibility amplitude as the \u201ccorrect\u201d one.\nNext, we ray trace the same image with its FOV truncated at , a cutoff past which  drops to  times its maximum intensity.\nWe then plot the resulting visibility amplitude as the solid blue curve in the top left panel of Fig.\u00a016.\nPerhaps surprisingly, it differs quite significantly from the \u201ccorrect\u201d one!\nIn fact, their relative difference\u2014which we plot as a blue curve in the small panel below the main\u2014shows a large and growing percentage error that exceeds 100% before even reaching G.\nEven though the total flux that we ignored is tiny, the sudden drop in intensity at the FOV\u2019s edge triggered the Gibbs phenomenon.\nThe resulting error can affect the interferometric signature of the  photon ring and is therefore an obstacle that we need to overcome, especially since this very profile is roughly consistent with the 2017 EHT observations of M87* Gralla\u00a0et\u00a0al. (2020).\nThere are two approaches to mitigating this problem.\nThe first is to increase the FOV until the profile decays enough at the edges that it \u201ceffectively vanishes\u201d\u2014in that case, these spurious ringing effects will not be noticeable.\nIn effect, this is what we did when we chose an FOV of .\nHowever, it may not always be feasible to extend the FOV this much.\nFor instance, if the emission profile is an inoisy source simulated on a grid that stretches out to some maximal , then extending the source past this cutoff would require extrapolation.\nThis is already subtle for smooth profiles, as it amounts to introducing ad hoc data to the model.\nThe second approach\u2014referred to as \u201capodization\u201d\u2014has already been used to deal with this problem in Ref.\u00a0Paugnat\u00a0et\u00a0al. (2022).\nThis method involves the multiplication of the image by a suitable window (also known as tapering or apodization function) that smoothly tapers the intensity to precisely zero before the edge of the FOV.\nFor our example, we will use the window functionwith a cutoff value of  (well within the \u201csmall\u201d FOV of ) and , which results in the smooth but rapidly truncated profile depicted with a dashed red line in Fig.\u00a015.\nRay tracing the direct image of this profile and computing its visibility amplitude now results in the solid red curve that we plot in the top left panel of Fig.\u00a016.\nIts difference relative to the \u201ccorrect\u201d amplitude is much smaller, and the percentage difference remains fairly constant well past G.\nThis can therefore be an effective method.\nIn practice, we prefer to always use emission profiles that smoothly terminate within the FOV of our direct image, which we can easily take to be  wide.\nIn case our source profile extends beyond this FOV, we apply the window function (123) to it and take the resulting profile as our \u201ctrue\u201d source.\nV.2.2 Field of view of higher layers\nSince the  lensing bands all have compact support, it is straightforward to avoid the Gibbs phenomenon in higher- image layers and visibilities: we just take a FOV that includes the totality of the  photon ring (that is, all the flux in the  image layer).\nWe briefly describe the effects that windowing the emission profile as discussed above has on higher visibility amplitudes.\nThe top right panel of Fig.\u00a016 shows that the windowed profile produces roughly the same visibility (solid red curve) as the original one (dashed black curve) up to baselines G, which are necessary to resolve image features of sizeFor M87*, whose photon ring has a diameter as, this corresponds to a size of , or half the  ring width.\nThus, differences in the visibility amplitude  only become apparent on baselines that start to resolve its width, as can be seen in the small plot of percentage deviation.\nOn the other hand, truncating the FOV of the  image from  to  has no discernible effect on its visibility amplitude (solid blue curve) and results in a vanishingly small deviation.\nFinally, we can repeat this exercise for the  ring.\nAgain, windowing the profile has a negligible effect of , as does the truncation.\nIn fact, the latter deviation in this case ought to vanish entirely and is only nonzero due to numerical error introduced by the discretization of the Fourier transform: extending the FOV of the image to  by\u201czero padding\u201d changes the sampling of the fast Fourier transform, resulting in a minute effect.\nWe note that these tiny errors are essentially negligible in the full visibilities, which we compare in the bottom right panel of Fig.\u00a016, where most of the percentage error can be attributed to the direct image, as expected.\nVI Measuring the photon ring shape\nUsing black hole imaging to test general relativity (GR) in a regime where gravity is strong and yet non-dynamical poses a significant challenge: one must disentange the astrophysical effects of the radiating source from the purely gravitational ones C\u00e1rdenas-Avenda\u00f1o\u00a0et\u00a0al. (2020); Bauer\u00a0et\u00a0al. (2022).\nA promising approach is to focus on the  photon ring, whose interferometric signature is expected to dominate the time-averaged radio visibility on long baselines.\nMore precisely, Ref.\u00a0Gralla\u00a0et\u00a0al. (2020) proposed a test of strong-field GR based on a shape measurement of the  photon ring around M87*, which has been recently reviewed in Ref.\u00a0Paugnat\u00a0et\u00a0al. (2022).\nHere, we show in the context of our example from Sec.\u00a0IV how AART may be used to simulate this test using a source that includes \u201crealistic\u201d astrophysical fluctuations (generated with inoisy, as described in Sec.\u00a0III).\nWe offer a brief overview of the key points in the test, and refer the reader to Refs.\u00a0Gralla\u00a0et\u00a0al. (2020); Paugnat\u00a0et\u00a0al. (2022) for more details.\nIn the regime (120), a ring of projected diameter  has a visibility that takes the universal form (121).\nTherefore, its amplitude can be well approximated in this regime by Gralla (2020); Gralla\u00a0and\u00a0Lupsasca (2020b)where the functionsencode the intensity profile around the ring image, while  are the upper/lower envelopes of the visibility amplitude, respectively.\nThe width  and diameter  of the  ring do not always satisfy the condition  needed for the universal regime (120) to exist, but those of the  ring do.\nHence, we can fit Eq.\u00a0(125) to the visibility amplitudes in the regime (122) dominated by the  ring after numerically computing the functions  (a simple cubic interpolation is enough).\nThe inset panel in Fig.\u00a02 shows the visibility amplitude for two baseline angles  and  in the baseline range G (corresponding to an Earth-Moon baseline with an operation band of \u2009GHz) with their best fit to Eq.\u00a0(125) overplotted in black dashed lines.\nAccording to GR, the shape of the  photon ring is the sum of a circle, with radius , and an ellipse centered at the origin, with radii  and  Gralla\u00a0et\u00a0al. (2020).\nThis \u201ccirclipse\u201d shape has a projected diameter given by Gralla\u00a0and\u00a0Lupsasca (2020b)where  is an offset angle to account for the orientation of the ring within the image plane.\nUsing the statistical model described in Sec.\u00a0III for the emission profile with the parameters shown in Table\u00a02, we (i) average the visibility amplitudes of  snapshot images; (ii) fit Eq.\u00a0(125) to the visibility amplitude for 36 angles  to obtain the projected diameters ; and (iii) fit the general GR prediction given in Eq.\u00a0(127) to obtain .\nThe best global fits of Eqs.\u00a0(125) and (127) were found using a Markov chain Monte Carlo (MCMC) method.151515Since we are neglecting the phase of the oscillation, Eq.\u00a0(125) allows for several values of  separated by  to provide a good fit Gralla\u00a0et\u00a0al. (2020).\nHowever, the global maximum is not always the actual diameter  of the ring as measured directly in the image domain.\nAs explained in Ref.\u00a0Paugnat\u00a0et\u00a0al. (2022), in those cases, one must infer the diameter by fitting at multiple angles.\nWe report the best-fit values of the parameters in Eq.\u00a0(127) and their normalized root-mean-square error (RMSE) for each  in Table\u00a03.\nThe resulting curves, shown in Fig.\u00a03, follow the GR prediction very closely, even when only five snapshots are (incoherently) averaged.\nThe lower panels in Fig.\u00a03 show the difference of the best-fit curve for each case with the best-fit curve for the purely radial profile consisting of the envelope of the emission model (that is, when there are no fluctuations).\nThe results of this example are very encouraging for future missions targeting measurements of the photon ring shape: with only a few snapshots, one may already start to check whether the data follows the GR prediction.\nA systematic study including instrumental noise is required to simulate a realistic experimental forecast\u2014we leave this for future work.\nVII Future outlook\nHere, we have presented AART: a new, publicly available, numerical code designed for precision studies of a black hole\u2019s photon rings.\nAART exploits the integrability of null geodesics in the Kerr geometry to ray trace images analytically, with no loss of numerical precision even for strongly lensed photons that orbit the black hole multiple times.\nThe code decomposes the image plane into layers\u2014lensing bands\u2014with increasing grid resolution adapted to the lensing behavior of the hole.\nThe modular structure of AART can accomodate any time-dependent and non-axisymmetric equatorial emission profile, and can even be extended beyond equatorial sources.\nAlso, the components described in this work can be used separately: our framework is designed to individually export the lensing bands, critical curve, apparent horizon, and redshift factors, which can therefore serve as input for other studies.\nAs a prime application, we showed how the experimental forecast for the test of general relativity proposed in Ref.\u00a0Gralla\u00a0et\u00a0al. (2020) could be further refined by including source fluctuations.\nWe used inoisy\u00a0Lee\u00a0and\u00a0Gammie (2021) to simulate a stochastic model of equatorial emission, and we produced high-resolution synthetic images together with their corresponding visibility on long baselines.\nWe then successfully extracted the GR-predicted shape for the projected diameter of the  ring from its interferometric signature.\nIn a follow-up paper, we will use this framework to carry out a parameter estimation survey that also includes instrument response and noise\u2014this will further validate the test proposed in Ref.\u00a0Gralla\u00a0et\u00a0al. (2020) and bears relevance to SALTUS and other space-VLBI missions targeting the photon ring Gurvits\u00a0et\u00a0al. (2022); Kurczynski\u00a0et\u00a0al. (2022).\nAlthough we only studied the Kerr geometry, our approach may serve as a useful guide to studying other theories.\nFor instance, the Kerr lensing bands may offer a starting point for numerically finding those of slightly deformed spacetimes.\nFinally, recent EHT observations of Sgr\u00a0A* found that only  of the EHT GRMHD models passed the light-curve variability constraint\u00a0Akiyama\u00a0et\u00a0al. (2022b).\nGiven the uncertainty associated with the variability excess, and the possibility of missing physical ingredients in current astrophysical models, efforts to develop astrophysics-agnostic phenomenological approaches such as the one presented in this work are just as valuable as the improvement of accretion disk simulations.\n\nAcknowledgements.We thank Charles Gammie, Delilah Gates, Samuel Gralla, Aaron Held, Daeyoung Lee, Hadrien Paugnat, Eliot Quataert, Leo Stein, Fr\u00e9d\u00e9ric Vincent, Maciek Wielgus, and George Wong for their useful comments.\nThis work used resources provided by Princeton Research Computing, a consortium that includes PICSciE (the Princeton Institute for Computational Science and Engineering) as well as the Office of Information Technology\u2019s Research Computing division.\nACA and AL gratefully acknowledge support from Will and Kacie Snellings.\nACA also acknowledges support from the Simons Foundation.\nAL also thanks Pam Davis Kivelson for her black hole art inspired from this AART.\n\n\nAppendix A Explicit form of null geodesics in the Kerr exterior\nThis appendix lists all the formulas needed to compute the observational appearance of Kerr equatorial sources in the sky of a distant observer.\nReaders are referred to Refs.\u00a0Gralla\u00a0and\u00a0Lupsasca (2020a, c) for derivations and further details.\nThroughout, , , and  denote the incomplete elliptic integrals of the first, second and third kind, respectively, defined according to the conventions listed in App.\u00a0A of Ref.\u00a0Kapec\u00a0and\u00a0Lupsasca (2020).\n denotes the complete integral of the first kind and we also let .\nA.1 Angular geodesic integrals\nThe angular motion of a Kerr photon can display two qualitatively different behaviors depending on the sign of its energy-rescaled Carter constant .\nSince we only consider sources in the Kerr equatorial plane, we may ignore vortical motion with , which can never reach the equator Kapec\u00a0and\u00a0Lupsasca (2020).\nWe thus restrict our attention to ordinary motion with , in which case the angular geodesic integrals in Sec.\u00a0II are Gralla\u00a0and\u00a0Lupsasca (2020a)where ,  counts the number of angular turning points encountered along the trajectory,  denotes the Heaviside function, and we also introduced\nA.2 Radial geodesic integrals\nThe radial integrals can be decomposed into\nGralla\u00a0and\u00a0Lupsasca (2020c)with the integrals , ,  and  reducible to Legendre form.\nTheir precise form depends on the nature of the radial roots : there are four different cases for null geodesics in the Kerr exterior, but only two of these\u2014labelled type (2) and type (3)\u2014arise for light rays that connect the equatorial plane to a distant observer; meanwhile, type (4) geodesics can reach distant observers but never the equator, since they are all vortical, whereas type (1) geodesics are all bound to the black hole and cannot reach a distant observer at infinity Gralla\u00a0and\u00a0Lupsasca (2020c).\nA.2.1 Type (2):\nIn this case, all the roots are real and the motion is restricted to .\nThe antiderivatives of the radial geodesic integrals take the manifestly real and smooth forms Gralla\u00a0and\u00a0Lupsasca (2020c)with (recall that )where the auxiliary function  is defined aswhile the elliptic modulus is\nFinally, the source radius is given in terms of the Jacobi elliptic sine function  by\nA.2.2 Type (3):\nIn this case, only  and  are real roots while  are complex-conjugate roots, and the range of radial motion is .\nThe antiderivatives of the radial geodesic integrals take the manifestly real and smooth forms Gralla\u00a0and\u00a0Lupsasca (2020c)with (recall that )where the auxiliary function  is defined aswhile the elliptic modulus isand the other parameters are\nFinally, the source radius is given in terms of the Jacobi elliptic cosine function  by\nAppendix B Accretion flow four-velocities\nLet us consider an equatorial four-velocitywith  and  the contravariant and covariant components, respectively.\nThe angular and radial-infall velocities areMeanwhile, the energy and specific angular momentum areFor geodesic motion, these quantities are conserved, whereasis not.\nThese variables parameterize the four-velocity asAny two components of  determine it entirely, as the third can be recovered from the normalization condition .\nWe will parameterize the four-velocity using either the pair , the pair , or the pair , as follows.\nFirst, defineGiven , unit-normalization fixeswhich is physically admissible provided the quantity in square brackets is positive.\nWe took the positive square root to ensure  is future-directed.\nLowering the index of  yieldsConversely, given , unit-normalization fixes the energy towhich is physically admissible provided the quantity under the square root is positive.\nRaising the index of  then yieldsIt is often convenient to express  and  in terms of  only asLastly, given , the full four-velocity can be recovered by solving the normalization condition  [or equivalently, Eq.\u00a0(169)] for\nFinally, the observed redshift  isAlternatively, the redshift can also be expressed in terms of  as [Eq.\u00a0(B)]\nB.1 Keplerian circular orbits (geodesic motion)\nWe let  denote the four-velocity of timelike, circular-equatorial geodesics.\nThese orbits define Keplerian motion in the Kerr spacetime; they are only stable if (Eq.\u00a0(2.20) of Bardeen\u00a0et\u00a0al. (1972))or equivalently, if , where  denotes the radius of the (marginally stable) innermost stable circular orbit (ISCO),Inside the ISCO, we must use an inspiraling geodesic motion, as orbits are unstable and particles must fall into the horizon.\nB.1.1 Outside the ISCO radius\nFor , we can set  and the Kerr geodesic equation determines the Keplerian angular velocity (Eq.\u00a0(2.16) of Bardeen\u00a0et\u00a0al. (1972)):The contravariant four-velocity is then [Eqs.\u00a0(165) and (169)]and the Keplerian conserved quantities are [Eqs.\u00a0(B)]Likewise [Eqs.\u00a0(B)],Hence, the covariant four-velocity is [Eq.\u00a0(165)]\nFinally, the observed redshift is [Eq.\u00a0(173)]All of the above quantities are physically admissible provided , which is the case for all .\nB.1.2 Inside the ISCO radius\nFor , we follow Cunningham\u2019s prescription Cunningham (1975) and smoothly extend the flow past the ISCO using geodesic inspirals with the conserved quantities of the ISCO:This choice results in a nonzero radial component [Eq.\u00a0(172)]where we used the identity  [Eq.\u00a0(175)] to simplify the expressions for both  and .\nIt then follows that [Eqs.\u00a0(B)]so that the covariant four-velocity is explicitly [Eq.\u00a0(165)]The contravariant four-velocity is then [Eqs.\u00a0(165) and (B)]The contravariant components may also be recast in the formwhich matches Eqs.\u00a0(A12) of Cunningham (1975) since .\nFinally, the observed redshift is [Eq.\u00a0(B)]\nB.2 Radial infall (geodesic motion)\nWe let  denote the four-velocity of timelike, radially infalling equatorial geodesics.\nOne class of such trajectories consists of particles that fall in from spatial infinity with zero initial velocity and vanishing (conserved) angular momentum:As particles fall in, they pick up a radial velocity [Eq.\u00a0(172)]and due to frame-dragging (the off-diagonal term ), they also acquire an angular velocity  [Eqs.\u00a0(B)]:\nExplicitly, the covariant four-velocity is then [Eq.\u00a0(165)]while the contravariant four-velocity is [Eqs.\u00a0(165) and (B)]\nFinally, the observed redshift is [Eq.\u00a0(173)]\nB.3 Sub-Keplerian orbits (non-geodesic motion)\nWe now define a four-velocity  for timelike, equatorial sub-Keplerian orbits.\nSuch trajectories cannot be geodesic; following Penna\u00a0et\u00a0al. (2013), we introduce a \u201csub-Keplerianity\u201d parameter  and instead prescribe a non-geodesic motion viawhere  denotes the Keplerian specific angular momentum (179b).\nAs for Keplerian motion (with ), we must treat radii outside and inside of the ISCO radius  separately.\nB.3.1 Outside the ISCO radius\nFor , we demand that, as for Keplerian orbits,This fixes the sub-Keplerian orbital energy to be [Eq.\u00a0(169)]which is manifestly real for all , since the quantity in the square root is strictly greater than when .\nIt then follows that [Eqs.\u00a0(B)\u2013(171)]so that the covariant four-velocity is explicitly [Eq.\u00a0(165)]The contravariant four-velocity is then [Eqs.\u00a0(165) and (B)]\nFinally, the observed redshift is [Eq.\u00a0(B)]\nB.3.2 Inside the ISCO radius\nFor , we do not expect orbits to remain circular.\nInstead, we use Cunningham\u2019s prescription (B.1.2) to smoothly extend the sub-Keplerian condition (196) past the ISCO using the conserved quantities of the sub-Keplerian ISCO orbit,or more explicitly,This choice results in a nonzero radial component [Eq.\u00a0(172)]\nIt then follows that [Eqs.\u00a0(B)]so that the covariant four-velocity is explicitly [Eq.\u00a0(165)]The contravariant four-velocity is then [Eqs.\u00a0(165) and (B)]\nFinally, the observed redshift is [Eq.\u00a0(B)]\nB.4 General flow (non-geodesic motion)\nWe can linearly superpose the preceding four-velocities to obtain a general flow  combining both circular motion and radial inflow.\nFollowing Pu\u00a0et\u00a0al. (2016); Vincent\u00a0et\u00a0al. (2022), we do so by definingwhere  is the four-velocity of the sub-Keplerian flow, given by Eq.\u00a0(B.3.1) for  (outside the ISCO) and by Eq.\u00a0(B.3.2) for  (inside the ISCO), while  is the radial inflow four-velocity (B.2).\nLikewise,  is the sub-Keplerian angular velocity, given by Eq.\u00a0(B.3.2) outside the ISCO and by Eq.\u00a0(B.3.2) inside the ISCO, while  is the angular velocity (B.2) of radial inflow.\nGiven  and , we can solve the normalization condition  for , the only missing component of the four-velocity, resulting in a simple modification of Eq.\u00a0(167):This fully specifies the general 4-velocity .\nFor generic values of the three parameters , the flow  is not geodesic.\nHowever, when ,  reduces to the radial inflow , which is -independent and geodesic.\nAt the opposite end, when ,  reduces to the sub-Keplerian flow , which in turn reduces when  to geodesic Keplerian motion .\nAppendix C More on the Mat\u00e9rn covariance\nThis appendix offers a field-theoretic interpretation of the Gaussian random field with Mat\u00e9rn covariance.\nC.1 Classical field\nA free, massive scalar field  with mass  in Euclidean spacetime  is described by the Lagrangianand therefore obeys the Euler-Lagrange field equationwhich in this case is the classical Klein-Gordon wave equationwhere  is the scalar Laplacian.\nThe Green function  for this equation is defined byIn momentum space, this reads , sowhere .\nThe inverse Fourier transform (70) yieldswhere .\nWe present a full derivation of this nontrivial identity in Eq.\u00a0(246) below.\nC.2 Quantum field\nIntegrating the Lagrangian (213) by parts recasts it asThe path integral over this Lagrangian defines the Euclidean quantum field theory of a free, massive scalar field  with mass  in , which is fully characterized by its two-point function: the Feynman propagator (218).\nLetting  and , the propagator becomeswhich is (proportional to) a Mat\u00e9rn covariance.\nWe conclude that a -dimensional Gaussian random field with Mat\u00e9rn covariance of order  and correlation length  is equivalent to a (Euclidean) quantum scalar field of Compton wavelength  (and therefore mass ).\nC.3 Higher-derivative fields\nConsider now the higher-derivative theorywhere  is an integer power.\nThis is a free (Gaussian) theory because it remains quadratic in the field for any .\nClassically, the field obeys the higher-derivative wave equationwhose Green function  is defined byIn momentum space, this reads , soand the inverse Fourier transform (70) yieldsThis nontrivial identity, including the proportionality factor, is derived in Eq.\u00a0(246) below.\nLetting  and , the propagator becomeswhich is (proportional to) a Mat\u00e9rn covariance.\nWe conclude that a -dimensional Gaussian random field with Mat\u00e9rn covariance of order  and correlation length  is equivalent to a (Euclidean) quantum scalar field of Compton wavelength  (and therefore mass ) with a kinetic term including  derivatives.\nIn Lorentzian signature, such a kinetic term would lead to problems with causality, but in Euclidean signature this seems like an acceptable statistical field.\nC.4 Connection with the associated SPDE\nA -dimensional Gaussian random field  with Mat\u00e9rn covariance of order  and correlation length  obeys the stochastic PDEwhere the pseudodifferential operator on the LHS is defined via its spectral properties Lindgren\u00a0et\u00a0al. (2011), and the Gaussian random field  is the standard white noise process defined in Sec.\u00a0III.4.\nWe now wish to reconcile this statement with more familiar facts from quantum field theory, particularly in the case .\nWhen , the Gaussian random field  is a Euclidean scalar field.\nYet, Eq.\u00a0(227) implies that it also obeyswhich seems to impose yet another condition on the field.\nWe now show how this statement is consistent with the propagator (218), which fully characterizes the behavior of the field.\nThe key is to multiply two copies of this equation inserted at two different points  and , keeping track of which position the derivatives in the Laplacian act upon:We now massage the LHS as follows.\nFirst, we are free to move the derivatives to the left, since  only acts on :Next, we take expectation values of the fields on both sides:By definition, the two-point function on the LHS is of course the Euclidean quantum propagatorAs for the two-point function on the RHS, it is none other than the autocorrelation function of Gaussian white noise,which is by definition a delta function.\nWe thus haveSince both two-point functions depend only on , we have  and thus we are left withThis is exactly Eq.\u00a0(216), proving that it is consistent for the Euclidean quantum field  to also obey the SPDE (228).\nThis is the quantum-statistical analogue of the classical field equation (215): the presence of the white noise source term  is what lends the Euclidean field its statistical nature.\nFinally, when , the Gaussian random field  obeyswhich is a linear SPDE and therefore straightforward to solve.\nThis is the reason why it is implemented in inoisy Lee\u00a0and\u00a0Gammie (2021).\nC.5 Derivation of the scalar propagator\nHere, we derive Eqs.\u00a0(218) and (225), which are equivalent to the position-space formula (77) for the Mat\u00e9rn covariance.\nIn spherical coordinates,where  denotes the solid angle on the sphere , which isWe now need two identities from Gradshteyn and Rhyzik Gradshteyn\u00a0et\u00a0al. (2007): by 3.915-5 (p492), we have for ,and by 6.565-4 (p678), we have for , , and ,Using the first formula with  and , we findwhere the prefactor isWe can thus rewriteThe second identity with  and  then yieldsso we finally obtainSince , this exactly reproduces Eq.\u00a0(225):and setting  recovers Eq.\u00a0(218).", "output": "Recent interferometric observations by the Event Horizon Telescope have resolved the horizon-scale emission from sources in the vicinity of nearby supermassive black holes. Future space-based interferometers promise to measure the ''photon ring''--a narrow, ring-shaped, lensed feature predicted by general relativity, but not yet observed--and thereby open a new window into strong gravity. Here we present AART: an Adaptive Analytical Ray-Tracing code that exploits the integrability of light propagation in the Kerr spacetime to rapidly compute high-resolution simulated black hole images, together with the corresponding radio visibility accessible on very long space-ground baselines. The code samples images on a nonuniform adaptive grid that is specially tailored to the lensing behavior of the Kerr geometry and is therefore particularly well-suited to studying photon rings. This numerical approach guarantees that interferometric signatures are correctly computed on long baselines, and the modularity of the code allows for detailed studies of equatorial sources with complex emission profiles and time variability. To demonstrate its capabilities, we use AART to simulate a black hole movie of a stochastic, non-stationary, non-axisymmetric equatorial source; by time-averaging the visibility amplitude of each snapshot, we are able to extract the projected diameter of the photon ring and recover the shape predicted by general relativity.", "question": "none", "title": "2211.07469", "qa_pairs": "none"}
{"input": "Smaller11\n\n\n\n\n\\NewEnvironSmaller08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMnLargeSymbols\u2019164\nMnLargeSymbols\u2019171\nOn Continuum Effective Field Theoriesand GravitySylvain\u00a0Fichet ***sfichet@caltech.edu \u2009,\nEugenio\u00a0Meg\u00edas \u2020\u2020\u2020emegias@ugr.es\u2009,\nMariano\u00a0Quir\u00f3s \u2021\u2021\u2021quiros@ifae.es\nICTP South American Institute for Fundamental Research & IFT-UNESP,\n\u2009 R. Dr. Bento Teobaldo Ferraz 271, S\u00e3o Paulo, Brazil\nCentro de Ciencias Naturais e Humanas, Universidade Federal do ABC,\n\u2004 Santo Andre, 09210-580 SP, Brazil\nDepartamento de F\u00edsica At\u00f3mica, Molecular y Nuclear and\n\u2004 Instituto Carlos I de F\u00edsica Te\u00f3rica y Computacional,\n\u2004 Universidad de Granada, Avenida de Fuente Nueva s/n, 18071 Granada, Spain\nInstitut de F\u00edsica d\u2019Altes Energies (IFAE) and\n\u2004 The Barcelona Institute of Science and Technology (BIST),\n\u2004 Campus UAB, 08193 Bellaterra, Barcelona, Spain\nAbstract \nWe examine effective field theories (EFTs) with a continuum sector in the presence of gravity. We first explain, via arguments based on central charge and species scale, that an EFT with a free continuum cannot consistently couple to standard (i.e.\u00a04D\u00a0Einstein) gravity. It follows that EFTs with a free, or nearly-free, continuum must either have a finite number of degrees of freedom or nonstandard gravity.\nWe demonstrate the latter through holographically-defined continuum models, focusing on a class of 5D dilaton-graviton systems giving rise to a gapped continuum (i.e.\u00a0the linear dilaton background). In the simplest version of the model we find an  deviation from the Newtonian potential. At finite temperature, we find an energy density with  scaling law (i.e.\u00a0)\nin the brane Friedmann equation, induced by the horizon in the bulk. We also present a slightly more evolved model for which these exotic deviations transition into those from pure AdS. Brane cosmology in dilaton-gravity backgrounds could be explored along these lines.\n\n\n Introduction\nAmong the multitude of effective field theories (EFT) extending the Standard Model (SM) of particles physics, models involving a continuum sector stand out as an intriguing possibility. Of course, any weakly coupled Poincar\u00e9-invariant quantum field theory (QFT) features a continuum in its spectral distributions. But beyond this standard case, a nearly-free continuum can also emerge in theories with some nontrivial underlying dynamics.\nSuch a continuum can for example appear from gauge sectors with large number of degrees of freedom, or from EFTs whose background features a brane (i.e.\u00a0domain wall or defect) living in a higher dimensional spacetime. Such nontrivial continuum sectors are the subject of this note.\nFrom a more phenomenological viewpoint we may also write, from a bottom-up approach, a continuum model with arbitrary spectral functions describing the phenomena that are potentially observables in a given set of experiments, as allowed by the rules of the EFT paradigm.\nPhenomenologically, the underlying dynamics of the continuum may or may not matter, depending on the situation. In particular, in certain cases, it may be sufficient to use an effective model in which the continuum has properties analogous to an ordinary free field. This is called a generalized free field\u00a0Greenberg:1961mr . This approach applies for example to processes observable at colliders, such as \u201cSM  continuum SM\u201d and \u201cSM  continuum\u201d for which only the two-point function of the continuum is needed.\nRegarding the latter class of processes, we emphasize that even though a continuum does not have well defined asymptotic states, such processes make sense as inclusive ones, for which no measurement of the continuum final state is required.\nThe EFT of a free continuum works fine for scattering processes observable at a collider. But, are there other physical observables for which the description of a continuum as a generalized free field does not apply? The answer is positive: whenever interactions with gravity are considered, the underlying dynamics of the continuum does matter. Clarifying the interplay of continuum models with gravity is the first aim of this note. This investigation will then naturally lead us to explore aspects of gravity in holographic models of continuum, which is the second aim of this note.\nOur analysis is structured as follows.\nIn Sec.\u00a02 we lay out the formalism, and introduce the notion of generalized free field. In Sec.\u00a03 we review the arguments (both old and new) that prevent a generalized free field to consistently couple to standard gravity. As an interesting aside we give an argument for the species scale that is valid for conformal field theories (CFTs) with any central charge and coupling. We then discuss the classes of models that give rise to a gravity-compatible continuum. It turns out that, apart from the conformal case, continuum models are best studied holographically, via 5-dimensional braneworld models. In Sec.\u00a04.3 we lay out the basic holographic framework, review necessary QFT aspects and show how to compute the deviations from the standard Friedmann equation and Newtonian potential.\nIn Sec.\u00a05 we solve two versions of a specific dilaton-gravity background (both analytically and numerically) that features a gapped continuum and investigate gravity aspects. Section\u00a06 contains a summary.\nFinally App.\u00a0A contains further discussions on the transition between discretum and continuum, and App.\u00a0C includes a piecewise solving of the asymptotically-AdS linear dilaton background.\nPrevious literature:\nThe perspective of continuum models as a phenomenological possibility was first highlighted in Refs.\u00a0Georgi:2007ek ; Georgi:2007si . Among the subsequent references we mention only a few, as an introduction into the literature\u00a0Stephanov:2007ry ; Strassler:2008bv ; Cacciapaglia:2008ns ; Friedland:2009iy ; Friedland:2009zg . Aspects of cosmology with a conformal sector have been investigated in, e.g.\u00a0Refs.\u00a0vonHarling:2008vwq ; vonHarling:2012sz ; Hong:2019nwd ; Redi:2020ffc ; Hong:2022gzo , and in Refs.\u00a0Grzadkowski:2008xi ; Artymowski:2019cdg ; Artymowski:2021fkw \nin case of large  weakly coupled CFT.\nA continuum as a mediator in the dark sector has been investigated in Refs.\u00a0Katz:2015zba ; Chaffey:2021tmj . Finally\na proposal of \u201ccontinuum dark matter\u201d was recently made in Refs.\u00a0Csaki:2021gfm ; Csaki:2021xpy , that needs to be put in perspective with the arguments and results of the present note.\n  Continuum models\nIn this section we discuss some basic aspects of continuum models and introduce the notion of free continuum limit.\n Continuum EFT\nWe consider an EFT described by the following four-dimensional Lagrangian,This Lagrangian contains in general irrelevant operators\u00a0333The  operator is often taken as an irrelevant operator i.e.\u00a0dim. A detailed parametrization is unnecessary for our purposes.. The fundamental fields  can in principle have any spin.  and  are in general composite operators made of the corresponding fundamental fields. For simplicity those are assumed to be scalars.\nThe  sector is assumed to feature a nontrivial continuum \u2014 in a sense defined further below and in Sec.\u00a02.2.\nIn the  sector, the spectral functions are assumed to describe stable, or narrow, particles as occurs in weakly coupled QFT.\nThe two sectors interact which each other only via the  operator.\nFrom the viewpoint of an observer able to probe the particle sector ,\nthe continuum sector is probed by the  fields through the  operator. Thus in the correlators of the  fields, the continuum sector manifests itself via subdiagrams made out of the correlators of , i.e.\u00a0, \u00a0444Time-ordering is left implicit, we use the usual shortcut notation . . Our interest precisely lies in these correlators of the continuum sector.\nFor any two-point (2pt) correlator one can always introduce a spectral representation of the form\u2009555This follows from Cauchy\u2019s integral formula .where  is the spectral distribution and the contour  encloses non-analyticites of the correlator in momentum space. In our conventions the momentum is timelike for . The non-analyticities can either be poles or branch cuts along .\nOn the domain corresponding to a branch cut the spectral density  is a smooth function. In this most generic case we refer to the  sector as a continuum. As a more particular case, it may be that the support of  be a discrete set of points. Similarly it is also possible that the function be made of a series of narrow resonances such that the branch cut can be approximated by a set of points.\nIn such cases the spectral distribution describes a countable set of standard 4D particles, and we refer to the  sector more specifically as a discretum.\n Interactions\nIt is useful to classify the interactions encoded in the continuum sector.\nThere are fundamental interactions between the  fields, encoded inside the Lagrangian . We denote collectively these interactions by the coupling . These fundamental interactions may be either weak or strong.The continuum interacts with the particle sector via the  operator. This implies that local operators of the formare generically present in the continuum sector. Analogous ones with an arbitrary number of derivatives also exist. All these operators are in general present due to the quantum dynamics in the  sector. In general, even if these operators are set to zero at a given scale, they are generated at a different scale due to renormalization group (RG) running. We refer collectively to these local operators as  and the corresponding coupling as .\n Realizations\nIn principle any interacting QFT can realize the setup of Eq.\u00a0(1). For example, for a weakly coupled interacting QFT the continuous part of the spectral distribution  encodes a multiparticle continuum, and possibly a resonance.\nHowever, our interest lies in theories that can give rise to a free continuum when some parametric limit is taken in the model (see Sec.\u00a02.2). A non-trivial dynamics is needed for such a limit to occur. It is realized in at least the two following classes of theories.\nGauge theories with a large number of colors . For simplicity we assume that the  fields are in the adjoint representation, so that the standard large  scaling applies\u00a0Witten:1979kh . The theory may, in principle, have either weak or strong t\u2019Hooft coupling .\nAs a particular case, the gauge theory may be at a conformal fixed point in which case it is a CFT. For  this occurs at a Banks-Zaks fixed point if the theory has number of flavors within the conformal window. At  stringy effects are expected to emerge for large  (see e.g.\u00a0Refs.\u00a0PhysRevD.10.2445 ; PhysRevD.10.4262 ; tHooft:1977nqb ; Nambu:1978bd ; Luscher:1980iy ; Luscher:1980ac ; Sundrum:1997qt ) while at  the stringy effects are expected to decouple Gubser:1998bc ; Polchinski:2002jw .Holographic theories. These arise from EFTs living in a 5D background (with arbitrary metric) featuring a flat 3-brane.\nIn such a setup an effective Lagrangian of the form of Eq.\u2009(1) appears from the viewpoint of an observer placed on the brane. The  field is identified as a brane-localized mode with standard 4D spectral distribution, which mixes with a continuum controlled by the 5D dynamics (see Sec.\u00a05 for more details).\nIn such models there are both bulk and brane-localized local interactions, that we denote by  and . We also refer to this setup as a \u201cbraneworld\u201d in the context of cosmology.\n The free continuum (GFT) limit\nWe are interested in taking a parametric limit for which a free continuum arises in the general Lagrangian of Eq.\u2009(1).\nOur notion of free continuum is equivalent to the one described by a generalized free theory (GFT), hence we are using either naming depending on context.\nGFTs have been studied in the context of QFT and CFT (see\u00a0e.g.\u00a0Refs.\u00a0Greenberg:1961mr ; Dymarsky:2014zja ; Kap:lecture ).\nIn a GFT the connected part of the correlators of  vanishes.\nAs a result the odd correlators are zero while the even correlators are given by the disconnected contributions which are just a product of 2pt correlators. For example for the 4pt correlator we have\nWe define the free continuum (i.e.\u00a0GFT) limit as the limit for which the fundamental interactions of the continuum sector vanish,while the spectral density does not become discrete (i.e.\u00a0remains supported on  and not only on a discrete set of points when ).\nThis definition of the free continuum limit automatically excludes the trivial case of an interacting QFT with finite degrees of freedom, since in that case for  the multiparticle continuum vanishes and the spectral density of  becomes discrete. Thus some nontrivial dynamics in  is required for a free continuum to emerge at .\nOur definition of GFT allows for the existence of the local interactions . Thus in our definition the GFT correlators can have  contributions. This is however a minor point in the rest of our analysis, as we will obtain the same conclusions as if .\nHow is the free continuum/GFT limit realized in the classes of models listed in Sec.\u00a02.1.2?A GFT emerges from a gauge theory by taking the limit of infinite number of colors  at constant \u2018t Hooft coupling \u2014 notice that  in this limit.\nIndeed, by normalizing the 2pt function coefficient such that it does not scale with , standard large  scaling arguments imply that the connected correlators scale as powers of . In the  limit the odd correlators are  and the even correlators are given by the free disconnected result plus  terms. This matches the properties of a GFT, henceWe could similarly write this limit for the full Lagrangian including the  interactions.A GFT emerges from a holographic setup by sending the bulk couplings to zero. Indeed in this limit the bulk propagators are free, hence the higher point correlators factorize into 2pt propagators. The holographic theory inherits this property, therefore the holographic theory is a GFT.\nThe brane couplings contribute solely to the  interactions \u2014 which are allowed in our definition of GFT.\nIn summary for the full holographic Lagrangian we schematically have\n Continuous mass representation\nIn the GFT the correlators of  can be described with a diagrammatic expansion using perturbation theory in the  couplings. The resulting diagrams are built from the  vertices, connected by lines which are the propagators of , i.e.\u00a0the 2pt free correlator . This is just the usual picture of Feynman diagrams, with GFT propagators instead of ordinary propagators.\nWe can thus view the continuum sector as a set of fields  whose only interactions are those encoded in the  operators. The domain for the  label is determined below.\nThese  fields must reproduce the propagator of . Using the spectral representation introduced in Eq.\u2009(2),\nthis is possible if the  operator iswithThe  are ordinary free fields with squared mass  and propagator\u2009666\nIn terms of quantization rules, one\nintroduces creation and annihilation operators of fields  such that .Eq.\u2009(10) together with the definition (8) reproduces the spectral representation Eq.\u2009(2) of the  correlator. Similar developments can be found in Refs.\u00a0PhysRev.126.1209 ; Deshpande:2008ra .\nThe higher point correlators of  follow trivially since they inherit the properties of the free fields . Namely, the odd correlators of  vanish, up to ,\nand the even correlators tend to the free disconnected result, up to , as required for a GFT. For example in the 4pt case, one obtains Eq.\u2009(4).\n Consistency with gravity  \nIn the previous section we have introduced the notion of free continuum i.e.\u00a0of GFT. Here we expand the explanation of why a GFT is not compatible with gravity. In this section gravity means 4D Einstein gravity. Some of the arguments already existed previously, and are hereby reviewed, while others are new to the best of our knowledge. We then discuss gravity-compatible realizations and sketch some basic cosmological consequences.\n Arguments from OPE \nIn this section we provide arguments based on the operator product expansion (OPE).\n From CFT (review)\nWe start with a gauge theory with arbitrary \u2019t\u2009Hooft coupling, focusing on the conformal case. In conformal theories, there is a rigorous claim that the simultaneous existence of a generalized free field and the stress-energy tensor are incompatible, unless the generalized free field is an ordinary free field (see e.g.\u00a0Ref.\u00a0Dymarsky:2014zja ; Kap:lecture ).\nA version of the proof of this well-known result goes as follows.\nLet us assume that a conformal theory contains a generalized free field  and a stress tensor . The stress tensor has dimension  and spin . The 4pt function of , given in Eq.\u2009(4), contains information about the spectrum and OPE coefficients of . It can be shown\u00a0Kap:lecture  that Eq.\u2009(4) implies that the OPE of  only contains bilinear operators built from derivatives of , e.g.\u00a0.\u2009777The same feature is true in an ordinary free field theory, and thus the same conclusion can be obtained using the continuum mass representation.\nSuch operators have dimension . These facts put together imply that\nthere can be a stress tensor in the OPE of  only if , hence requiring , which corresponds to the ordinary free field (in which case one has ). Otherwise, i.e.\u00a0if , there cannot be  in the OPE of . The latter feature implies, by symmetry of the OPE coefficients, that  is absent of the  OPE. This is inconsistent with translation invariance, which requires that  must appear in this OPE with a nonzero coefficient. We thus reach a contradiction.\nThe contradiction is solved if either the generalized free field  or  are absent from the conformal theory.\n From continuous mass representation\nThe fact that a GFT with stress tensor is inconsistent can also be directly seen from the continuum mass representation defined in Sec.\u00a02.2.1. The  distribution is in general supported over , but the argument also applies if the distribution is truncated to an interval such as , as may occur in an EFT.\nIn the presence of the free continuum described by the set of free fields , we can formally derive a stress tensor from the Lagrangian Eq.\u2009(9), which gives . We can then compute the correlator of this generalized free stress tensor with itself and focus on the traceless part. The result is proportional to . Since , the central charge is infinite.\u2009888This is consistent with the viewpoint of the GFT as a CFT with , which also gives infinite central charge.\nThe infinite central charge effectively sends to zero the coefficient involving  in the OPE of . This leads to a contradiction with translation invariance, as in the CFT proof above.\nThe argument given here extends beyond the CFT case, and holds whether or not there are  local operators.\n From species scale \nLet us consider the GFT in the presence of dynamical gravity via the action .\nThis is in general a low-energy EFT describing subPlanckian gravity interacting with matter, together with classical black holes. What is the UV cutoff scale of this EFT?\nEven though the strength of gravity is set by the reduced Planck mass , the actual validity scale of the EFT may be lower. Using an argument based on classical black hole lifetime, Ref.\u2009Dvali:2008ec  established the bound  where  is the number of species of matter in the theory. This argument relies on Hawking radiation and thus assumes that the species are stable or narrow particles.\nHere we will verify that the species bound can be extended, beyond weak coupling, to a CFT with arbitrary central charge  and arbitrary \u2018t Hooft coupling . This is an aside result that we use it to strengthen our analysis and which is also interesting in itself.\n Species scale for CFT with arbitrary central charge \nLet us consider . We want to determine the UV cutoff scale\u00a0 of the theory.\nLet us assume there is no cosmological constant and let us put the CFT at finite temperature . The energy density is given by , with  and  at weak and strong coupling, respectively. For simplicity we drop the  factor in the following.\nAs a result of this energy density, spacetime expands with a Hubble rateThe associated volume for a Hubble patch is . But this volume is bounded from below by the cutoff of the theory, as it cannot be smaller than the volume , which amounts to a Hubble rate .\nThe corresponding momentum scale is of order  and, since temperature is proportional to the average momentum scale, we can say that this Hubble rate is attained for . Therefore the UV cutoff is determined by the condition , which givesIn the case of weakly coupled stable species we have  which recovers the usual formula from Ref.\u00a0Dvali:2008ec .\n Application to GFT\nHaving ensured that the species scale applies to any CFT, we turn to the GFT.\nViewing the GFT as the limit of a CFT with , we can see that the number of species in the GFT goes to infinity. Therefore , and so there is no energy regime where gravity is weakly coupled! This means that a GFT coupled to gravity simply does not exist.\nThe same conclusion is obtained when considering the continuous mass representation. For any  there is an infinite number of degrees of freedom , hence , which implies .\nFrom all of the above arguments we conclude that gravity cannot couple to the GFT because the latter has infinitely too many degrees of freedom. Notice that, in contrast, a CFT has a finite number of species , and thus in that case the UV cutoff  is nonzero.\nNotice also that all the arguments would be avoided in the case of an ordinary free field (, ); however this is excluded in our definition of free continuum (see Sec.\u20092.2).\nThus, in other words, the coupling to gravity would enforce the generalized free field to be an ordinary free field.\n Holographic theory vs GFT\nWe have shown that a GFT (as defined in Sec.\u00a02.2) is obtained from a holographic setup by setting all the bulk interactions to zero. This definition implies that 5D gravity is removed when taking the GFT limit, . In such a limit we have a gravity-less bulk which can be trivially integrated out.\u00a0999A situation reproduced by Little String Theories\u00a0Aharony:1999ks .\nConversely, a holographic setup with gravity provides automatically a continuum compatible with gravity. However the price to pay is that gravity in the holographic theory is intrinsically 5D, implying that the graviton itself has a continuum component, such that gravity deviates from 4D Einstein gravity.\nLet us comment about the case of AdS background (e.g.\u00a0the RS2 setup\u00a0Randall:1999vf ). In this case the AdS/CFT correspondence applies. By the correspondence the  coupling goes as some power of , and hence the GFT limit is consistent from either the AdS or the CFT viewpoints since . We can also note that, even without gravity, the AdS theory always has a 5D stress tensor. What really changes when taking  is that the graviton field is removed. The CFT operator dual to this bulk field is the stress tensor, which is thus removed upon taking . This is in agreement with the argument of Sec.\u00a03.1.1.\n Gravity-compatible continuum models \nAlong with the arguments of Secs.\u00a03.1 and 3.2 we have established that a free continuum i.e.\u00a0a GFT is incompatible with 4D Einstein gravity.\nWe now consider theories lying in the neighborhood of this limiting case in theory space (see Fig.\u20091). Such neighboring theories feature some notion of free or nearly-free continuum, and some ingredient making the continuum EFT compatible with gravity \u2014 associated to loopholes in the no-go arguments of Secs.\u00a03.1 and 3.2.\nBy examining the latter arguments, we can identify the following logical possibilities for EFTs neighbors to the excluded case of GFT+4D Einstein gravity: a) The EFT has large but finite number of degrees of freedom, and b) Gravity differs from 4D Einstein gravity.\nFollowing these lines we then identify the following three (possibly overlapping) classes of theories giving rise to free or nearly-free continuum models consistent with gravity.\nThe continuum is really a discretum.It is possible that the free continuum be an approximation of a free discretum. Indeed both are indistinguishable to a finite precision experiment unable to resolve the discretum spacing.\nIn this case the underlying degrees of freedom are countable and their number is finite since they are bounded by a gravity-induced UV cutoff. Thus the central charge is finite and inconsistencies with gravity are avoided. In the bottom-up EFT of a free continuum this can be simply obtained by making the spectral distribution discrete in the continuous mass representation of Sec.\u20092.2.1.The continuum is a large- gauge correlator. For finite number of colors  the central charge is finite, thus inconsistencies with gravity are avoided. In that case the continuum is nearly-free since it has nontrivial connected correlators which are -suppressed but nonzero.\nAt strong coupling a discretum may arise at low energy if the theory enters a confining phase, hence providing a realization of i).The continuum is holographic.In this case the underlying dynamics is intrinsically 5D even though it is seen from a brane viewpoint.\nThe matter continuum arising in the 4D holographic theory automatically couples consistently to gravity. The counterpart is that gravity itself has a continuum component. Thus gravity in the holographic theory is not 4D Einstein gravity.\nThe holographic framework can also realize the above ones in specific cases, as for certain backgrounds a discrete KK spectrum arises, hence realizing i), and for pure AdS background ii) is realized via the AdS/CFT correspondence.\nFor convenience we refer to the continuum from both  and  as a nearly-free continuum. For , \u201cnearly\u201d applies to \u201ccontinuum\u201d, which really is a discretum, while for , \u201cnearly\u201d applies to \u201cfree\u201d, since the continuum has small but nonzero nontrivial correlators.\nWe can now observe that for any kind of EFT with a free or nearly-free continuum consistently coupled to gravity, substantial deviations must appear in the gravity sector. These are the deviations that would blow up and make the theory inconsistent when taking the limit of a free continuum coupled to 4D Einstein gravity.\nThis fact is evident for holographic models, class iii), in which gravity automatically deviates from 4D Einstein gravity. But this fact also occurs in the classes of models  and  because, in any event, the graviton propagator is dressed by insertions of  correlators which are proportional to the central charge. This is a physical QFT correction to the Newton law of gravity. In the limit of large central charge the correction to the graviton propagator blows up, inducing thus large effects on the gravity sector.\nIn summary we can state that consistent models of a free or nearly-free continuum must feature deviations in the gravity sector as a general feature.\nThis is pictured in Fig.\u20091.\nWe investigate such effects in a concrete framework in the upcoming sections.\n Cosmological implications\nIn this section we qualitatively discuss the expected cosmological effects in the classes of gravity-compatible continuum models listed in Sec.\u20093.4. Along the same lines as the observations made there, such models must have significant impact on standard cosmology since they feature either a large number of degrees of freedom or deviations from gravity that blow up when approaching the forbidden limit of GFT+4D Einstein gravity (see Fig.\u20091).\nHere we thus discuss basic cosmological aspects of the classes of models   and , i.e. \u00a0discretum, large  gauge theories and holographic theories.\nA cosmological discretum is a fairly intuitive possibility. In that case the continuum is really made out of a set of 4D particles with standard properties and thus their contributions to the Friedmann equation are clear. For example, at temperature lower than the mass gap , the tower of particles is nonrelativistic and can be a candidate for dark matter. Such a scenario has been studied at length, see e.g.\u00a0Refs.\u2009Dienes:2011ja ; Dienes:2011sa .\nThe cosmological implications of a hidden large  gauge theory are trickier, because in general we do not know the equation of state , except in the following particular cases.\nFirst, the gauge theory may transition to a confined phase at low temperature, in which case the confined case is described by a discretum EFT already discussed above.\nSecond, the gauge theory may be at a conformal fixed point, in which case it is a CFT whose properties are very constrained by symmetries. Let us review this well-known particular case. The hot CFT behaves as dark radiation because scale invariance implies  which in turn implies , i.e.\u00a0.\nSince the hidden CFT has many () degrees of freedom, the temperature  must be much lower than the one of the visible sector, otherwise the CFT energy density  overwhelms the visible one, which amounts to a large amount of dark radiation, excluded by observations. Hence one requires . Since , such a requirement on  implies that the temperature of the hidden CFT should be much lower than the visible one,\n.\nFor more general gauge theories a similar reasoning applies at a more qualitative level, yielding the generic prediction that a large  hidden sector must be ultracold in order to not spoil cosmology. However, we cannot say more because we do not know the equation of state for such an energy density. A cosmological continuum model, apart from the CFT case, is thus best studied via holography.\nWe now turn to holographic continuum models. The cosmology of some of these models\nhas been well studied.\nThe simplest, and best studied, cosmological scenario is the one for which the bulk is exactly AdS everywhere, which furthermore exactly mirrors\nthe scenario of hot CFT reviewed above (see e.g.\u2009Refs.\u2009Gubser:1999vj ; Shiromizu:1999wj ; Binetruy:1999hy ; Hebecker:2001nv ; Langlois:2002ke ; Langlois:2003zb ).\nThe key point is that at finite temperature a horizon develops in the bulk, with AdS-Schwarzschild metric (AdS-S). The presence of the horizon crucially modifies the effective Friedmann equation projected on the brane with a term which, from the standpoint of the brane observer, behaves as dark radiation. This effective radiation term arising from the bulk geometry matches the CFT result  for strong \u2018t\u2009Hooft coupling. We summarize such a remarkable feature as\nDeparting from the pure AdS case there are plenty of possible background geometries, in particular \u201csoft-wall\u201d backgrounds appearing from the 5D gravity-dilaton system, see e.g.\u00a0Refs.\u2009Karch:2006pv ; Gursoy:2007cb ; Gursoy:2007er ; Gubser:2008ny ; Falkowski:2008fz ; Batell:2008zm ; Batell:2008me ; Cabrer:2009we ; vonGersdorff:2010ht ; Cabrer:2011fb ; Megias:2019vdb .\nSome of these backgrounds\ngive rise to a continuum in the 4D holographic theory. Continuum models from the gravity-dilaton framework will be the focus of the rest of the paper.\n The holographic continuum: gravity and Friedmann equation\nOur focus here is on holographically defined continuum models.\nSuch models are particularly attractive as everything is calculable since the 5D QFT is weakly coupled.\nIn this section we lay out the overall framework for holographic models of continuum. The setup is reminiscent of braneworld models (see e.g.\u00a0Ref.\u2009Brax:2003fv ). Namely, we consider\na five-dimensional spacetime with a flat 3-brane (i.e.\u00a0domain wall or defect) living on it, and evaluate the effective theory for an observer living in the brane worldvolume (see Fig.\u20092). In such a setup the 5D excitations are integrated out and form a continuum from the standpoint of the brane observer.\nSince the overarching theme of the paper is the consistency of continuum EFT with gravity, we will be especially interested in the gravity side of the holographic continuum models. Thus two concrete objects of study stand out.The gravitational potentialAt any scale for which a continuum is present in the holographic EFT,\nsomething nontrivial has to occur in the gravity sector to ensure consistency with gravity. Thus some deviation from Newtonian gravity can be expected at such scales. This can also be qualitatively understood in terms of the existence of a stress tensor in the continuum sector. Such a stress tensor, whose existence is ensured in the holographic setup,\ndresses the 4D graviton, yielding a modification of the Newtonian potential.The Friedmann equationThe equation of state in the continuum sector is in general nontrivial and unknown (see also the discussion in Sec.\u20093.5). However in holographic models this equation of state is encoded into the geometry of the 5D background. This appears at the level of the effective Friedmann equation seen by a brane observer, which contains nontrivial information about the bulk geometry \u2014 and thus about the equation of state.In summary we expect deviations to both the Newtonian potential and Friedmann equation.\n The five-dimensional background \nWe consider a five-dimensional spacetime with a flat 3-brane (i.e.\u00a0domain wall).\nThe 5D coordinates are denoted by  indices, while the 4D coordinates on the 3-brane  are denoted by  indices.\nWe consider the action of the graviton-dilaton systemwith  the dilaton field,  the fundamental 5D Planck scale,  the 5D cosmological constant,  the brane tension, and  the induced metric on the brane.  encodes the quantum fields living on this background.\nThe ellipses encode a term giving rise to a vacuum expectation value (VEV) for  that does not need to be explicitly specified here. For concreteness we can assume it is fixed on the boundary of the 5D spacetime.\u00a0101010\nAlternatively a potential giving rise to the dilaton VEV may be localized on the brane of Eq.\u2009(14). Such a possibility is inequivalent to the model considered here and will be studied in a future work.\nThe 5D metric is given the formThe coordinate frame in the first line shows that the metric is conformally related to the flat space Schwarzschild metric. The functions  and  are referred to, respectively, as the warp and blackening factors.\nThe coordinate frame in the second line are convenient for brane cosmology.\nAlong any constant slice of , the  coordinate acts like a scale factor.\nThe 3-brane is a hypersurface located at .\nWith the above coordinates the induced metric  readswhere we have introduced the brane cosmic time .\nAccording to this metric, if the brane moves along  in the extra dimension, i.e.\u00a0if , the observer perceives expansion of the 4D universe.\nThe 5D equations of motion for metric factors and the dilaton field are given in conformal coordinates by\u00a0Megias:2018sxv where for convenience we have defined the dimensionless scalar field\u00a0. The general solutions contain five integration constants. However it turns out that one of the equations, e.g. Eq.\u2009(20), acts as an algebraic constraint on the integration constants hence there are only four independent constants. Some of the integration constants have no physical meaning and can be fixed without loss of generality i.e. amount to \u201cgauge redundancies\u201d, while others have physical meaning. A detailed discussion is provided in App.\u00a0B.\n The effective Friedmann equation \nThe effective Einstein equation seen by an observer standing on the brane is computed from the 5D Einstein equation, projected on the 3-brane via the Gauss equation together with the Israel junction condition, which relates the extrinsic curvature to the brane-localized stress tensor. The outcome takes the form\u2009Shiromizu:1999wj Here\n is the Ricci tensor projected on the brane.  is the stress energy tensor on the brane. The effective 4D cosmological constant  contains contributions from both the 5D cosmological constant and from the brane tension, which are tuned so that .\nThe  tensor is a quadratic combination of brane-localized stress tensors, thus\nit comes with a  factor.\nFinally,  is a term built from the projection of the 5D Weyl tensor \u2014 i.e.\u00a0the traceless part of the Riemann tensor \u2014 on the brane.\nThe  tensor is a term induced by the extrinsic curvature terms in the Gauss equation and contains quadratic combinations of the stress tensor . We can see that, at energy densities , the effect of  is negligible with respect to the standard  term of Einstein equation.\nWe plug the metric of Eq.\u2009(16) into Eq.\u2009(22), for a brane at .\nFocusing on , tuning to zero the 4D cosmological constant, and focussing on the  component of Eq.\u2009(22) we obtain the effective Friedmann equation on the branewhere  in this equation is the 4D energy density localized at the brane. Here  where  is the cosmic time for the brane observer.\nThe  term depends on the  component of the Weyl tensor,The second line is the result obtained with the metric of Eq.\u00a0(16).\nFrom Eq.\u2009(23) we can see that all the effects of the 5D geometry at energies below  are encapsulated into the  term.\nWe thus have a geometric effect which translates from the brane viewpoint as an effective energy term, that we refer to as the Weyl energy. The scaling of  in  determines the equation of state of the Weyl energy.\nThe Weyl tensor measures deviation from conformality and it vanishes if  identically in Eq.\u2009(15).\nIf  vanishes at a given point , the hypersurface  is a horizon whose temperature and entropy are given by  and , respectively, where  is the volume in the 3D space and  is the Newton constant in 5D.\u00a0111111The expression of the temperature in the brane cosmology coordinates of Eq.\u00a0(16) is  where . The presence of the Weyl energy in the brane Friedmann equation is thus associated with the temperature of the horizon in the bulk. In Sec.\u20095 we will compute the horizon temperature for completeness and to compare with the literature. Regarding the entropy, its general formula in the brane cosmology coordinates for any model is .\n QFT overview \nIn this section we consider quantum fields living over the 5D background encoded in the term  in Eq.\u00a0(14).\nWe review some essential properties of bulk QFT as seen from a brane, that are needed to establish the general picture of a holographic continuum model.\nOur focus is on the fields living in the , i.e.\u00a0, region of the bulk.\nWe assume that the fields have Neumann boundary conditions (BC) on the brane, i.e.\u00a0the fields are allowed to fluctuate on the brane.\u2009121212\nA field with Dirichlet boundary condition would contribute to the brane correlators only via internal lines. This is not the focus of the present study.\n\nThe fields are described by a Lagrangian in the 5D bulk, but additionally there can always be operators localized on the brane. In fact those are always generated by loop effects (see Ref.\u2009Fichet:2021xfn  for explicit results). Thus following the EFT paradigm such operators should be included in the brane Lagrangian in a first place.\nLet us now consider a generic bulk field  with value  on the brane. The field propagates in the bulk, but the brane-localized operators would influence its propagation. In fact, on general grounds, a brane-to-brane propagator\ntakes the form , where  and  is the bilinear insertion induced by the brane-localized operators\u00a0Fichet:2021xfn  and dressing .\nIn momentum space, both  and possibly  contain an analytic piece , which amounts to having an isolated 4D free mode in the spectrum. The wavefunction of this mode is typically localized near the brane. Singling out this 4D localized mode, the propagator can be written aswhere  is a wavefunction renormalization effect, and the  term is non-analytical. For sufficiently smooth background, as the one we will consider here,  has a branch cut along some region of the  axis, i.e.\u00a0it is a continuum. This term encodes the contributions of all the rest of the bulk modes to the brane-to-brane propagator. We thus have split the denominator into a 4D free piece and a continuum piece.\nWe can see that the structure of Eq.\u2009(25) amounts to the one of a 4D free propagator dressed by insertions due to mixing with a continuum (see Fig.\u20092). This is the same structure as the  propagator of the continuum EFT in Eq.\u2009(1) dressed by  insertions, upon identifying  and .\n131313The notion of mixing can be understood more explicitly as follows. In the set of all degrees of freedom of , we can single out those which do not fluctuate on the brane, i.e.\u00a0have Dirichlet BC. Writing\n, with  the amputated brane-to-bulk propagator and  the continuous basis of Dirichlet modes,\nthe set  forms a complete basis which is orthogonal \u2014 in the sense that the quadratic action is diagonal in \u00a0Fichet:2021xfn . In this basis  has a nontrivial propagator, Eq.\u2009(25), i.e.\u00a0a nontrivial spectral distribution.\nHowever one could instead, as introduced in Ref.\u00a0Batell:2007jv , trade the\n component for , in which case the associated degree of freedom  simply is a 4D free field.\nIn that case the propagator of  is trivial, but in counterpart the  basis is not orthogonal (see Batell:2007jv ), and therefore there is a mixing between  and . The form of Eq.\u2009(25) is understood as a manifestation of this mixing.\nThis shows explicitly that the holographic setup leads to a continuum model of the kind described by the generic continuum EFT given in Eq.\u2009(1).\nThe crucial gain with respect to the generic continuum Lagrangian is that, here, the setup dictates exactly how the law of gravity is modified. Before focusing on gravity we discuss qualitatively some other QFT aspects which are useful for the overall understanding of the model.\n Spectrum and continuum final state\nThe continuum piece  may, or may not, be supported at the pole location given by . In analogy with familiar weakly coupled QFT we can distinguish two cases. If the pole lies in a region where  is zero, the 4D mode described by the propagator Eq.\u2009(25) is stable. It thus contributes as a Dirac delta function to the spectral distribution and is identified as a particle in the Hilbert space of the 4D theory. In contrast if the pole lies in a region where\n is nonzero, the 4D mode acquires a width given by  and thus amounts to a resonance as first noted in Ref.\u00a0Dubovsky:2000am . This striking feature means that the 4D mode has a nonzero probability to convert into the continuum.\nWe notice here a key difference between continuum and discretum. If  was a discretum, e.g. \u00a0, the isolated 4D mode would remain exactly stable. Such a propagator would simply describe a mixing between the 4D mode and the discretum.\nThis, in a sense, is because a free particle cannot just convert into another one with different mass.\nIn contrast, the mass of the continuum is a continuous variable, thus it can be arbitrarily close to . As a result there is a well-defined probability for the 4D mode to convert into the continuum.\u2009141414\nAt a deeper level, a continuum does not have the properties required to build the familiar asymptotic multiparticle states of flat space, and may thus obey other rules. In the AdS case, for example, the continuum amounts to the normalizable bulk modes of AdS, that we know are perfectly stable (see e.g.\u2009Ref.\u2009DiPietro:2021sjt ).\nDiagrams with AdS modes, such as , for example, only induce a mixing of the bulk modes, and thus amount in familiar terms to a radiation process rather than a decay process that would remove the initial mode from the spectrum (see e.g.\u00a0Fichet:2021pbn ).\nThe spectral function contains the necessary information to describe a continuum final state. In practice, in a given diagram one can simply take a unitarity cut on the generic brane-to-brane propagator Eq.\u2009(25).\nIn particular, in the case of a stable particle the result takes the formwhere  computes the discontinuity across , as defined in Sec.\u00a04.4. In Eq.\u2009(26),\n is real and  is imaginary.\nWe can see from Eq.\u2009(26) that the final state can either be the stable 4D mode, or transition via a 4D propagator into the continuum.\nIn the notation of the generic Lagrangian Eq.\u2009(1), this amounts to a \u201ccontinuum\u201d process, see Fig.\u20092.\n Finite temperature\nThe sector of brane-localized 4D modes can form a thermal bath. In such a case we can simply say that there is finite temperature on the brane.\nThe conversion processes highlighted in the above section appear in the collision term of the Boltzmann equation of the 4D modes. They describe a sustained flux of radiation into the continuum of bulk modes, dumping energy into the bulk. In a sense these processes are responsible for \u201cheating up\u201d the bulk since, when falling deep enough in the bulk, they create a horizon which, in Eq.\u2009(15), is encoded in the blackening factor  (see e.g.\u2009Ref.\u2009Hebecker:2001nv ).\nSuch processes, and the overall coupled dynamics, have been studied in a number of references, at various degrees of refinement, using both the 5D and dual 4D viewpoints, see e.g.\u1e58efs.\u2009 Gubser:2002zh ; Hebecker:2001nv ; Langlois:2002ke ; Langlois:2003zb ; Brax:2019koq ; Redi:2020ffc . Similar calculations could similarly be done in the linear dilaton background, although this is not the focus of the present work. Here we take the horizon coordinate  as a free parameter, constant in time. This assumption is compatible with the typical cosmological history, for which the above mentioned processes are efficient at very high energy but then quickly lose efficiency when the temperature drops, resulting in a constant .\n Gravitational potential\nThe graviton propagator should, following the above discussions, describe a massless 4D mode with bilinear mixing to a continuum.\nWe denote the general propagator aswhere the superindex  in the propagator refers to the spin of the graviton.\nThe polarization structure  is given below.\nWhat is the gravitational potential resulting from the propagator, Eq.\u2009(27)?\nTo obtain it we write the spectral representation of the propagator as\u00a0Zwicky:2016lka ,where  is the discontinuity of  across the\nbranch cut along the real line, :In this representation the tensor structures are\nthose of the standard Fierz-Pauli propagators\u00a0Hinterbichler:2010es ,with .\nThe potential can be directly obtained using the spectral representation Eq.\u2009(28) (see e.g.\u00a0Callin:2004py  and also\u2009Chaffey:2021tmj ). One picks point sources at rest such that . Performing the  integral yields a general representation of the long-range potential aswhere , .\nIf  we have , which reproduces the standard Newtonian potential. The continuum term will induce a deviation to this potential. In the following we compute explicitly the continuum-induced deviation in specific 5D backgrounds.\n The holographic gapped continuum\nWe focus on a specific version of the dilaton-gravity setup\ncalled the linear dilaton (LD). This background has the fascinating property that it naturally realizes the notion of a gapped continuum that was proposed phenomenologically in Ref.\u2009Georgi:2007ek .\nWe assume the presence of a thermal bath on the brane, inducing a horizon in the bulk via QFT processes as described in Sec.\u20094.3 and Fig.\u20092.\n AdS-Schwarzschild (review)\nThe well-known case of pure AdS background is recovered in the case where  with , and the dilaton has no VEV, i.e.\u00a0 cte. For  the background is AdS-Schwarzschild, i.e.\u00a0hot AdS. In the cosmological context this amounts to the RS2 model\u00a0Randall:1999vf  at finite temperature. In that case one has, in conformal coordinatesfor any value of  and, in brane cosmology coordinateswhere we have used the relation . Finally, the temperature of the black hole is\n Deviation from the Friedmann equation\nWe findThis indicates that the Weyl energy behaves as 4D radiation \u2014 in accordance with the discussion in Sec.\u00a03.5. Notice that the Weyl energy is regular at the Schwarzschild horizon.\n Deviation from the Newtonian potential\nIn AdS the reduced brane-to-brane graviton propagator takes the form (see e.g.\u2009Ref.\u2009Fichet:2019owx )where we are using that .\nThe discontinuity is found to beAfter substituting in Eq.\u2009(32) we obtain the gravitational potential\nThe  deviation is the manifestation of the continuum  which mixes with the 4D graviton. This is the well known behavior found in\nRandall:1999vf , with the exact coefficient obtained in Callin:2004py .\n Linear dilaton\nThe linear dilaton model (LD) is defined by the potential\u00a0Megias:2021mgj where . Here  is a scale characterizing a mass gap (up to some  multiplicative factor) for the fields living over the LD background.\nThis model has a solution at zero temperature which is given in conformal coordinates bywith . The solution at finite temperature is given by the same expressions of Eq.\u00a0(41), with the blackening factor\nIn the brane cosmology coordinates, the black hole solution can be written asThe black hole temperature in the LD background isThese results are consistent with the\nborderline solution between confining and non-confining geometries reported in Gursoy:2008za .\n Deviation from the Friedmann equation\nWe findwhich is a non-standard Weyl energy. In terms of the scale factor for the brane observer , the Weyl energy scales as  in the effective Friedmann equation.\nIn terms of the parameter of the equation of state , the Weyl energy has , which should be interpreted as a sort of exotic radiation.\n Deviation from the Newtonian potential\nIn the LD background the reduced brane-to-brane graviton propagator is Megias:2021mgj where . This expression has both a pole at  and a branch cut along . The denominator can also be put in the form\n which reproduces the form shown in Eq.\u2009(25). The first term is the 4D pole with . The second term corresponds to the pure continuum part which is non-analytical above  and  near .\nWe obtain the discontinuityAs expected the graviton spectral distribution features a massless pole and a gapped continuum.\nSubstituting into Eq.\u2009(32) we obtain the gravitational potentialwithWe see that the deviation from the Newtonian potential appears essentially below the distance scale  corresponding to the inverse mass gap. The deviation to the potential goes as , unlike the AdS case, where it goes as .\n Linear dilaton with AdS asymptotics (LDA)\nWe consider a modification of the LD background by assuming an AdS asymptotic behavior in the UV. The model is defined by the superpotential\u00a0Cabrer:2009we ; Megias:2019vdb which leads to the following scalar potentialThe metric we are considering is, using proper coordinates,The solution of the background equation of motion iswhere  is the location of a naked singularity, which would correspond to  in conformal coordinates.\nIn the brane cosmology coordinates the solution is given by\u00a0151515The relation between the proper \u201c\u201d and the brane cosmology \u201c\u201d coordinates in the LDA model of Sec.\u00a05.3 is\n\n\n\n\n\n\n(56)\n\nwhere  is the Lambert function.withand  is the principal branch of the Lambert function. As in the LD model of Sec.\u00a05.2, in the LDA model the graviton spectrum has a mass gap .\n Deviation from the Friedmann equation\nThe Weyl contribution to the Friedmann equation is then computed by using Eq.\u00a0(24). Explicit analytical results for the temperature and Weyl energy in the LDA model are provided in App.\u2009B, cf. Eq.\u00a0(83). Using the piecewise approximation of the metric given in App.\u2009C we can compute a more transparent analytical approximation to the Weyl tensor. Details are given in App.\u00a0C. We find that the Weyl energy behaves asThe behavior of  computed exactly with the LDA model of Eq.\u00a0(51) is displayed in Fig.\u00a03. It matches the analytical behavior obtained in (59) and illustrates the transition at  between the two regimes, AdS-like for , and LD-like for .\n Deviation from the Newtonian potential\nThe equations of motion on the LDA background do not have exact solutions. However an approximation is easily obtained by considering two regimes.\nAs can be seen in App.\u00a0C, the metric is approximately AdS for  and LD for .\nOn the other hand, at the level of propagation we know that AdS propagators, expressed in  space with given spacelike momentum  (with ), are exponentially suppressed beyond . That is, the propagator only knows about the  region of the bulk. This fact implies that if  the spectral function should not know about the LD part of the background, and thus be approximately AdS. On the other hand, for  the propagator should know about the LD background. But since the LD background induces a mass gap at , the dominance of the LD background implies that the continuum vanishes. This is consistent with the spectral function obtained in our approximation, in which the continuum part starts at .\nIn summary we can approximate the discontinuity of the graviton propagator asThe Newtonian potential is easily computed by plugging Eq.\u2009(60) into Eq.\u2009(32), givingWe can see that for  the expression reduces to the AdS one, Eq.\u2009(39). On the other hand for  the potential is exponentially suppressed \u2014 as a consequence of the mass gap induced by the LD background. We also evaluate numerically in Fig.\u20094 the results of  and  by considering the piecewise approximation of the metric in App.\u00a0C. Nontrivial oscillations occur near the threshold that cannot be captured analytically. Despite this detail the numerical evaluation of the potential accurately reproduces the analytical behavior.\n Discussion\nWe have found that the deviations from the Newtonian potential and Friedmann equation appearing in the LD background completely differ from those occurring in the AdS background.\nThe deviation from the Newtonian potential induced in the LD background goes as  and is gapped at . In contrast, the deviation from gravity in the AdS background goes as  and is ungapped. We can use the landscape of Yukawa-like fifth force searches to bound the deviation.\nWe find that the relevant bound is the one from micron-scale fifth force experiments\u00a0Smullin:2005iv . The order of magnitude bound isor \u00a0meV.\nThe Weyl energy term induced by the bulk horizon in the effective Friedmann equation on the brane has the equation of state parameter . This exotic energy term is determined by a combination of parameters of the model. However we can simply write the Friedmann equation withwhere ,  and  are the Hubble constant, scale factor and fractions of energy at present times, respectively, and then bound . Requiring that the exotic term be negligible at the BBN time or earlier, at which the matter term is also negligible, we obtain\nFor the LDA background the deviations feature transitions between asymptotically LD and AdS regimes. For the deviation from the Newtonian potential, the AdS regime emerges in the UV i.e.\u00a0for small , while the LD regime shows up in the IR i.e.\u00a0for large .\nIn the Friedmann equation, the Weyl energy behaves as in LD for high\u00a0temperature while it behaves as in AdS for low\u00a0temperature.\nFinally, let us briefly comment further about the behaviour of the Weyl energy in the LDA model. In terms of cosmological evolution, there are two cases corresponding to whether the scale factor today  is smaller or larger than . If , the Weyl energy has  scaling, i.e.\u00a0 until the present days.\nIn contrast if  there is a transition at some point in the history of the Universe, when . Before this time, the Weyl energy behaves with  scaling but after this time it has  scaling. In other words, the Weyl energy turns into a radiation term at late times.\nThe bound at BBN times from Eq.\u2009(63) applies if . Otherwise, the Weyl energy turns into dark radiation before BBN happens, and standard BBN bounds on 4D dark radiation apply, see e.g.\u00a0Refs.\u00a0Hebecker:2001nv ; Langlois:2003zb .\nThese cosmological braneworld scenarios would deserve further investigation.\n Summary \nHere we summarize the logical steps and results of our study.\nOur interest lies in theories giving rise to a free continuum in some parametric limit. A theory featuring a free continuum is referred to as a GFT. In our definition of GFT we allow for local interactions of the continuum, as this has no impact on the results. A free continuum sector emerges in the limit of theories with nontrivial dynamics, such as the  limit of gauge theories or the  limit of braneworld models. Additionally, a GFT may be seen as an approximation of a discretum. Standard Poincar\u00e9-invariant (i.e.\u00a0no brane) weakly coupled QFTs do not give rise to a continuum in the free limit, thus these are excluded from our study.\nThere is a priori no obvious principle to prevent us from writing an EFT featuring a free continuum. However we argue that such an EFT is incompatible with standard gravity. One line of argument is to show that the continuum sector has no stress tensor, or that the central charge is infinite. An axiomatic version of this fact is known for CFT and reviewed here. Using the continuous mass representation we obtain a similar conclusion for any non-conformal free continuum.\nAnother line of reasoning relies on the species scale of gravity. The species scale is usually given for stable particles. Here, as a side result, we present a finite-temperature-based argument that generalizes the species scale in terms of the central charge of any CFT. Using the species scale we argue that the free continuum sector amounts to an infinite number of species, and thus that the cutoff of the EFT is zero.\nThese arguments imply that a free continuum in the presence of standard gravity cannot exist. We then consider the neighborhood of this point in theory space, that evade the no-go arguments either because the number of degrees of freedom is finite or gravity is nonstandard.\nThis is the case of the classes of theories already listed above: a discretum, gauge theories with finite , holographic theories.\nWe point out that a common feature of all these models is that they must feature significant deviations in the gravity sector \u2014 these are the effects blowing up when approaching the GFT+4D Einstein gravity point.\nWe focus on holographic theories giving rise to a continuum. We consider a class of 5D gravity-dilaton models giving rise to a gapped holographic continuum. We lay out \u2014 together with a review of QFT aspects needed for an overall understanding of the holographic model \u2014 the necessary formalism to compute the effective Friedmann equation and the Newtonian potential. When brane-localized fields are at finite temperature, a horizon forms in the bulk.\nWe solve the pure linear dilaton background (LD) at finite temperature analytically and the asymptotically LD at finite temperature using both analytical approximations and exact numerical solving.\nIn the pure linear dilaton background, we find that the Newtonian potential features a  deviation and has a mass gap at . This is in sharp contrast with the deviation in the AdS background. We find that the Friedmann equation features an anomalous \u201cWeyl\u201d energy with  scaling. This is summarized asin terms of the equation of state parameter.\nThis is, again, in contrast with the AdS case for which the Weyl energy scales as dark radiation . We also study a somewhat more evolved linear dilaton background with AdS asymptotics near the boundary. The Newtonian potential is found to be essentially like the AdS one, but with a gap at  like in the LD case. The Weyl energy features a transition from the LD regime () at high temperature to the AdS regime () at low temperature.\nA general lesson from our study of the holographic models is that the cosmology of continuum models is highly nontrivial. This, in a sense, is because it necessarily involves the underlying dynamics giving rise to the continuum.\nHere we have studied a particular case of the dilaton-gravity background. A host of solutions remains to be explored. A more detailed study of the cosmological history of these braneworld models certainly deserves further study. These exciting directions are left for future work.\nAcknowledgments\nSF thanks Flip Tanedo for useful discussions and comments. EM would like to thank the ICTP South American Institute for Fundamental Research (SAIFR), S\u00e3o Paulo, Brazil, for hospitality and partial finantial support during the final stages of this work. The work of SF has been supported by the S\u00e3o Paulo Research Foundation (FAPESP) under grants #2011/11973, #2014/21477-2 and #2018/11721-4, by CAPES under grant #88887.194785, and by the University of California, Riverside. The work of EM is supported by the project PID2020-114767GB-I00 financed by MCIN/AEI/10.13039/501100011033, by the FEDER/Junta de Andaluc\u00eda-Consejer\u00eda de Econom\u00eda y Conocimiento 2014-2020 Operational Programme under Grant A-FQM-178-UGR18, by Junta de Andaluc\u00eda under Grant FQM-225, and by the Consejer\u00ed\u0131a de Conocimiento, Investigaci\u00f3n y Universidad of the Junta de Andaluc\u00eda and European Regional Development Fund (ERDF) under Grant SOMM17/6105/UGR. The research of EM is also supported by the Ram\u00f3n y Cajal Program of the Spanish MICIN under Grant RYC-2016-20678. The work of MQ is partly supported by Spanish MICIN under Grant FPA2017-88915-P, and by the Catalan Government under Grant 2017SGR1069. IFAE is partially funded by the CERCA program of the Generalitat de Catalunya.\nAppendix A On the transition between discretum and continuum \nIn this appendix we expand on the possiblity of a discretum EFT, studying its validity range using general arguments.\nFor concreteness we assume that the discretum arises as the low-energy limit of a confining large  Yang-Mills theory with large \u2018t Hooft coupling .\nWe choose the spectral distribution of the free propagator to bewhere the  are intervals with some spacing set by some typical scale .\nThe sum starts at , with . We refer to  as the mode spacing and  as the mass gap of the spectrum. The gap  is either  or . In the following we assume . The conclusions are trivially extended to the cases ,  by substituting  by  in the arguments.\nThe free propagator takes the formIt encodes a series of free 4D particles. Similarly to Sec.\u20092.2.1 the model is equivalently written with a set of canonically normalized 4D fields  with  and the operator .\nA similar picture is also obtained from holographic models with a discrete spectrum\u00a0Costantino:2020msc .\nIn the context of phenomenological continuum models, some aspects of the discretum EFT were discussed in Ref.\u00a0Stephanov:2007ry .\nAssuming that the discretum arises from confinement of gauge theory, the  fields can be understood as glueball fields. The couplings among the  fields are then controlled by powers of \u00a0Witten:1979kh . The modes encoded into the full 2pt function are thus narrow \u2014 in accordance with our definition of discretum.\nThe discretum EFT has a validity cutoff scale , above which the gauge theory description takes over, and above which  is a continuum.\nThis means that in the spectral distribution of the 2pt function there should be a transition, between the discrete and the continuous regime, as a function of the mass variable\u00a0.\nWhat can we learn from general considerations about the transition scale ?\nWe can reason in terms of degrees of freedom. On very general grounds, the number of degrees of freedom should decrease when the RG flow goes toward the IR. The UV theory (i.e.\u00a0the deconfined gauge theory) has  degrees of freedom. Hence the low-energy effective theory can have at most  degrees of freedom. Hence the heaviest field of the EFT has at most a squared mass of .\nMoreover, since the  fields are by assumption regularly spaced, the cutoff has to be of order of the heaviest field of the discretum EFT in order to truncate the heavier ones.\nWe conclude that the transition scale is constrained to be\nWe can also reason in terms of interactions. Using large- counting rules for glueballs, the 3pt interaction of the  fields has  strength and we can then evaluate the width of an individual field . A very rough estimate is , where  counts the lighter states available for decay. Therefore the  fields become broad (i.e.\u00a0) at , which signals a breakdown of the EFT.\nWe conclude that the cutoff cannot be higher than .\nThis estimate matches the one from the number of degrees of freedom.\nA more refined estimate can also be obtained using input from holographic models, and in particular, and for simplicity, using a pure AdS two brane model (see Ref.\u00a0Costantino:2020msc ). In that case the spacing is , we have , and we know that the width estimate is rather  because the selection rules set by the residual symmetries constrain the decay channels. We also know that the transition scale is reached when\nthe modes tend to overlap with each other, in which case not only the diagonal width , but the full self-energy matrix that mixes all the  would become relevant\u00a0Fichet:2019hkg ; Costantino:2020msc . At that scale the \u2019s merge, giving rise to a continuum. The estimate of the transition scale in this case is . This matches the previous one when using .\nAppendix B Solutions of the equations of motion\nWe present in this appendix the most general solutions of Eqs.\u00a0(18)-(21), both in conformal coordinates and in brane cosmology coordinates. The integration constants are discussed.\n AdS-Schwarzschild\nIn the conformal frame the solution of the equations of motion is given bywhere , , , and the horizon position  are integration constants. In the brane cosmology frame one findsand the relation between both coordinates is given by . We can already notice that  is an irrelevant shift symmetry in the coordinate  which does not have counterpart in the brane cosmology frame. We can thus set  without loss of generality. The  constant is also physically irrelevant because  cte.\nThe temperature and Weyl energy turn out to beThe  constant affects the horizon temperature but not the Weyl energy.\nIt can be eliminated by a constant rescaling of the coordinates, so that we can set , which gives the usual AdS-Schwarzschild metric of section 5.1. The Weyl energy depends on , the horizon position. This is the only physically meaningful integration constant.\n Linear dilaton\nIn the LD model, the solution of the equations of motion in conformal frame writeswhere , , , and  are integration constants.\nAs in the AdSS case, there is an irrelevant shift symmetry in , so that we can set  without loss of generality.\nThe  constant has physical meaning. It is\nidentified with the  scale (see main text) which is proportional to the mass gap in the spectrum (see also e.g.\u00a0Antoniadis:2011qw ; Cox:2012ee ; Megias:2021mgj  for discussions). In the brane cosmology frame one findsIn these coordinates the solution involves three integration constants: ,  and . The relation between both coordinates is , and . Finally, the temperature and Weyl energy turn out to be\nThe  constant affects the horizon temperature but not the Weyl energy.\nUnlike the AdSS case,  depends on both the horizon position and another integration constant, . This constant corresponds to the boundary value of , i.e. .\nMoreover,  contributes to the scalar VEV via .\nIn the present work we have taken the hypothesis that the scalar VEV is set by a mechanism independent of the brane at , e.g. at the boundary of spacetime. As a result  is independent of .\nIt follows that the Weyl energy scales as .\nSince  is inversely proportional to , then  is also independent of . In particular,  leads to the zero temperature solution near the boundary, i.e. far from the black hole horizon.\nIn summary, we can setwhich leads to the solution of section\u00a05.2.\n Linear dilaton with AdS asymptotics\nIn the LDA model, the solution in proper coordinates \u201c\u201d iswith , ,  and  as integration constants, and their relation with the scale  isIn the brane cosmology frame we findThe relation between both frames isThe integration constants in the brane cosmology coordinates are , ,  and , and their relation with  is . Finally, the temperature and Weyl energy turn out to bewhereandwhile  is the exponential integral function. Using  and , one finds the asymptotic behaviors of the Weyl energy  and .\nRegarding the fixing of the integration constants, we can set  as  is an irrelevant shift symmetry in the  coordinate. We will fix the other integration constants aswhich allows to connect with the zero temperature solution near the boundary. This leads to the solution of section\u00a05.3.\nAppendix C Linear dilaton background with AdS asymptotics: \napproximate analytical solution\nHere we present analytical results obtained within an approximate version of the LDA of Sec.\u00a05.3. We consider the following realization of the model\u00a0Megias:2021arn where  is the step function, while  is the value of the dimensionless scalar field  at the UV brane and  is a value of the field which determines the transition region from AdS to LD.\u00a0161616We can understand the value of  as coming from a hypothetical IR brane located at  with a potential fixing the value of the field  at .\nThe solution at zero temperature of this model can be written in conformal coordinateswith . In this model . The solution at finite temperature is given by the same expressions of Eqs.\u00a0(88)-(89), with the blackening factorwhere . This solution is valid for . In the brane cosmology coordinates, the black hole solution writeswherewith  and . The solution in these coordinates is valid for . The temperature and entropy of the black hole in the LDA arerespectively. The graviton spectrum has a mass gap . Finally, we findvalid for .", "output": "We examine effective field theories (EFTs) with a continuum sector in the presence of gravity. We first explain, via arguments based on central charge and species scale, that an EFT with a free continuum cannot consistently couple to standard (i.e. 4D Einstein) gravity. It follows that EFTs with a free or nearly-free continuum must either have a finite number of degrees of freedom or nonstandard gravity. The latter claim is realized for holographically-defined continuum models. We demonstrate this by computing the deviations from standard gravity in a specific 5D scalar-gravity system that gives rise to a gapped continuum (i.e the linear dilaton background). We find an $R^{-2}$ deviation from the Newtonian potential. At finite temperature we find an energy density with matter-like behavior in the brane Friedmann equation, holographically induced from the bulk geometry. Thus, remarkably, a brane-world living in the linear dilaton background automatically contains dark matter. We also present a slightly more evolved asymptotically-AdS linear dilaton model, for which the deviations exhibit a transition between AdS and linear dilaton behaviors.", "question": "none", "title": "2208.12273", "qa_pairs": "none"}
{"input": "Chapter 0 Report of the Topical Group on Dark Energy and Cosmic Acceleration: Complementarity of Probes and New Facilities for Snowmass 2021\nConveners: Brenna Flaugher, Vivian Miranda, David J.\u00a0Schlegel  \nAdam J.\u00a0Anderson, Felipe Andrade-Oliveira, Eric J.\u00a0Baxter, Amy N.\u00a0Bender, Lindsey E.\u00a0Bleem, Chihway Chang, Clarence C.\u00a0Chang, Thomas Y.\u00a0Chen, Kyle S.\u00a0Dawson, Seth W.\u00a0Digel, Alex Drlica-Wagner, Simone Ferraro, Alyssa Garcia, Katrin Heitmann, Alex G.\u00a0Kim, Eric V.\u00a0Linder, Sayan Mandal, Rachel Mandelbaum, Phil Marshall, Joel Meyers, Laura Newburgh, Peter E.\u00a0Nugent, Antonella Palmese, M.\u00a0E.\u00a0S.\u00a0Pereira, Neelima Sehgal, Martin White, Yuanyuan Zhang\n1 Executive Summary\nThe mechanism(s) driving the early- and late-time accelerated expansion of the Universe represent one of the most compelling mysteries in fundamental physics today. The path to understanding the causes of early- and late-time acceleration depends on fully leveraging ongoing surveys, developing and demonstrating new technologies, and constructing and operating new instruments. This report presents a multi-faceted vision for the cosmic survey program in the 2030s and beyond that derives from these considerations.\nCosmic surveys address a wide range of fundamental physics questions, and are thus a unique and powerful component of the HEP experimental portfolio.\nWide-field surveys in the optical/near-infrared have played a critical role in establishing the standard model of cosmology, CDM.\nWe strongly advocate for continuing this extremely successful program into the coming decade and beyond.\nRegarding photometric imaging surveys, the HEP community sees three options for Rubin Observatory beyond LSST, each of which would require different investments with costs and benefits needing detailed study. These studies must be undertaken a few years into the LSST so that the range of opportunities and trade-offs between them can be informed by the then-current scientific findings and open questions in the field.\nThe next generation of spectroscopic surveys has the opportunity to map a significant fraction of the observable Universe in three dimensions, tracking the expansion of the Universe and providing constraints on dark energy throughout most of cosmic history. The spectroscopic roadmap starts with continued operation of DESI (i.e., DESI-II), followed by a new wide-field spectroscopic facility that leverages and complements LSST imaging. [1].\nObservations of the cosmic microwave background (CMB) have provided one of the most powerful probes of the origin, evolution, and contents of our Universe.\nContinuation of a strong CMB program will transform our understanding of the early Universe through measurements of tensor modes, test the particle content to unprecedented precision and provide unique insights about gravity, dark energy, and new physics through cross-correlation with the wide-field galaxy surveys advocated in this report.\nHEP investment in CMB-S4 is critical to enable a diverse fundamental physics program.\nFollowing CMB-S4, higher-resolution observations of the CMB will open a new regime of microwave background cosmology.\nAdvancement of emerging techniques for cosmology and the study of dark energy, and complementarity among methods, should also be a priority. An array of concepts for mapping the Universe using radio or millimeter-wave spectroscopy have promise as unique probes of large-scale structure. Third-generation gravitational wave observatories now being studied have potential for independently probing the expansion of the universe and dark energy, which should be characterized and optimized. Across surveys and methods, priority should be given to the potential sensitivity gains from joint processing.\nThis report arrives at several recommendations:\nNear-term FacilitiesGiven the pivotal role of CMB experiments in the landscape of particle physics and cosmology, and their phenomenal successes thus far, we advocate for advancing the CMB program through strong support of the near-term construction and operation of CMB-S4, which will cross critical, well-motivated thresholds in the searches for inflationary gravitational waves and new particle species.We advocate for the continued operations of DESI (DESI-II;\u00a0[1]) as an important part of the spectroscopic roadmap while a Stage V spectroscopic facility is designed and built.We advocate for support of small- and medium-scale projects that enhance the science reach of studies of transients discovered by Rubin LSST and \u201cstandard sirens\u201d detected by gravitational wave facilities. Data from these projects should be combined with infrastructure that enables cross-experiment coordination and data transfer for time-domain astronomical sources and a US-HEP multi-messenger program with dedicated target-of-opportunity allocations on US-HEP and partner facilities.\nLonger-term FacilitiesThrough the Snowmass2021 process, the HEP community has identified the pressing need for next-generation wide-field, massively multiplexed spectroscopic capabilities to complement LSST imaging. We strongly advocate for the establishment, support and start of construction of a Stage V spectroscopic facility in the coming decade.Recognizing the wealth of fundamental physics that could be probed if much higher resolution and lower noise could be efficiently achieved over a wide-area CMB survey, we strongly advocate for support of studies of a Stage V CMB facility to bring it to conceptual readiness for the next decade.New approaches such as millimeter and 21-cm line-intensity mapping (LIM) hold the promise of exceptional cosmological constraining power.\nHowever, the technological readiness of these programs must be further demonstrated before the community is prepared to invest fully in a large-scale project using these technologies.\nThus, we recommend a coordinated R&D program to advance the technical readiness of these projects.We advocate for the continued operation of the Rubin Observatory after LSST. The Rubin Observatory will continue to be a groundbreaking facility in 2034 that can advance the state-of-the-art by targeting the sky with new innovative observation strategies and/or instruments.\nComplementarityNo single experiment can reveal the nature of dark energy.\nSuch a breakthrough will require data from a network of experiments, small and large, probing the early- and late-time Universe in complementary ways.\nAt present, cross-survey analyses are challenging to initiate, organize, and fund. We advocate for the creation of clear pathways to support cross-survey analyses as part of the core mission of the HEP Cosmic Frontier.Multi-messenger measurements of gravitational wave events are an emerging complementary technique for probing cosmology through standard sirens. Support for coordination with future large facilities (such as the European Einstein telescope) will enable maturation of this novel technique for measuring dark energy.We advocate for the creation of multi-site data archive centers, where data from cosmological surveys is replicated for robustness and continuous availability. The centers will provide the long-term preservation of datasets and simulations. Such centers should also supply computing resources for in-place analyses, making joint investigations attainable given the huge I/O bottleneck that arises from downloading data from such centers.We advocate for a robust program to increase the available supercomputing resources to enable running, postprocessing, and validating a diverse set of numerical gravity-only and hydrodynamical simulations tailored to the specificities of different surveys. This program would enable the running and testing of data-driven methods involving, for example, machine learning or bayesian methods.\n2 Introduction\nCosmic surveys, including observations of the cosmic microwave background (CMB) and the distribution of stars and galaxies, enable investigations of the fundamental components of the Universe including dark energy, dark matter, inflation, the properties of neutrinos, and signatures of other \u201cdark sector\u201d particles.\nCosmological and astrophysical measurements provide the only empirical measurements of dark energy and inflation, while measurements of dark matter and neutrinos both motivate and complement other terrestrial HEP experiments.\nOver the last several decades cosmic surveys have resulted in the creation of a \u201cStandard Model\u201d of cosmology (CDM), in which the Universe is currently comprised of  dark energy (assumed to be a cosmological constant, ) and  non-baryonic, collisionless, cold dark matter (CDM)\u00a0[e.g., 2, 3, 4, 5, 6, 7]. The fact that cosmic surveys can address a wide range of fundamental physics questions make them a unique and powerful component of the HEP experimental portfolio.\nFigure 2 shows the breadth of HEP scientific opportunities enabled by cosmic surveys, stretching from the earliest moments of the Universe to present day. The previous P5 science driver of \u201cUnderstanding dark energy and cosmic acceleration\u201d is still very relevant and will continue to be so for the next decade and beyond. The theorized epoch of inflation is shown at the highest redshifts and optimally probed through tracers at the largest spatial scales on the sky. In contrast, dark energy is shown at the left, as its impact is most significant on the growth of structure in the modern (late-time) universe. Dark energy is optimally probed at large to medium scales. Cosmic signals that probe inflation and dark energy include (but are not limited to) the cosmic microwave background from the very early universe, the gas and galaxies tracing the matter distribution as structure formed and evolved, and optical galaxies and transients in the late universe. Each of theses signals has unique strengths that are discussed in further detail below. Additionally, cross-correlating between cosmic signals can eliminate systematics and extend the scientific reach further than that of the individual measurements. Finally, it is important to note the wealth of physics beyond dark energy and inflation that these very same cosmic signals can probe. From neutrinos and new relativisitic particles, to modified gravity and dark matter, cosmic signals have the ability to answer some of the biggest questions currently facing high-energy physics.\nFigure 3 shows a simplified summary of these same scientific targets as well as the cosmic signals and techniques used to explore them. Four main techniques are shown and discussed further in this report. First, optical and near-infrared surveys combining both imaging and spectroscopic (SPEC) measurements to measure tracers of structure (such as galaxies) in the late-time universe. Section 3 discusses the highly anticipated scientific impact of the Vera Rubin Observatory (LSST) and the Dark Energy Spectroscopic Instrument (DESI), as well as complementary facilities and a future envisioned Stage V spectroscopic survey. Next, Section 4 introduces CMB facilities, including the CMB-S4 experiment that was prioritized in the previous Snowmass and P5 process. Also discussed is one concept for a CMB facility that is a potential successor to CMB-S4. Section 5 highlights the power of cross-correlations between optical imaging, spectroscopic, and CMB surveys. This section also introduces transients and gravitational wave observations (GWO, emitted from local universe sources) as probes of fundamental physics, which also relies on complementary survey observations. Smaller projects and technology pathfinders are described in Section 6. Included is a discussion of line-intensity mapping (LIM) both using the 21-cm line from neutral hydrogen and mm-wavelength tracers, such as the rotational transitions of CO and the [CII] ionized carbon fine structure line. Finally, Section 7 details current and future gravitational wave observatories that will provide gravitational wave events for multi-messenger probes. Altogether, these observational techniques and cosmic survey facilities provide a unique and powerful means to explore dark energy and inflation in the coming decade, as well as developing the technology and concepts needed to continue a vibrant and cutting-edge program in the years that follow.\n3 Optical/Near-Infrared Surveys and Facilities\nWide-field surveys at optical and near-infrared wavelengths play a central role in the exploration of the physics of the dark Universe. The Sloan Digital Sky Survey (SDSS), the first major survey jointly supported by the DOE and NSF, delivered unprecedented measurements of the structure of the Universe at late times. SDSS had first light in 1998 and provided both imaging and spectroscopic data. DOE-supported upgrades to the instrumentation in 2007\u20132009 enabled the cosmology reach to earlier cosmic times with the SDSS-III/BOSS and SDSS-IV/eBOSS programs. BOSS and eBOSS were spectroscopic surveys focused on refining measurements of the BAO signal through extensions of the SDSS program.\nBuilding upon the tremendous success of SDSS, new optical surveys have been designed, constructed, and executed through continued partnership between DOE and NSF. The Dark Energy Survey (DES) is an imaging survey that was operated on the 4-m Blanco telescope in 2013\u20132019 and is currently extracting final cosmology results. DES has delivered exciting results on the fundamental physics of dark energy, modified gravity, and dark matter. The Rubin Observatory is under construction in Chile and will start the Legacy Survey of Space and Time (LSST) in 2024. LSST will survey the southern sky with an unprecedented combination of depth, visit frequency, spectral bands, and areal coverage to provide unprecedented constraints on dark energy, neutrinos, and dark matter over the course of its 10-year survey. Recently, the Dark Energy Spectroscopic Instrument (DESI) started its observational campaign on the 4-m Mayall telescope in pursuit of measurements of dark energy, neutrino mass, and dark matter.\nWide-field surveys in the optical/near-infrared have played a critical role in establishing the standard model of cosmology, CDM and have delivered a broad range of science in addition to dark energy studies.\nThis exceptional success showcases the power of imaging and spectroscopic surveys, and we strongly advocate for continuing this extremely successful program into the coming decade and beyond.\nIn particular, the unparalleled efficiency of DESI for wide-field spectroscopy and the unprecedented imaging survey data to be collected by the Rubin Observatory will open up many exciting directions for advances in cosmology.\nIn the following, we provide first a brief summary of facilities that are currently operating (DESI) or will soon start operations (Rubin Observatory). Then we discuss future opportunities with either existing or new facilities. We emphasize the following priorities for the optical survey program:\nSupport for extracting science from ongoing and near-future surveys;Support for small programs that use existing facilities to maximize the science from flagship facilities;Support for the development of new technology to enable future surveys;Support for the design and development of a Stage V spectroscopic survey.\n1 Rubin Observatory\nThe Vera C.\u00a0Rubin Observatory is a powerful facility that will further our knowledge of the Universe in many ways by enabling studies of the nature of dark energy and dark matter, a deep census of the solar system, exploration of the transient optical sky, and surveys of the stellar populations of the Milky Way\n\u00a0[8]. The Legacy Survey of Space and Time (LSST) to be undertaken with the observatory is due to start operations in 2024 and map the Southern sky for 10 years. LSST will deliver exciting science opportunities and we stress that support for LSST science will be crucial for the community.\nPrecursor surveys have shown that data from a new survey always come with unexpected challenges but also opportunities. To address the challenges and to take advantage of new opportunities, sufficient support of the science programs is essential.\nAfter LSST is completed, Rubin will still be a state-of-the-art survey facility. The\nRubin White Paper\u00a0[9] describes possibilities for future endeavors for the observatory, and provides the scientific motivations for three post-LSST scenarios. Given that this CF6 report focuses on future facilities, we summarize them here and refer the reader to the White Paper and the CF4 report for the scientific justifications.\nThe post-LSST opportunities for Rubin are in three broad categories, as described in Ref.\u00a0[9]:Continuing operations: A strong science case for continued cooperation of Rubin relates to time-domain studies that would rely on modified observing cadence, exposure time, or filter selections relative to the LSST survey for greatly enhanced efficiency and target-of-opportunity observations of rare phenomena. Other scientific cases for continued operation of the observatory relate to follow-up observations of discoveries with LSST, focusing on studies that would enhance understanding the fundamental nature of dark matter. Continuing operations of Rubin, modifying only the observing strategy, could also provide synergistic observations that enable better scientific outcomes from combined analyses with overlapping large-area deep optical surveys in support of cosmology. In particular, the planned 2000 deg High Latitude Survey with the Nancy Grace Roman Observatory would be an important target.New filters: Several scientific opportunities would be enabled by installation of new photometric filters. Examples discussed in Ref.\u00a0[9] include a filter set complementary to the original six to improve photometric redshift estimates of the catalogued galaxy sample; a set of narrow-band or medium-band filters to enable emission line surveys for particular lines at redshift  or to select samples of galaxies at a set of discrete redshifts; and a set of patterned filters, which would enable multiple bandpasses to be sampled simultaneously across the field.New instrument: This would be the most expensive option but could transform the Rubin Observatory by providing truly new capabilities. For example, a wide-field spectrograph would provide the opportunity to follow up the rich LSST imaging dataset and open many new scientific approaches. This option would require a detailed feasibility and design study in the near future.\n2 Dark Energy Spectroscopic Instrument\nThe next decade promises exciting findings to gain a better understanding of the physics of the dark Universe. DESI, located on the 4-m Mayall Telescope at Kitt Peak, Arizona\u00a0[10, 11], is the first Stage IV dark energy experiment to begin science operations.\nDESI consists of a focal plane with 5,000 fiber positioners, a field-of-view with a diameter of 3.2 deg and ten 3-channel spectrographs covering the wavelength range 0.36\u20130.98 m.\nDESI is currently conducting a 5-year survey to measure redshifts of 40 million galaxies plus a survey of gas in the intergalactic medium to constrain dark energy and cosmological parameters using the BAO and RSD techniques. At the end of the survey in 2026, the instrument will still be competitive with all other multi-object spectrographs that will exist at the time. The proposed DESI-II survey would continue operating the instrument (possibly with upgrades) leveraging and complementing the first\nyear or two of imaging data from Rubin LSST.\nAdditional spectroscopic data can enhance Rubin science in several ways (e.g., in photometric redshift training).\nAdditionally, the DESI instrument is being considered as a possible contributor to Snowmass CF4 programs, particularly a large-volume survey to study inflation, neutrinos, and early dark energy in the linear/quasi-linear regime\u00a0[12], and a large number density survey to study dark matter physics, modified gravity, small scale features in the primordial power spectrum, and possibly unknown physics\u00a0[13].\nThe continued operation of the DESI instrument (DESI-II) is an important first step in the future spectroscopic roadmap and it is currently at the early stages of conceptual design [14].\nSeveral unique science opportunities are possible, either by continued operations of the current instrument, or with modest technological upgrades. These include dense surveys of the local volume for precision measurements of dark matter, dark energy, and high-resolution studies of the cosmic web (and transients followup for gravitational waves, supernovae, etc.), extension of the Luminous Red Galaxy (LRG) and Emission Line Galaxy (ELG) samples to higher redshift to enable multi-tracer analyses and take advantage of sample-variance cancellation, as well as increasing the observed volume, allowing access to larger scales, providing the cleanest probes of primordial physics.\nA high-redshift () survey of Lyman-alpha emitters (LAEs) and Lyman Break Galaxies (LBGs) would measure a volume comparable to the main DESI samples, but at a different cosmic time. This would allow measurements of the amplitude of fluctuations at high redshift, a particularly compelling measurement in light of the recent tensions between the amplitude of structures at late time (), compared to the predictions from the CMB (the so-called \u201c tension\u201d). Measurements in the intermediate redshift regime () are particularly well-suited for understanding the origin of this tension. Moreover, measurements of expansion over this redshift range, deep into the matter-dominated epoch, will shed light on dynamical dark energy, where many models mimic a cosmological constant at late times, but can differ significantly from it during matter domination.\nIn addition to its science reach, such a survey would also serve as a pathfinder for extended wide-field observations of high-redshift galaxies by a future facility, as discussed in the next Section.\nPossible technology upgrades to the DESI instrument include replacement of detectors with low-read-noise Skipper CCDs, a replacement of the focal plane with a larger number of fiber positioners, and the addition of a 4th spectroscopic channel extending further into the IR to measure [OII]-emitting galaxies to , not currently possible with the existing 3 channels.\nMoreover, the potential overlap between DESI and LSST is an impressive 14,000 square degrees of extragalactic sky if both instruments were to observe to their design limits () and represents a great opportunity to complement LSST observations with galaxy spectroscopy. The most ambitious upgrade of DESI would include the replacement of the primary mirror, effectively turning the instrument into MegaMapper, a candidate future stage V spectroscopic facility described in the next Section.\n3 Stage V Wide-field Multi-Object Spectroscopy\nBy 2030, Rubin LSST will have mapped at least 20,000 deg of the sky at unprecedented depth from Cerro Panch\u00f3n in Chile.\nLSST will measure the expansion history and structure of the Universe through observations of type Ia supernova, weak lensing, galaxy clustering, strong lensing, and ultra-faint galaxies.\nHowever, LSST provides only coarse spectral information, and spectroscopic capabilities are essential to maximize the fundamental physical output from cosmic surveys\u00a0[15].\nCurrent wide-field spectroscopic capabilities in the southern hemisphere are insufficient for the task of complementing Rubin LSST.\nExisting capability is dominated by the Anglo-Australian Observatory\u2019s 2dF, with 400 optical fibers covering 3 deg field-of-view on the 3.9-m AAT in Australia. The 4MOST instrument\u00a0[16], currently under construction and scheduled to begin operations soon, will measure 2400 spectra simultaneously using the 4-m VISTA telescope at the European Southern Observatory. Larger instruments, such as the 6.5-m Magellan telescopes at Las Campanas Observatory, the 8-m Gemini Telescope at Cerro Pach\u00f3n, and the 8.2-m Very Large Telescope at the European Southern Observatory (all in Chile), have fields-of-view that are too small for wide-field surveys. Other facilities are planned with 8-m to 30-m mirrors, but also have fields-of-view that are insufficient for large-field surveys.\nThe Snowmass2021 Cosmic Frontier is charged with synthesizing community input on future studies of dark energy, dark matter, inflation, neutrinos, and other light relics through observational cosmology within the HEP program.\nThrough the Snowmass2021 process, the HEP community has identified the pressing need for additional wide-field spectroscopic capabilities to complement LSST imaging\u00a0[13, 12].\nUnderstanding of the needs has evolved from previous community studies on maximizing science from LSST in 2015\u20132016\u00a0[17, 15] and from the HEP Cosmic Visions process in 2016\u20132018\u00a0[18, 19, 20].\nSeveral white papers have been submitted to Astro2020 and Snowmass2021 describing the physics program and facilities that could meet some or all of these needs including DESI-II\u00a0[14], MegaMapper\u00a0[21, 22, 23], the Maunakea Spectroscopic Explorer (MSE)\u00a0[24, 25], and SpecTel [26]. In-depth discussion of the science opportunities, together with detailed forecasts for a number of experimental configurations have been presented\u00a0[12, 27, 28].\nThe fundamental physics program of a future spectroscopic facility is diverse and multifaceted. Following the evolutionary history of the Universe from early to late times:\nInflation: A next-generation spectroscopic survey will access an extremely large volume of the Universe, which will enable it to measure a number of primordial quantities beyond the cosmic variance limit of the CMB. These include making exquisite measurements of the power spectrum, dramatically increasing the sensitivity to primordial features or oscillations that can be created by many models of inflation.\nSharp features arise when there is a sudden transition during inflation such as a step in the potential. Resonant features arise when some component of the background oscillates with a frequency larger than the Hubble scale.\nAnother important advance achievable by these surveys is measurement of primordial non-Gaussianity with the goal of an order-of-magnitude improvement in sensitivity to surpass , allowing the two main inflationary scenarios (single field vs multi-field inflation) to be distinguished.\nAdditionally, greatly improved measurements of the running of the spectral index and of spatial curvature will shed additional light on the physics of the early Universe.Neutrinos and Dark Radiation: Measurements of the physics of the early Universe provide strong constraints on the dark sector via, for example, via the determination of the number of light particles that are thermalized. This is parameterized by , the number of relativistic particles other than photons. The Standard Model with three neutrino species predicts .\nMeasurements of the matter power spectrum can detect or exclude the existence of other particle species that decouple after the QCD phase transition, and tightly constrain particles that decouple earlier.\nCosmological measurements from large galaxy surveys will complement CMB observations and other experimental efforts to detect low-mass dark sector particles (e.g., via quantum sensors, a 3\u2009GeV muon beam dump experiment, and DarkQuest).Dark Energy Throughout Cosmic History: We are now in the domain of precision tests of the CDM model.During this decade, experiments like DESI, Rubin LSST, Euclid, and the Roman Space Telescope will map the expansion of the Universe up to redshifts of  (when the Universe was roughly one-third of its current size). A wide-field multi-object spectroscopic facility is needed to map the expansion of the Universe to higher redshifts (earlier times). A detailed 3D map of at least  million galaxy positions with redshifts in the range  is needed to take the next step in dark energy research. Precision measurements of the redshifts of  million distant galaxies will require an increase of about an order of magnitude in the combination of the number of fibers and light collection capabilities over current spectroscopic instruments, driving the design of future facilities. Additionally, precision measurements of the matter power spectrum will be able to provide indirect percent-level constraints on Early Dark Energy (EDE) up to , when the Universe was only a few years old\u00a0[27].\n4 Complementary Facilities\nThe optical/near-infrared dark energy facilities described in this section will be complemented by several ground- and space-based observatories at similar wavelengths.\nThey will be in various phases of planning, construction, and operation over the coming decades.\nSince these facilities are currently driven by support from NASA, NSF-AST, and private contributions, we summarize them briefly here.\nWe note that future support from DOE or NSF-PHYS could come through future instruments, US Extremely Large Telescopes (US-ELTs) or support for joint analyses.\nUS Extremely Large Telescopes The US-ELT program consists of two 30-m-class telescopes: the Giant Magellan Telescope (GMT) to be sited in Chile and the Thirty Meter Telescope (TMT) to be sited in Hawai\u2018i.\nThese telescopes have relatively small fields-of-view and multiplexing, and thus are not optimal as wide-area spectroscopic survey facilities.\nHowever, the large light collecting area provided by a 30-m mirror allows these telescopes to observe extremely faint objects quickly.\nThe US-ELT program was the highest-ranked ground-based porgram in the Astro2020 Decadal survey, but it is unlikely that the HEP community will participate in the design or construction of these telescope facilities.\nHowever,\nUS-ELTs could complement one of the surveys discussed in this section by providing, for example, deep spectroscopy for training photometric redshift estimators on the faintest galaxies observed by Rubin or high-resolution imaging data to constrain dark matter through strong lensing.\nThe cost of an ELT instrument (M) would be roughly comparable to the cost of other HEP cosmic survey construction projects (e.g., DECam or DESI).Small, Wide-field Optical Surveys Both the Zwicky Transient Facility (ZTF) and the La Silla Schmidt Southern Survey (LS4) provide a complementary, and necessary, set of observations to those of the Rubin and the space-based surveys. ZTF and LS4 have direct relevance to several cosmology and fundamental physics efforts including: peculiar velocity measurements, and hence fundamental constraints on general relativity, with supernova as standardized candles; gravitational wave standard sirens as probes of the expansion of the\nUniverse and gravity; and measurements of the Hubble constant through Type Ia and II-P supernovae. They provide a higher cadence than the aforementioned surveys, especially important for analyzing the light curves as well as triggering follow-up for low- supernovae, and both have a robust ToO program for GW counterpart discovery in the optical. In addition, they open up the possibility of improved calibration for both Tully-Fisher and Fundamental Plane measurements (from spectroscopic surveys such as DESI) via supernova distances.Space-based Observatories Some description of Euclic, Roman, SpherEx and any others\u2026Gravitational Wave Observatories Some description of LIGO, Cosmic Explorer,\u2026\n4 Cosmic Microwave Background Surveys\nWide-field surveys of the CMB play a central role in particle physics and cosmology. Missions such as COBE [29], WMAP\u00a0[30], and Planck\u00a0[31] have provided critical insight into the birth and early evolution of our Universe. In addition, many ground-based CMB experiments such as AdvACT\u00a0[32], SPT-3G\u00a0[33], BICEP/KECK\u00a0[34], and Simons Array\u00a0[35] continue to push the frontiers of CMB measurements into lower-noise and higher-resolution regimes. Power spectra of CMB temperature and polarization data provide some of the tightest constraints on particle physics models, dark matter, and inflation, and \u2013 combined with measurements of gravitational lensing of the CMB \u2013 compelling evidence for dark energy.\nBuilding on the successes of precursor CMB experiments, the Simons Observatory\u00a0[36] and the South Pole Observatory are commencing observations in the early 2020s (see Figure\u00a05). Looking ahead, the CMB-S4 project\u00a0[37] is planned to make significant leaps in sensitivity. CMB-S4 is a joint DOE and NSF project that received DOE CD-0 approval in 2019, is advancing toward DOE CD-1 and NSF PDR, and currently has broad engagement from the majority of the US ground-based CMB science community. On a longer time-scale, CMB-HD is a proposed experimental concept that would have six times the resolution of current and planned CMB experiments, opening up a new regime of millimeter-wave science\u00a0[38].\nGiven the pivotal role that CMB experiments play in the landscape of particle physics and cosmology, and their phenomenal successes thus far, we strongly advocate for continuing the CMB program into the coming decade and beyond. Similar to the optical survey program, we emphasize three priorities for the CMB survey program:\nSupport for ongoing and near-future surveys, including CMB-S4;Support for the development of new technology to enable the next major survey post CMB-S4;Support for the design and development of the next major survey.\n1 CMB-S4\nCMB-S4 is the next-generation (Stage IV) cosmic microwave background experiment\u00a0[37]. CMB-S4 is designed to achieve an enormous increase in sensitivity compared to existing CMB experiments while simultaneously leveraging two premier observing sites. Combined, these unique features will enable CMB-S4 to make transformational measurements of primordial gravitational waves and inflation and the dark Universe\u00a0[39]. Both of these science themes are of significant interest to the high-energy physics and cosmology communities. Additionally, the unique properties of CMB-S4 will enable mapping the matter in the cosmos and studies of the time-variable millimeter wavelength sky. CMB-S4 is a joint DOE and NSF project that has strong community support as evidenced by the mature, large collaboration and endorsements in the previous Snowmass, P5 report\u00a0[40], and more recently the Astro2020 Decadal Survey Report\u00a0[41].\nCMB-S4 will construct telescopes in both Chile and at the South Pole, taking best advantage of features of each site to pursue its scientific goals. The South Pole site will host 18 small-aperture telescopes (SATs, diameter \u00a0 0.5 meter) and one 5-meter large-aperture telescope (LAT). These telescopes will conduct an ultra-deep survey of 3% of the sky, targeting the B-mode polarization measurements at both the large and small angular scales on the sky needed to constrain inflation. Two 6-meter LATs will conduct a deep and wide survey of 60% of the sky from the Chilean site, targeting the CMB-S4 science goals that benefit from additional sky area. Over 550,000 detectors will be deployed across the CMB-S4 telescopes, an enormous increase over all Stage III experiments combined that will make the planned increase in sensitivity possible. As introduced above, CMB-S4 has four main science themes that drive this experiment design and subsequent exceptional measurement opportunities. Here, we emphasize CMB-S4\u2019s impact on two key themes of particular relevance to the science of cosmic acceleration (for more details see discussions in white papers\u00a0[37, 42, 43, 44, 45, 46]).Primordial gravitational waves and inflation: Cosmic inflation is a prominent theory for the origin of structure in the Universe. A detection of primordial gravitational waves from inflation would be historic, providing evidence for the quantization of gravity and opening a window into the very early Universe [44].\nThe factor of five leap in sensitivity and exquisite systematics control embedded in the CMB-S4 design will enable the experiment to cross major theoretically motivated thresholds through either a detection of these primordial gravitational waves from an inflationary epoch or an upper limit that will rule out entire classes of the most compelling inflationary models. In either outcome, CMB-S4 will dramatically advance our understanding of the primordial Universe.The dark Universe: CMB-S4 will also provide multiple compelling probes of the late-time universe which will enable stringent tests of dark energy and other models of the Universe\u2019s observed accelerated late-time expansion. These probes include precision measurements of the gravitational lensing of the CMB, the kSZ velocity field, and a large (100,000) sample of massive galaxy clusters discovered via the tSZ effect. There is an additional wealth of information to be gained through cross survey analyses between the CMB and other tracers of structure as detailed below.\nIn addition to the fundamental physics above, the sensitivity and sky coverage of the CMB-S4 millimeter-wavelength survey will enable other important scientific opportunities in the themes of \u2018mapping matter in the cosmos\u2019 and the \u2018time-variable millimeter-wave sky\u2019. Light relics are a well-motivated potential contributor of energy density in the Universe that lead to an observable signal in the CMB temperature and polarization\u00a0[47]. CMB-S4 will be able to constrain the effective number of neutrino species with a sensitivity to Weyl fermion and vector particles that froze out in the first fractions of a nanosecond.\nFor explorations of the cosmological and astrophysical science of the growth of structure, maps of the ionized gas distribution at CMB-S4 sensitivity will lead to the detection of an order of magnitude more high-redshift () galaxy clusters than found by Stage III experiments\u00a0[39]. This is just one example of the scientific potential of the ionized gas map; several others, including opportunities for complementarity, are described in the CMB-S4 white paper and its references\u00a0[37]. Finally, CMB-S4 will provide new, key insights into millimeter-wavelength transient phenomena by making a repeated, systematic survey of a larger area of the sky at a cadence of approximately a day. Limited studies of the variable millimeter-wave sky exist, and therefore the CMB-S4 survey will open this discovery space.\n2 CMB-HD\nCMB-HD is a proposed CMB experiment that would have three times the total number of detectors as CMB-S4 and about six times the resolution of current and planned high-resolution CMB telescopes, opening a new regime for millimeter-wave science\u00a0[38]. CMB-HD would cross important thresholds for improving our understanding of fundamental physics, including the nature of dark matter and dark energy, the light particle content of the Universe, the mechanism of inflation, and whether the early Universe has new physics beyond the Standard Model, as suggested by recent H measurements. The combination of CMB-HD with contemporary ground and space-based experiments would also provide countless powerful synergies.\nThe concept for the CMB-HD instrument is two new 30-meter-class off-axis crossed Dragone telescopes located on Cerro Toco in the Atacama Desert\u00a0[38, 48, 49]. Each telescope would host 800,000 detectors (200,000 pixels), for a total of 1.6 million detectors. The CMB-HD survey would cover half the sky over 7.5 years. This would result in an ultra-deep, ultra-high-resolution millimeter-wave survey over half the sky with 0.5\u00a0K-arcmin instrument noise in temperature (0.7\u00a0K-arcmin in polarization) in combined 90 and 150 GHz channels and 15-arcsecond resolution at 150 GHz. CMB-HD would also observe at seven different frequencies between 30 and 350 GHz for mitigation of foreground contamination.\nCMB-HD would be able to measure the dark energy equation of state with an uncertainty of  by combining galaxy cluster abundance measurements, galaxy cluster lensing measurements, and measurements of the primary CMB power spectra\u00a0[50, 51]. This would provide a constraint on the dark energy equation of state to sub-percent level accuracy. CMB-HD would also constrain an epoch of inflation in several ways. CMB-HD would probe the existence of inflationary magnetic fields in the early Universe via tight constraints on anisotropic birefringence. It would have the sensitivity to obtain a  uncertainty on the strength of scale-invariant inflationary magnetic fields, , of , which is below the  threshold required for inflationary magnetic fields to explain the  level magnetic fields observed in galaxies today\u00a0[52]. CMB-HD will therefore have the capability to detect inflationary magnetic fields with about  significance or greater, and such a detection would provide compelling evidence for inflation.\nThe cross correlation of CMB-HD with galaxy surveys would also provide powerful constraints on inflation. CMB-HD would measure primordial local non-Gaussian fluctuations in the CMB, characterized by the parameter , with an uncertainty of , by combining the kinetic Sunyaev-Zel\u2019dovich (kSZ) signal from CMB-HD with an over-apping galaxy survey such as from the Vera Rubin Observatory. This constraint is limited by the galaxy sample from Rubin Observatory, rather than by CMB-HD, and a combination with future even higher resolution galaxy surveys would lead to even better constraints. Reaching a target of  would rule out a wide class of multi-field inflation models, shedding light on how inflation happened\u00a0[53, 54, 55, 56, 57, 58]. Moreover, the combination of the kSZ effect from CMB-HD with the Rubin Observatory galaxy survey can constrain the primordial trispectrum amplitude, , with \u00a0[59]. CMB-HD also can provide an independent constraint on primordial gravitational waves with an uncertainty of  via the combination of the polarized Sunyaev-Zel\u2019dovich effect from CMB-HD with Rubin Observatory galaxies\u00a0[38]. For further details see\u00a0[38] and\u00a0https://cmb-hd.org.\n5 Opportunities from Cross-survey Analyses\nThe next decade will see dramatic improvements in our ability to probe the Universe, with major leaps in capabilities occurring nearly simultaneously across many new facilities. Each of these new facilities will enable transformative science, but joint analyses of the resultant datasets will be more powerful and robust than what can be achieved with any individual instrument. Notably, cross-survey analyses will improve the constraints on cosmic acceleration that drive the design and requirements for cosmological surveys into which DOE has invested, and also leverage those investments to constrain other aspects of fundamental physics that are important for our understanding of the Universe. At present, however, cross-survey analyses can be challenging to initiate, organize and fund. We therefore advocate for the creation of clear pathways to support cross-survey analyses as part of the core mission of the DOE Cosmic Frontier.\n1 Static Probes\nWe first consider cross-survey analyses between \u201cstatic\u201d probes of the Universe, i.e. those observables that do not change significantly over the time frame of a survey. This includes probes like galaxy positions, weak gravitational lensing, and the Sunyaev Zel\u2019dovich effect. Current and future cosmic surveys will obtain measurements of multiple static probes that overlap over significant fractions of the sky. Such measurements will enable many cross-survey analyses to obtain tighter and more robust constraints on the fundamental ingredients of our Universe. We illustrate the diversity and complementarity of overlapping cosmic probes in Fig.\u00a06.\nBy combining overlapping probes from different surveys, new information about cosmological structure can be extracted, and the cosmological constraints from individual surveys can be made more robust to possible systematic biases. Some prominent examples include:Improved cosmological constraints. By leveraging multi-wavelength data, combining imaging and spectroscopic surveys, cross-survey analyses will improve cosmological constraints from the evolution of large-scale structure.Improved robustness of cosmological constraints. Analyses of cross-survey correlations help to isolate survey-specific systematic effects and break degeneracies between cosmological parameters and nuisance parameters, making cosmological constraints more robust. In addition, multi-wavelength data allow for improved understanding of baryonic processes,\none of the main sources of systematic uncertainty in cosmological analyses of large-scale structure.\nMeasuring cross-correlations between different cosmological probes requires overlapping measurements on the sky. The survey strategies of several operational and planned DOE-funded cosmic surveys \u2014 including optical imaging, spectroscopic, and CMB surveys \u2014 have significant overlap. The potential therefore exists to harness the power of cross-correlations between them. However, modeling multi-survey correlations necessarily requires additional work beyond that typically undertaken by single surveys. In particular, there are significant technical challenges in simultaneously modeling and simulating observables that span a wide range of wavelength and scales, and that involve multiple astrophysical processes.\nBeyond the technical challenges associated with cross-survey analyses, there are also practical difficulties associated with this work. Any such analysis necessarily requires detailed knowledge of data products generated by multiple surveys. Some of this information may be proprietary, and not easily shared. Previous cross-survey analyses have typically waited until data products become public (thereby delaying results) or have operated through cross-survey memoranda of understanding (MoU). Relative to single-survey analyses, analyses conducted through MoU are often subject to additional bureaucratic hurdles that can delay progress and unnecessarily increase workloads. These difficulties can be significant enough to discourage cross-survey analyses, a clearly suboptimal outcome.\nTo capitalize upon these opportunities and address the associated challenges, a qualitatively new level of investment in cross-survey, joint-probe infrastructure is required \u2013 this includes simulations, associated modeling, coordination of data sharing, survey strategy, and training for the next generation of scientists in a way that transcends any individual project or collaboration. The required investments are substantial, but they are critical for the next generation of cosmic surveys to fully realize their potential. Below we present a summary of future opportunities for growth that have potential to multiplicatively enhance the scientific returns of cosmological surveys in the 2020s:\nJoint simulations: Nearly all of the multi-probe analyses discussed above require high-fidelity synthetic data that is validated against observational data. The computational demands of these simulations can be high, and an intensive human effort is required in order to generate synthetic data that is of sufficiently high quality to merit this expense. Considerable progress has been made in this area in recent years, but efforts are typically limited to an individual survey, or even an individual probe in isolation. For example, most CMB simulations do not include physically realistic models of galaxy populations at low redshift, and synthetic datasets tailored for optical surveys of galaxies do not commonly include realistic treatments of the diffuse gas that can be observed in CMB surveys via, e.g., the SZ effect.\nAs a result, the need is increasing for simulations that are suitable for multi-wavelength cross-correlation analyses. Addressing this widespread need is a key opportunity for further growth in the area of generating multi-survey synthetic data, and the wider cosmology community stands to greatly benefit from increased support for these efforts.Joint modeling and analysis: Current toolkits such as Cobaya [60], Monte Python [61], CosmoLike [62], and CosmoSIS [63] have been successful in combining a number of \u201cstandard\u201d large-scale structure probes in Bayesian analyses. Sophisticated modeling efforts with capability to make multi-wavelength predictions are commonly implemented in custom codebases that require highly specialized techniques in order to infer cosmological parameters in a Bayesian fashion. Fully integrating a new generation of models together with cosmological inference pipelines is another exciting opportunity, and would leverage new technologies such as machine learning methods, GPU interfaces, automatic gradient approaches, and likelihood-free inference methods.New initiatives enabling joint analyses: By construction, multi-survey analyses in the era of large collaborations are not hosted under one single collaboration with well-established communication structure and analysis tools. Presently such analyses are enabled by MoUs and other agreements, or carried out with public data. This structure can create an inherent barrier for multi-survey analyses, and suppress potential opportunities for exciting discoveries. Conversely, new levels of effort in cross-survey collaboration could offer major benefits to the scientific returns of future surveys. Such initiatives could include coordination of survey strategy to ensure overlap, joint processing of data, and coordination of cross-survey blinding strategies. New funding lines that focus on multi-survey cross-correlation analyses could be an effective, modest way to address some of these limitations. The scope of these problems, however, warrants consideration of new \u201ccenters\u201d focusing on development of joint simulation/modeling/analysis tools, as well as training/education for the next generation of cosmologists who will be confronted with data already in the 2020s that is of a qualitatively new character from previous decades.\nIn addition, this effort should be combined with a support for a healthy and equitable collaboration community [64, 65].Support for proposed cosmic survey instruments: The enormous potential of joint analyses discussed in this white paper is necessarily built on the success of single-probe experiments. Enabling cross-survey analyses requires support for wide-field cosmic surveys including those listed in Figure\u00a01, and many more described in accompanying Snowmass white papers [38, 66, 67, 68, 12, 21]. In return, joint-probe analyses will provide critical and complementary information for understanding cosmic acceleration and other fundamental physics.\n2 Transient Probes\nTransient science is a key frontier of modern cosmology, with profound implications for our understanding of dark energy, cosmological distances in the Universe, extreme strong-gravity environments, and high-energy physics. An extensive variety of transient science requires diverse data sets that can only be acquired via multiple experiments and surveys. For example, optical telescopes are necessary for the search and association of transient counterparts of gravitational-wave standard sirens detected by gravitational-wave observatories to measure the Hubble constant  [69, 70, 71, 72, 73, 74, 75]. Moreover, studies using transients in combination with data from neutrino experiments such as IceCube have been proposed for measurement of the neutrino masses [76, 77].\nTo measure the properties of dark energy specifically precise and accurate distance measurements will be needed for the Rubin Observatory Type Ia supernovae via spectroscopic, near-infrared, and enhanced temporal sampling [78].\nA high-efficiency search and discovery program will also be needed for the electromagnetic counterparts of standard sirens, to enable a measurement of the Hubble constant that is independent from the systematic uncertainties affecting other dark energy probes\u00a0[79]. One can also test theories of gravity from GW sources for both bright and dark standard sirens\u00a0[80]. High spatial resolution and enhanced temporal sampling are also required to obtain precise time delays by modeling strongly lensed systems discovered by Rubin Observatory, and therefore, independently measure the Hubble constant\u00a0[81, 82, 83, 84]. Finally, peculiar velocities inferred from the distances of standard sirens and supernovae could be compared with the density perturbations within the DESI survey volume to measure the strength and length scale of gravity\u00a0[85, 86, 87].\nCurrently a critical issue experienced by the HEP community is the perceived inconsistencies between different experiments and/or cosmological probes. A prime example is the Hubble tension, where the Hubble constant measured from the cosmic microwave background, baryon acoustic oscillations, and Type Ia supernovae are not in agreement. These tensions present an opportunity for our community to make a breakthrough in our understanding of dark energy. Their resolution may lie in new fundamental physics, or unaccounted-for systematic errors. Transient science can play a crucial role in solving this challenging issue with enough resources and support for developing its full potential (see Section 2 of\u00a0[79], for example).\nNo experiment alone can solve the dark energy problem. Such a breakthrough will require a complex network of experiments, small and large, working in tandem. As dark energy is a priority of our community, it is natural that we ramp up our efforts to build and operate those experiments, optimizing for dark energy science. Those efforts include near-, medium-, and long-term investments. For example, we need data from gravitational wave observatories, and from telescopes that can identify their transient counterparts and host galaxies. Therefore, supporting partnerships between ongoing projects (such as DES/DESI/LSST and the LIGO/Virgo/KAGRA Collaborations) as well as the development of a third-generation gravitational wave observatory (e.g. Cosmic Explorer\u00a0[88]), which until recently had been considered as a outside the scope of the HEP community, is consistent with our goals.\nTime-domain science with multiple experiments have unique considerations that do not occur for self-contained experiments, e.g., regarding experimental design. In a multi-experiment context, experimental designs can be optimized for a joint rather than stand-alone project. The joint analysis of low-level data products (e.g., pixels) can preserve significantly more information than the combination of lossy final data products. To benefit from this kind of joint analysis, static and time-domain resources are necessary for developing a new infrastructure for real-time communication between experiments.\nNew support is needed to enable this time-domain science to achieve and surpass the precision level of the current standard static experiments. As such, analysis of multiple experiments requires resources beyond the sum allocated to the individual ones. We need to develop simulations that account for different probes to support self-consistent interpretation of the multi-experiment data. Ultimately, new experiments must be developed and supported when existing ones are insufficient.\nWe advocate for these transient science initiatives detailed in Kim et al.\u00a0(2022)\u00a0[79]:Small projects to acquire supplemental data to enhance the science reach of transients discovered by Rubin LSST.Use of the 4-m Blanco telescope hosting DECam for fast and effective search and discovery of transients including gravitational wave events, strongly lensed quasars and strongly lensed supernovae.Infrastructure that enables cross-experiment, cross-facility coordination and data transfer for time-domain astronomical sources.Theory/modeling that improves understanding of the transient astrophysical probes that are used to study cosmology.A US-HEP multi-messenger program, supported with dedicated target-of-opportunity allocations on US-HEP and partner facilities for the follow-up of gravitational waves and rare neutrino events.The development of a novel standard siren survey program using next-generation gravitational wave observatories to fully incorporate this new observable into the research portfolio for dark energy science.Construction of novel large-scale projects for a multi-messenger dark energy survey, including gravitational wave observatories and optical NIR telescopes, designed to resolve the current tensions and advance understanding of dark energy and cosmic acceleration.\n6 Small Projects and Pathfinders\nIn 2016 and 2017, the community held two workshops to discuss future opportunities for survey science and to develop a small-project portfolio that would include technology developments to enable a major new Stage V Spectroscopic Facility. The findings are summarized in Ref.\u00a0[20]. In the following, we provide an overview of the findings that are relevant in particular to the development of new facilities to explore cosmic acceleration.\n1 Spectroscopy Pathfinder\nIn Ref.\u00a0[20] the importance of new technology developments were highlighted. These developments are needed in the near future to enable a credible design for a Stage V spectroscopic facility. In particular, near-term investigations of the following areas will be crucial:\nDetector technologies to extend to higher redshift (e.g., Germanium CCDs) and lower noise (e.g., Skipper CCDs). Current silicon CCD detectors have a wavelength cutoff due to the band gap of silicon. Lower band gap materials, such as Germanium offer the potential to extend to higher redshift. Precision measurements of faint, distant sources can be dominated by detector readout noise. Novel Skipper CCD detectors offer the ability to reduce noise through multiple non-destructive measurements of the charge in each detector pixel. A challenge in Skipper CCD technology is the readout time, which scales with the number of non-destructive measurements that are made.Fiber positioner technologies to enable smaller pitch, denser packing, and greater robustness. Two technologies are currently considered for fiber positioners. The robotic twirling post design has been used by DESI. R&D is ongoing to shrink the patrol radius and increase the packing density. Robustness is a current challenge faced by twirling post technology. The second technology is tilting spines, which are being used by the 4MOST spectrograph. R&D is ongoing to shrink the pitch and demonstrate precise control of fiber positions.Wide-field optics to enable larger focal planes that can hold more fibers. This is a critical component toward increasing total fiber number. Advances have been made in the context of several telescope designs to allow -meter diameter focal planes (i.e., MegaMapper, MSE, SpecTel). Current challenges are the fabrication of large-diameter lenses.Verification of high-redshift target viability (e.g., Lyman-alpha emitters, Lyman-break galaxies, etc.). This work is currently on-going with targeted observations by DESI.Narrow-band targeting would use large-field imagers outfitted with multiple medium- or narrow-band filters to improve targeting efficiency for future spectroscopy. Such a campaign could be executed by DECam outfitted with a new set of filters for a moderate cost.\n2 21-cm Pathfinders\nNeutral hydrogen is ubiquitous in the Universe after the CMB was formed, such that its 21\u2009cm emission can trace large-scale structure across cosmic time. At low redshift, maps of the 21\u2009cm emission line can form a galaxy survey to constrain models of dark energy. At higher redshifts, they can improve measurements of the primordial power spectrum as a probe of inflation (described in the CF5 report). In all cases, the primary challenge is removing bright foreground emission from the resulting maps, which drives the instrument design.\nMaps of 21\u2009cm emission at redshifts  form a galaxy survey using the signal from neutral hydrogen trapped in galaxies. Unlike their optical counterparts, these radio surveys naturally have wide fields of view and observe all redshifts in their band simultaneously, allowing these radio telescopes to quickly survey very large volumes spanning the redshift desert (\u2013) and beyond (\u2013), where optical spectroscopy is challenging or impossible. To detect cosmological neutral hydrogen across a wide redshift range and target inflation and dark energy science goals, a dedicated 21\u2009cm instrument will require a close-packed array of thousands of dishes at least 6\u2009m in diameter across a wide redshift range\u00a0[89, 90], resulting in a radio array with a physically large footprint ( km scales) that requires efficient signal transfer and an extremely large digital correlator.\nDedicated experiments to use 21\u2009cm emission to map structure have shown that the primary challenge is foreground removal\u00a0[91, 92, 93, 94, 95, 96], which drives requirements for instrumentation calibration and design. Solving these design challenges requires targeted R&D for a pathfinder that has uniform elements; a well-controlled bandpass; instrument stability and stabilization methods using digital signal processing and fast real-time analysis; robust real-time RFI flagging; new calibration techniques for beam and gain measurements potentially including drone-based calibration; and requires analysis and simulations to fold in calibration measurements and assess their impact on cosmological parameter estimation[89]. The primary US pathfinder targeting this R&D is The Packed Ultra-wideband Mapping Array (PUMA)\u00a0[90], a proposed next-generation 21\u2009cm \u00a0intensity mapping array which is optimized for cosmology in the post-reionization era. The reference design calls for PUMA to consist of a hexagonal close-packed array of 32,000 parabolic dishes 6m in diameter, observing at 200-1100\u2009MHz, corresponding to a redshift range of . The pathfinder array for this experiment is the PUMA-5K array, a staged deployment of 5000 dishes that would be used to test the analog, digital, and calibration equipment at a scale large enough to assess success on the sky. Specific technology R&D required includes:Digital electronics at or near the dish foci.A timing distribution network that spans kilometers with relative timing accuracy better than a picosecond.Real-time data processing, including real-time calibration, to enable essentially real-time data compression across interferometer inputs.Analog system design that includes uniformity of all elements and smooth response across a wide bandwidth.\nFinally, the Dark Ages () are a particularly clean probe of the primordial power spectrum and its statistics, including searches for non-Gaussianity. However, measurements during this era are extremely challenging because the resulting long wavelengths (7 to 70\u2009m) require a physically large instrument and must contend with non-negligible effects from the Earth\u2019s ionosphere and significant contamination from human-generated radio sources (RFI). To assess whether the far side of the moon is adequate to address these issues, the DOE and NASA are collaborating to launch the pathfinder experiment LuSEE-Night (Lunar Surface Electromagnetics Experiment at Night) in lateW 2025 to deploy 4 steerable monopole antennas to characterize the radio sky at frequencies 1-50MHz with percent level absolute calibration and a  relative calibration between frequency bands. With data collected over 12 nights, it should provide measurements of the low-frequency radio sky below 50\u00a0MHz, demonstrate the feasibility of Dark Ages cosmology from the far side of the Moon, should have sufficient sensitivity to exclude presence of a monopole signal at about the 1 Kelvin level, about 1-2 orders of magnitude above the expected signal yet sufficient to constrain some models predicting non-standard properties of baryon thermodynamics during the Dark Ages.\n3 Line-Intensity Mapping\nLine-intensity mapping (LIM) is a nascent technique for mapping the large-scale structure (LSS) in the universe by measuring the spatial distribution of an atomic or molecular emission line with low-resolution spectrometers ()\u00a0[97, 98].\nThe ability to measure multiple emission lines over a wide range of redshifts , beyond the range of current galaxy surveys, makes LIM a particularly promising technique for future surveys of large-scale structure.\nAlthough this method can be used with any emission line, LIM using mm-wavelength tracers, such as the rotational transitions of CO and the [CII] ionized carbon fine structure line, is of great experimental interest because such emission can be detected over the redshift range of  from the ground using technology that is already in widespread use in CMB and sub-mm telescopes.\nIn addition, the Galactic foregrounds are significantly less bright in these frequency ranges than in 21cm surveys using similar techniques.\nLIM with mm-wave tracers may be capable of making very significant improvements in constraints on primordial non-gaussianity, neutrino properties, light thermal relics, and dark energy, but doing so will require experiments with significantly more receiver elements and longer integration times than currently exist and development of sophisticated analysis pipelines.\nA suite of small projects, including CCAT-p, COMAP, CONCERTO, EXCLAIM, mmIME, SPT-SLIM, TIM, and TIME, is currently prototyping various spectrometer and detector technologies, at the scale of  spectrometer-hours or less.\nBy contrast, constraining the amplitude of local-type primordial non-gaussianity to a level  that would distinguish between single- and multi-field inflation, or dtecting the minimal sum of the neutrino masses at  would require a survey with  spectrometer-hours, three-orders of magnitude larger than existing projects.\nTo reach this level of sensitivity requires investment in a program of technology development, complemented by the staged deployment of projects with increasingly large focal planes of detectors to demonstrate these technologies in the field, analogous to the way the CMB field has grown from few-pixel experiments to an experiment like CMB-S4 with 500,000 detectors. Concurrent, steady improvement in modeling, analysis techniques, tools and pipelines is a must.\nSpecific technological capabilities to develop include:On-chip spectrometers:\nA key challenge in scaling mm-wave spectrometers to very high channel counts is the spectrometer element itself.\nTraditional technologies, such as diffraction gratings, Fourier Transform or Fabry-Perot spectrometers, and heterodyne detection perform well for the existing generation of small focal planes, but each has difficulties scaling to larger focal planes.\nOn-chip spectrometers, which channelize the incident radiation using a filter bank on the same silicon wafer as the pixel itself (similar to the current generation of multichroic CMB detectors, but with many more channels), offer a promising solution to the scaling problem by shrinking the physical size of the spectrometer and eliminating complex coupling optics between the telescope and the pixel.\nDespite these attractive features for mm-wave LIM, on-chip spectrometers are comparatively less mature than traditional technologies, and require field demonstration to test existing architectures and adapt the form factor to more efficiently use focal plane area of telescopes.Multiplexed readout electronics:\nSpectrometers with  spectral channels per spatial pixel require far more detectors or channels than broadband cameras.\nIncreased multiplexing factors are essential in order to reduce the per channel cost of the readout system to a manageable level.\nAdvances in FPGA technologies, such as RF system-on-a-chip (RFSoC) devices, for example, may reduce per channel cost of readout for kinetic inductance detectors to the level of $1\u20132 / channel.Telescopes and facilities:\nDetectors for mm-wave LIM, especially on-chip spectrometers, are compatible with the existing generation of small- and large-aperture telescopes built for CMB observations, including SPT, ACT, SO, and CCATp.\nIn some cases, these existing facilities can be used to host mm-wave demonstration cameras without compromising other science goals (e.g. SPT-SLIM on SPT and PrimeCam on CCATp).\nA staged deployment of mm-wave LIM cameras of increasing size, using existing telescope infrastructure, is critical for achieving on-sky demonstrations of detector and readout technologies and prototyping analysis pipelines.\nSince mm-wave LIM is still a very young field, a staged program of surveys of increasing size will provide valuable data sets for developing analysis techniques and characterizing observational systematics.\nFor example, the problem of interlopers \u2014 lines from different transitions and redshifts that map to the same observed frequency \u2014is one well-known systematic with several proposed solutions, but these mitigations have yet to be tested on real data.\nSimilarly, the effect of atmospheric lines at mm-wavelengths is not expected to corrupt cosmological LIM signals, but projecting to the low required noise levels is difficult.\n7 Multi-Messenger Probes\n1 Gravitational Wave Observatories\nHistorically, gravitational wave (GW) observatories were outside the scientific scope of the US HEP community\u2019s efforts. However, since the discovery of GW150914 by the LIGO & Virgo collaborations and the realization that gravitational wave standard sirens are a powerful dark energy probe (e.g., GW170817), the community has embraced this type of experiment. For that reason, we incorporate them here in the discussion of this report. The next decade will see upgrades of existing facilities, as well as developments of new large-scale projects. Both are discussed below.\nCurrent Ground-Based GW Facilities\nCurrently, there are two LIGO facilities, in Livingston, Louisiana (LLO) and Hanford, Washington (LHO). Each of these detectors has 4-km long arms and is expected to have sensitivity for binary neutron star (BNS) mergers out to 160\u2013190\u2009Mpc during the LIGO Fourth Observing run (O4). Other facilities expected to be online during O4 and beyond are Virgo, in Italy, as well as the recently constructed KAGRA in Japan. Each of these facilities has 3km long arms and is in various stages of sensitivity. During O3, Virgo reached a BNS range of 40\u201350\u2009Mpc and is expected to ramp up to 80\u2013115\u2009Mpc during O4. KAGRA, on the other hand, will be online only for a portion of O4 and it is expected to reach \u2009Mpc BNS sensitivity. During the O4 run the LIGO/Virgo Collaboration (LVC) expects to detect  BNS events.\nFuture Ground-Based GW Facilities\nWith the numerous GW discoveries in recent years, plans for new ground-based facilities are already underway. LIGO-India has been approved for construction and should be operational by the end of the decade. This detector is planned to be the same size and design as the current LIGO facilities and will come online at similar sensitivity as current detectors\u00a0[99]. The addition of LIGO-India will greatly improve the localization of GW events, as well as help to measure the polarization of GWs. Additionally, plans for the Einstein Telescope have been moving forward\u00a0[100]. This facility would be underground with 10-km long arms and would be a third-generation (3G) GW observatory. In the US, Cosmic Explorer (CE) is the current 3G proposal for the 2030s, and it is now in the conceptual design phase\u00a0[101]. One of the CE\u2019s proposals is two detectors of 40-km long arms that will be able to reach sources at  in network with the Einstein Telescope.\nFuture Space Based-GW Facilities\nSpace-borne gravitational wave observatories are being planned or proposed for the 2030s. The Laser Interferometer Space Antenna (LISA), a constellation of three spacecraft forming an equilateral triangle with sides 2.5-million km long, is understudy. LISA is led by the European Space Agency, but with significant contributions from NASA and the US, along with several other countries. LISA will open a new window in the GW spectrum by detecting sources in the mHz frequency band. Its main detections will be the inspiral and merger of massive binary black holes (MBBHs), with masses ranging between  and , at redshifts out to . LISA will observe the early inspiral phase of stellar-mass binary systems months to years before they are observed in terrestrial detectors. This has the potential to open an entire new chapter of the GW field by adding the power of multi-band observations. LISA scientific objectives include measurements of the expansion rate of the universe by means of GW observations alone and further to constrain cosmological parameters through joint GW and electromagnetic (EM) observations. Another objective of LISA is to understand primordial stochastic gravitational wave backgrounds (SGWBs) and their implications for early universe and particle physics [102].\nComplementary to LISA, the Deci-hertz Interferometer Gravitational Wave Observatory (DECIGO) is the proposed Japanese space mission in the decihertz frequency band. DECIGO consists of four clusters of three spacecrafts (LISA-like) with an arm length of 1000-km. The main goals of DECIGO are the detection of primordial gravitational waves to verify and characterize the inflationary era, measurement of the expansion rate of the universe, and to characterize dark energy, and the prediction of accurate time and direction for electromagnetic follow-up observations. DECIGO will catch  gravitational wave events per year from neutron star binary mergers within  [103]. A decihertz observatory like DECIGO is projected to determine the Hubble constant to , and the dark-energy parameters  and  to  and , respectively [69].", "output": "The mechanism(s) driving the early- and late-time accelerated expansion of the Universe represent one of the most compelling mysteries in fundamental physics today. The path to understanding the causes of early- and late-time acceleration depends on fully leveraging ongoing surveys, developing and demonstrating new technologies, and constructing and operating new instruments. This report presents a multi-faceted vision for the cosmic survey program in the 2030s and beyond that derives from these considerations. Cosmic surveys address a wide range of fundamental physics questions, and are thus a unique and powerful component of the HEP experimental portfolio.", "question": "none", "title": "2209.08654", "qa_pairs": "none"}
